
[返回AI主体部分](../../../ai.md)
# 深度学习部分
跟随天池中的教程进行学习([具体网址](https://tianchi.aliyun.com/course?spm=a2c22.12281897.J_3941670930.5.e34a23b7wA2LaV))

## 1.数据清洗
东西有点多，分个新的文档
[<font size="5">数据清洗</font>](../数据清洗/数据清洗.md)
<h5 id="data_1"></h5>

## 2.基础知识 ([原始链接](https://tianchi.aliyun.com/course/311/3558))
### 2.1 卷积
#### 2.1.1 实例
```python
import torch 
from torch import nn

def corr2d(X, K):  # X 是输入，K是卷积核
    h, w = K.shape  # 获取卷积核的大小
    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))
    for i in range(Y.shape[0]):
        for j in range(Y.shape[1]):
            Y[i, j] = (X[i: i + h, j: j + w] * K).sum()  # 累加
    return Y

X = torch.tensor([[0, 1, 2], [3, 4, 5], [6, 7, 8]]) # 模拟一个输入
K = torch.tensor([[0, 1], [2, 3]])                  # 模拟一个卷积核
corr2d(X, K)
```
tensor([[19., 25.],
        [37., 43.]])
下图就是上面程序的模拟图
![](http://tianchi-media.oss-cn-beijing.aliyuncs.com/dragonball/DL/other/img/5.1_correlation.svg)
### 2.2 填充（Padding）

1. 使卷积后图像分辨率不变，方便计算特征图尺寸的变化
2. 弥补边界信息“丢失”

填充（padding）是指在输入高和宽的两侧填充元素（通常是0元素）。下图我们在原输入高和宽的两侧分别添加了值为0的元素，使得输入高和宽从3变成了5，并导致输出高和宽由2增加到4。下图阴影部分为第一个输出元素及其计算所使用的输入和核数组元素：0×0+0×1+0×2+0×3=0。

![](http://tianchi-media.oss-cn-beijing.aliyuncs.com/dragonball/DL/other/img/卷积填充.png)
### 2.3 步长（Stride）


卷积窗口从输入数组的最左上方开始，按从左往右、从上往下的顺序，依次在输入数组上滑动。我们将每次滑动的行数和列数称为步幅或步长（stride）。

下图展示了在高上步幅为3、在宽上步幅为2的卷积运算。可以看到，输出第一列第二个元素时，卷积窗口向下滑动了3行，而在输出第一行第二个元素时卷积窗口向右滑动了2列。当卷积窗口在输入上再向右滑动2列时，由于输入元素无法填满窗口，无结果输出。下图阴影部分为输出元素及其计算所使用的输入和核数组元素：0×0+0×1+1×2+2×3=8、0×0+6×1+0×2+0×3=6。


![](http://tianchi-media.oss-cn-beijing.aliyuncs.com/dragonball/DL/other/img/5.2_conv_stride.svg)
### 2.4 池化

对图像进行下采样，降低图像分辨率。

**池化层的作用：使特征图变小，简化网络计算复杂度；压缩特征，提取主要特征**

常见的池化操作可以分为：最大池化（Max Pool）、平均池化（Avg Pool），示意图如下：

![](http://tianchi-media.oss-cn-beijing.aliyuncs.com/dragonball/DL/other/img/池化.png)
### 2.5 卷积和池化输出尺寸计算

假设输入图片的高和宽一致，卷积核的宽和高一致，那么输入图像的尺寸与输出图像的尺寸有如下关系：

其中，$F_{in}$ 是输入图像、k 是卷积核的大小、p 是图像填充的大小、s 是卷积核的步幅、$F_o$ 是输出、$\lfloor 6.6 \rfloor$ 是向下取整的意思，比如结果是 6.6，那么向下取整就是 6

$$F_{o}=\left\lfloor\frac{F_{\text {in }}-k+2 p}{s}\right\rfloor+1$$

![](http://tianchi-media.oss-cn-beijing.aliyuncs.com/dragonball/DL/other/img/卷积与池化输出尺寸计算.png)

除此之外，卷积神经网络还包括许多优化技术，大家可以参考相关资料。
### 2.6 为什么要用卷积来学习呢？

图像都是用方形矩阵来表达的，学习的本质就是要抽象出特征，以边缘检测为例。它就是识别数字图像中亮度变化明显的点，这些点连接起来往往是物体的边缘。

传统的边缘检测常用的方法包括一阶和二阶导数法，本质上都是利用一个卷积核在原图上进行滑动，只是其中各个位置的系数不同，比如3×3的sobel算子计算x方向的梯度幅度，使用的就是下面的卷积核算子。

![](http://tianchi-media.oss-cn-beijing.aliyuncs.com/dragonball/DL/other/img/sobel算子.png)

如果要用sobel算子完成一次完整的边缘检测，就要同时检测x方向和y方向，然后进行融合。这就是两个通道的卷积，先用两个卷积核进行通道内的信息提取，再进行通道间的信息融合。
这就是卷积提取特征的本质，而所有基于卷积神经网络来学习的图像算法，都是通过不断的卷积来进行特征的抽象，直到实现网络的目标。
### 2.7  卷积神经网络的优势在哪？
前面说了全连接神经网络的原理和结构上的缺陷，而这正好是卷积的优势。
1. 学习原理上的改进。

卷积神经网络不再是有监督学习了，不需要从图像中提取特征，而是直接从原始图像数据进行学习，这样可以最大程度的防止信息在还没有进入网络之前就丢失。

2. 学习方式的改进。

前面说了全连接神经网络一层的结果是与上一层的节点全部连接的，100×100的图像，如果隐藏层也是同样大小（100×100个）的神经元，光是一层网络，就已经有 10^8 个参数。要优化和存储这样的参数量，是无法想象的，所以经典的神经网络，基本上隐藏层在一两层左右。而卷积神经网络某一层的结点，只与上一层的一个图像块相连。

用于产生同一个图像中各个空间位置像素的卷积核是同一个，这就是所谓的权值共享。对于与全连接层同样多的隐藏层，假如每个神经元只和输入10×10的局部patch相连接，且卷积核移动步长为10，则参数为：100×100×10×10，降低了2个数量级。
又能更好的学习，参数又低，卷积神经网络当然是可以成功了。


## 3.numpy部分
numpy是人工智能中一个极为好用的库，大部分的算法都可以通过使用该库来进行优化。
[<font size="5">Numpy</font>](../基础/numpy/Numpy.md)
<h5 id="Numpy返回坐标">返回坐标</h5>

## 4.torch部分
### 4.0 安装
使用 `pip install pytorch`即可快速完成安装。但是大多是情况下仅会安装CPU版本，而GPU版本的话需要根据自己的电脑配置手动进行安装。
### 4.1 基础知识
<p id = "张量"><p>

#### 4.1.1 张量 ([具体笔记](torch/torch_basic_tensor.ipynb))<p id="tensor中的笔记绝大多数均为天池的原文件，只是根据个人理解进行了些许更改"> 
张量(tensor)是torch中的一种特殊的数据形式，可以在GPU上计算。所以通常会把需要进行大量操作的数据均转化为tensor形式进行操作
##### 4.1.1.1 常用函数 
###### 4.1.1.1.1 创建
- `torch.tensor(data)`
**功能**：**从data创建tensor**
`data`: 数据，可以是list，numpy
`dtype`: 数据类型，默认与data的一致
`device`: 所在设备，cuda/cpu
`requires_grad`: 是否需要梯度
`pin_memory`: 是否存于锁页内存
>
- `torch.from_numpy(ndarray)`
**功能**：**从numpy创建tensor**
注意事项：从torch.from_numpy创建的tensor于原ndarray共享内存，当修改其中一个数据，另一个也将会被改动。
>
- `torch.zeros(*size)`
**功能**：**依size创建全0张量**
>
- `torch.zeros_like(input)`
 **功能**：**依input形状创建全0张量**
>
- `torch.ones(*size)`
**功能**：**依size创建全1张量**
>
- `torch.ones_like(input)`
 **功能**：**依input形状创建全1张量**
>
- `torch.full(size, fill_value)`
 **功能**：**依size创建全fill_value张量**
>
- `torch.full_like(input)`
 **功能**：**依input形状创建指定数据的张量**
>
- `torch.arange(start, end. step)`
 **功能**：**创建等差的1维张量**
>
- `torch.linspace(start, end, steps)`
 **功能**：**创建均分的1维张量**
>
- `torch.logspace(start, end, steps)`
 **功能**：**创建对数均分的1维张量**
>
- `torch.eye(n)`
 **功能**：**创建单位对角矩阵（2维张量）**
>
- `torch.normal(mean, std, out=None)`
 **功能：生成正态分布（高斯分布）**
    - `mean`: `均值`
    - `std`: `标准差`
>
- `torch.normal(mean, std, size, out=None)`
 **功能：生成一定大小的生成正态分布（高斯分布）**
>
- `torch.randn(size)`
 **功能：生成标准正态分布**
>
- `torch.rand(size)`
 **功能：在区间$[0, 1)$上，生成均匀分布**
>
- `torch.randperm(n)`
 **功能：生成从0到n-1的随机排列**
>
- `torch.bernoulli(input)`
 **功能：以input为概率，生成伯努利分布（0-1分布，两点分布）**
###### 4.1.1.1.2 张量操作
>
- `torch.cat(tensors, dim=0)`
 **功能：将张量按维度dim进行拼接**
 >
- `torch.stack(tensors, dim=0)`
 **功能：在新创建的维度dim上进行拼接**
 >
- `torch.chunk(input, chunks, dim=0)`
 **功能：将张量按维度dim进行平均切分**
 >
- `torch.split(tensor, split_size_or_sections, dim=0)`
 **功能：将张量按维度dim进行切分**
 >
- `torch.index_select(input, dim, index)`
 **功能：在维度dim上，按index索引数据**
 >
- `torch.masked_select(input, mask)`
 **功能：按mask中的True进行索引**
  >
- `torch.reshape(input, shape)`
 **功能：变换张量形状**
  >
- `torch.transpose(input, dim0, dim1)`
 **功能：交换张量的两个维度**
  >
- `torch.t(input)`
 **功能：2维张量转置**
  >
- `torch.squeeze(input, dim=None)`
 **功能：压缩长度为1的维度（轴）**
  >
- `torch.unsqueeze(input, dim)`
 **功能：依据dim扩展维度**
   >
- `torch.add(tensor1, tensor2)`
 **功能：将tensor1与tensor2中对应元素进行相加**
   >
- `torch.mul(tensor1, tensor2)`
 **功能：将tensor1与tensor2中对应元素进行相乘**


#### 4.1.2 反向传播([具体笔记](torch/torch_basic_backward.ipynb))
即误差反向传播，是训练神经网络的重要方法。
本质是是单个样本通过计算梯度并且反向传播给各个参数以调节其权重。为了保证对于所有的样本识别均有效，实际上需要将所有的样本分别进行反向传播，然后以其平均值来真正的调整参数权重。


> 由于反向传播需要的计算量较大，所以引入了batch的概念。在训练完一个批次后再将本批次一同进行反向传播

#### 4.1.3 神经网络([具体笔记](torch/torch_basic_neural_network.ipynb))<p id="neural_network中的笔记绝大多数均为天池的原文件，只是根据个人理解进行了些许更改"> 
##### 4.1.3.1 softmax回归
将数据格式千奇百怪的输出通过softmax运算符
来将输出变换为值为正且和为以的概率分布

- 简单的模型定义
```python
# 自定义网络结构
class LinearNet(nn.Module):
    def __init__(self):
        super(LinearNet, self).__init__()
        # 定义一层全连接层
        self.dense = nn.Linear(4, 3)
        # 定义Softmax
        self.softmax = nn.Softmax(dim=1)

    def forward(self, x):
        y = self.dense(x.view((-1, 4)))
        y = self.softmax(y)
        return y

net = LinearNet()
```
- torch.nn.CrossEntropyLoss(weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean')
- 衡量模型输出与真实标签的差异，在分类时相当有用。
- **结合了nn.LogSoftmax()和nn.NLLLoss()两个函数，进行交叉熵计算。**
- 主要参数：
    - weight: 各类别的loss设置权值
    - ignore_index: 忽略某个类别
    - reduction: 计算模式，可为none/sum/mean
        - none: 逐个元素计算
        - sum: 所有元素求和，返回标量
        - mean: 加权平均，返回标量

- torch.optim.SGD(params, lr=<required parameter>, momentum=0, dampening=0, weight_decay=0, nesterov=False)
- 构建一个优化器对象optimizer，用来保存当前的状态，并能够根据计算得到的梯度来更新参数，使得模型输出更接近真实标签。
- 学习率（learning rate）控制更新的步伐。
- 主要参数：
    - params: 管理的参数组
    - lr: 初始化学习率
    - momentum: 动量系数
    - weight_decay: L2正则化系数
    - nesterov: 是否采用NAG
- zero_grad(): 清空所管理参数的梯度，因为Pytorch张量梯度不自动清零。
- step(): 执行一步更新
    
- 简单模型训练过程
```python
loss = nn.CrossEntropyLoss()  # 交叉熵损失函数
optimizer = torch.optim.SGD(net.parameters(), lr=0.1)  # 随机梯度下降法
for epoch in range(70):
    train_l = 0.0
    y_hat = net(X)
    l = loss(y_hat, target).sum()

    # 梯度清零
    optimizer.zero_grad()
    # 自动求导梯度
    l.backward()
    # 利用优化函数调整所有权重参数
    optimizer.step()

    train_l += l
    print('epoch %d, loss %.4f' % (epoch + 1, train_l))
```


### 4.2 强化部分

#### 4.2.1 数据增强([具体笔记](torch/torch_strengthen_Transform.ipynb))
数据增强本质上就是将原始的训练数据通过一系列的操作来进行变换，从而形成新的数据以参与训练。


#### 4.2.2 迁移学习([具体笔记](torch/torch_strengthen_TransferLearning.ipynb))
迁移学习是目前最为常用的一种模型训练方式。其实本质上就是使用已经训练完的模型在自己的数据集上再一次进行训练。这样的方式称为微调
1. 在源数据集（如ImageNet数据集）上预训练一个神经网络模型，即源模型。
2. 创建一个新的神经网络模型，即目标模型。它复制了源模型上除了输出层外的所有模型设计及其参数。我们假设这些模型参数包含了源数据集上学习到的知识，且这些知识同样适用于目标数据集。我们还假设源模型的输出层跟源数据集的标签紧密相关，因此在目标模型中不予采用。
3. 为目标模型添加一个输出大小为目标数据集类别个数的输出层，并随机初始化该层的模型参数。
4. 在目标数据集（如FashionMNIST数据集）上训练目标模型。我们将从头训练输出层，而其余层的参数都是基于源模型的参数微调得到的。

#### 4.2.3 保存和加载模型([具体笔记](torch/torch_strengthen_SaveAndLoad.ipynb))
最为简单的方式：
```python
# 保存  （保存可学习参数）
PATH = './download'
torch.save(model.state_dict(), PATH)

# 加载
model = TheModelClass()
model.load_state_dict(torch.load(PATH))
model.eval()

#或者

# 保存（保存全部模型）
torch.save(model, PATH)
# 加载
model = torch.load(PATH)
model.eval()
```



### 4.3 nn部分
#### 4.3.1 模型构建部分
- `torch.nn.Conv2d(in_channels,out_channels,kernel_size,stride ,padding)` : 创建  的卷积层
  - `in_channels` :  输入的Tensor的通道数
  - `out_channels` : 输出的Tensor的通道数
  - `kernel_size` : 卷积核尺寸
  - `stride` : 卷积步长
  - `padding` ： 填充操作
- `torch.nn.Linear(in_feature,out_feature,bias)` ：
  - `in_feature` :  输入的Tensor的通道数
  - `out_feature` : 输出的Tensor的通道数
  - `bias` ： 是否添加bias偏置
- `torch.nn.maxpool2d()` # 创建 的最大池化层


#### 4.3.2 模型参数初始化部分
- `torch.nn.init.xavier_uniform_(a)` : 为a以均匀分布的方式用值填充输入张量
- `torch.nn.init.constant_(a,b)` ： 为a以b为值填入张量

## 5.cv部分
量大，速速跳转[点这](../cv/cv.md)

[返回AI主体部分](../../../ai.md)