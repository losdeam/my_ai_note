{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "倒立摆环境实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\envs\\d2l\\lib\\site-packages\\gym\\envs\\registration.py:555: UserWarning: \u001b[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make(\"CartPole-v0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.04579001,  0.03924654, -0.03609226, -0.04957405], dtype=float32),\n",
       " {})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env.action_space:  Discrete(2)\n"
     ]
    }
   ],
   "source": [
    "print(\"env.action_space: \", env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj [-0.03169782  0.62620384 -0.05730348 -0.9638166 ]\n",
      "reward 1.0\n",
      "done False\n",
      "info {}\n"
     ]
    }
   ],
   "source": [
    "#执行一个向左的操作\n",
    "obj, reward, done,_, info = env.step(1) #1 向右 0向左\n",
    "print(\"obj\", obj) # 新状态\n",
    "print(\"reward\", reward) # 指定该动作获取的奖励值\n",
    "print(\"done\", done) # 回合是否结束\n",
    "print(\"info\", info) # 额外信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#随机获取一个动作\n",
    "action = env.action_space.sample()\n",
    "print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "done = True\n",
    "\n",
    "for step in range(50):\n",
    "    if done:\n",
    "        state = env.reset()\n",
    "    action = env.action_space.sample()\n",
    "    state, reward, done,_, info = env.step(action)\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调包的整完了，手搓一个试试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym \n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0005 \n",
    "gamma = 0.98 \n",
    "lmbda = 0.95\n",
    "eps_clip = 0.1 \n",
    "K_epoch = 3 \n",
    "T_horizon = 20 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "直接开始搓马里奥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym_super_mario_bros\n",
    "from gym.spaces import Box\n",
    "from gym import Wrapper\n",
    "from nes_py.wrappers import JoypadSpace#BinarySpaceToDiscreteSpaceEnv\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT, COMPLEX_MOVEMENT, RIGHT_ONLY\n",
    "import cv2\n",
    "import numpy as np\n",
    "import subprocess as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame(frame):\n",
    "    if frame is not None:\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY) #图像转换\n",
    "        \n",
    "        frame = cv2.resize(frame, (84, 84))[None, :, :] / 255. #裁剪合适大小，并归一化\n",
    "\n",
    "        return frame\n",
    "    else:\n",
    "        return np.zeros((1,84, 84))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomSkipFrame(Wrapper):\n",
    "    def __init__(self, env, skip=4):\n",
    "        super(CustomSkipFrame, self).__init__(env)\n",
    "        self.observation_space = Box(low=0, high=255, shape=(4, 84, 84))\n",
    "        self.skip = skip\n",
    "\n",
    "    def step(self, action):\n",
    "        total_reward = 0\n",
    "        states = []\n",
    "        state, reward, done, info = self.env.step(action)\n",
    "        for i in range(self.skip):\n",
    "            if not done:\n",
    "                state, reward, done, info = self.env.step(action)\n",
    "                total_reward += reward\n",
    "                states.append(state)\n",
    "            else:\n",
    "                states.append(state)\n",
    "        states = np.concatenate(states, 0)[None, :, :, :]\n",
    "        return states.astype(np.float32), reward, done, info\n",
    "\n",
    "    def reset(self):\n",
    "        state = self.env.reset()\n",
    "        states = np.concatenate([state for _ in range(self.skip)], 0)[None, :, :, :]\n",
    "        return states.astype(np.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomReward(Wrapper):\n",
    "    def __init__(self, env=None):\n",
    "        super(CustomReward, self).__init__(env)\n",
    "        self.observation_space = Box(low=0, high=255, shape=(1, 84, 84))\n",
    "        self.curr_score = 0\n",
    "        self.pre_x = 38 \n",
    "    def step(self, action):\n",
    "        state, reward, done, info = self.env.step(action) \n",
    "        state = process_frame(state)\n",
    "        reward += (info[\"score\"] - self.curr_score) / 50.\n",
    "        \n",
    "        reward += (info[\"x_pos\"] - self.pre_x ) * 10.\n",
    "        self.pre_x = info[\"x_pos\"]\n",
    "        # self.pre_x = info[\"x_pos\"]\n",
    "        self.curr_score = info[\"score\"]\n",
    "        if done:\n",
    "            if info[\"flag_get\"]:\n",
    "                reward += 5000\n",
    "            else:\n",
    "                reward -= 50\n",
    "        return state, reward/10. , done, info\n",
    "\n",
    "    def reset(self):\n",
    "        self.curr_score = 0\n",
    "        return process_frame(self.env.reset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#至此，我们完成了超级玛丽环境的自定义，封装如下：\n",
    "def create_train_env(world, stage, action_type, output_path=None):\n",
    "    env = gym_super_mario_bros.make(\"SuperMarioBros-{}-{}-v0\".format(world, stage))\n",
    "    if action_type == \"right\":\n",
    "        actions = RIGHT_ONLY\n",
    "    elif action_type == \"simple\":\n",
    "        actions = SIMPLE_MOVEMENT\n",
    "    else:\n",
    "        actions = COMPLEX_MOVEMENT\n",
    "    env = JoypadSpace(env, actions)\n",
    "    env = CustomReward(env)\n",
    "    env = CustomSkipFrame(env)\n",
    "    return env, env.observation_space.shape[0], len(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.signal\n",
    "from gym.spaces import Box, Discrete\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions.normal import Normal\n",
    "from torch.distributions.categorical import Categorical\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_shape(length,shape=None):\n",
    "    if shape is None :\n",
    "        return (length,)\n",
    "    return (length,shape) if np.isscalar(shape) else (length,*shape)\n",
    "    # np.isscalar 判断对象是否为标量值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn_model(nn.Module):\n",
    "    def __init__(self,num_inputs,num_out,activation = nn.ReLU):\n",
    "        super(cnn_model,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(num_inputs,32,3,stride = 2 ,padding =1)\n",
    "        self.conv2 = nn.Conv2d(32,32,3,stride = 2 ,padding =1)\n",
    "        self.conv3 = nn.Conv2d(32,32,3,stride = 2 ,padding =1)\n",
    "        self.conv4 = nn.Conv2d(32,32,3,stride = 2 ,padding =1)\n",
    "        self.lstm = nn.Linear(326*6,512)\n",
    "        self.fc_out = nn.Linear(512,num_out)\n",
    "        self._initialize_weights() # 初始化权重\n",
    "    def _initialize_weights(self):\n",
    "        for module in self.modules: # 以迭代器的方式返回此前声明的所有layer\n",
    "            if isinstance(module,nn.Conv2d) or isinstance(module,nn.Linear): #isinstance,判断参数一是否是参数二的格式\n",
    "                nn.init.xavier_uniform_(module.weight) # 使用均匀分布 用值填充输入张量\n",
    "                nn.init.constant_(module.bis,0)  # 使用 输入值来为bis填入张量\n",
    "            elif isinstance(module,nn.LSTMCell):\n",
    "                nn.init.constant_(module.bis_ih,0) \n",
    "                nn.init.constant_(module.bis_hh,0) \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = F.relu(self.lstm(x))\n",
    "        out = self.fc_out(x)\n",
    "        return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_var(module):#计算参数总数\n",
    "    return sum([np.prod(p.shape) for p in module.parameters()]) \n",
    "def discount_cumsum(x,discount):\n",
    "    return scipy.signal.lfilter([1],[1,float(-discount)],x[::-1],axis = 0)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spinup.utils.logx import EpochLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\envs\\d2l\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import scipy.signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ppo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
