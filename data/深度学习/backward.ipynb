{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 反向传播\n",
    "即误差反向传播，是训练神经网络的重要方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参照tensor.ipynb所写的一个简单的例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "第0次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第0次反向传播后的梯度为:\n",
      "tensor([-144.5525]) tensor([-23.0967])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第1次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第1次反向传播后的梯度为:\n",
      "tensor([353.6027]) tensor([53.8844])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第2次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第2次反向传播后的梯度为:\n",
      "tensor([-863.6285]) tensor([-134.1645])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第3次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第3次反向传播后的梯度为:\n",
      "tensor([2110.6216]) tensor([325.3762])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第4次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第4次反向传播后的梯度为:\n",
      "tensor([-5156.8525]) tensor([-797.4445])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第5次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第5次反向传播后的梯度为:\n",
      "tensor([12600.9355]) tensor([1946.1733])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第6次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第6次反向传播后的梯度为:\n",
      "tensor([-30789.5527]) tensor([-4757.7051])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第7次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第7次反向传播后的梯度为:\n",
      "tensor([75233.4453]) tensor([11623.0137])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第8次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第8次反向传播后的梯度为:\n",
      "tensor([-183829.7031]) tensor([-28402.6016])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第9次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第9次反向传播后的梯度为:\n",
      "tensor([449181.1875]) tensor([69398.5000])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第10次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第10次反向传播后的梯度为:\n",
      "tensor([-1097556.7500]) tensor([-169574.7344])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第11次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第11次反向传播后的梯度为:\n",
      "tensor([2681838.2500]) tensor([414347.2812])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第12次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第12次反向传播后的梯度为:\n",
      "tensor([-6552970.5000]) tensor([-1012443.8125])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第13次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第13次反向传播后的梯度为:\n",
      "tensor([16011936.]) tensor([2473866.2500])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第14次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第14次反向传播后的梯度为:\n",
      "tensor([-39124556.]) tensor([-6044800.5000])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第15次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第15次反向传播后的梯度为:\n",
      "tensor([95599376.]) tensor([14770239.])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第16次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第16次反向传播后的梯度为:\n",
      "tensor([-2.3359e+08]) tensor([-36090524.])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第17次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第17次反向传播后的梯度为:\n",
      "tensor([5.7078e+08]) tensor([88185808.])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第18次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第18次反向传播后的梯度为:\n",
      "tensor([-1.3947e+09]) tensor([-2.1548e+08])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第19次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第19次反向传播后的梯度为:\n",
      "tensor([3.4078e+09]) tensor([5.2651e+08])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第20次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第20次反向传播后的梯度为:\n",
      "tensor([-8.3269e+09]) tensor([-1.2865e+09])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第21次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第21次反向传播后的梯度为:\n",
      "tensor([2.0346e+10]) tensor([3.1436e+09])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第22次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第22次反向传播后的梯度为:\n",
      "tensor([-4.9716e+10]) tensor([-7.6812e+09])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第23次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第23次反向传播后的梯度为:\n",
      "tensor([1.2148e+11]) tensor([1.8769e+10])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第24次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第24次反向传播后的梯度为:\n",
      "tensor([-2.9683e+11]) tensor([-4.5860e+10])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第25次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第25次反向传播后的梯度为:\n",
      "tensor([7.2529e+11]) tensor([1.1206e+11])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第26次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第26次反向传播后的梯度为:\n",
      "tensor([-1.7722e+12]) tensor([-2.7381e+11])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第27次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第27次反向传播后的梯度为:\n",
      "tensor([4.3303e+12]) tensor([6.6904e+11])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第28次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第28次反向传播后的梯度为:\n",
      "tensor([-1.0581e+13]) tensor([-1.6348e+12])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第29次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第29次反向传播后的梯度为:\n",
      "tensor([2.5854e+13]) tensor([3.9945e+12])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第30次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第30次反向传播后的梯度为:\n",
      "tensor([-6.3174e+13]) tensor([-9.7605e+12])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第31次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第31次反向传播后的梯度为:\n",
      "tensor([1.5436e+14]) tensor([2.3849e+13])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第32次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第32次反向传播后的梯度为:\n",
      "tensor([-3.7718e+14]) tensor([-5.8275e+13])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第33次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第33次反向传播后的梯度为:\n",
      "tensor([9.2163e+14]) tensor([1.4239e+14])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第34次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第34次反向传播后的梯度为:\n",
      "tensor([-2.2520e+15]) tensor([-3.4793e+14])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第35次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第35次反向传播后的梯度为:\n",
      "tensor([5.5026e+15]) tensor([8.5016e+14])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第36次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第36次反向传播后的梯度为:\n",
      "tensor([-1.3445e+16]) tensor([-2.0773e+15])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第37次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第37次反向传播后的梯度为:\n",
      "tensor([3.2853e+16]) tensor([5.0759e+15])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第38次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第38次反向传播后的梯度为:\n",
      "tensor([-8.0276e+16]) tensor([-1.2403e+16])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第39次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第39次反向传播后的梯度为:\n",
      "tensor([1.9615e+17]) tensor([3.0305e+16])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第40次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第40次反向传播后的梯度为:\n",
      "tensor([-4.7929e+17]) tensor([-7.4050e+16])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第41次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第41次反向传播后的梯度为:\n",
      "tensor([1.1711e+18]) tensor([1.8094e+17])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第42次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第42次反向传播后的梯度为:\n",
      "tensor([-2.8616e+18]) tensor([-4.4212e+17])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第43次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第43次反向传播后的梯度为:\n",
      "tensor([6.9922e+18]) tensor([1.0803e+18])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第44次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第44次反向传播后的梯度为:\n",
      "tensor([-1.7085e+19]) tensor([-2.6397e+18])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第45次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第45次反向传播后的梯度为:\n",
      "tensor([4.1747e+19]) tensor([6.4499e+18])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第46次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第46次反向传播后的梯度为:\n",
      "tensor([-1.0201e+20]) tensor([-1.5760e+19])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第47次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第47次反向传播后的梯度为:\n",
      "tensor([2.4925e+20]) tensor([3.8509e+19])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第48次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第48次反向传播后的梯度为:\n",
      "tensor([-6.0903e+20]) tensor([-9.4096e+19])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第49次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第49次反向传播后的梯度为:\n",
      "tensor([1.4881e+21]) tensor([2.2992e+20])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第50次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第50次反向传播后的梯度为:\n",
      "tensor([-3.6362e+21]) tensor([-5.6180e+20])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第51次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第51次反向传播后的梯度为:\n",
      "tensor([8.8850e+21]) tensor([1.3727e+21])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第52次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第52次反向传播后的梯度为:\n",
      "tensor([-2.1710e+22]) tensor([-3.3542e+21])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第53次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第53次反向传播后的梯度为:\n",
      "tensor([5.3048e+22]) tensor([8.1960e+21])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第54次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第54次反向传播后的梯度为:\n",
      "tensor([-1.2962e+23]) tensor([-2.0027e+22])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第55次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第55次反向传播后的梯度为:\n",
      "tensor([3.1672e+23]) tensor([4.8934e+22])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第56次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第56次反向传播后的梯度为:\n",
      "tensor([-7.7390e+23]) tensor([-1.1957e+23])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第57次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第57次反向传播后的梯度为:\n",
      "tensor([1.8910e+24]) tensor([2.9216e+23])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第58次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第58次反向传播后的梯度为:\n",
      "tensor([-4.6206e+24]) tensor([-7.1388e+23])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第59次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第59次反向传播后的梯度为:\n",
      "tensor([1.1290e+25]) tensor([1.7443e+24])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第60次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第60次反向传播后的梯度为:\n",
      "tensor([-2.7587e+25]) tensor([-4.2622e+24])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第61次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第61次反向传播后的梯度为:\n",
      "tensor([6.7408e+25]) tensor([1.0415e+25])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第62次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第62次反向传播后的梯度为:\n",
      "tensor([-1.6471e+26]) tensor([-2.5448e+25])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第63次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第63次反向传播后的梯度为:\n",
      "tensor([4.0246e+26]) tensor([6.2181e+25])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第64次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第64次反向传播后的梯度为:\n",
      "tensor([-9.8340e+26]) tensor([-1.5194e+26])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第65次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第65次反向传播后的梯度为:\n",
      "tensor([2.4029e+27]) tensor([3.7125e+26])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第66次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第66次反向传播后的梯度为:\n",
      "tensor([-5.8714e+27]) tensor([-9.0714e+26])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第67次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第67次反向传播后的梯度为:\n",
      "tensor([1.4346e+28]) tensor([2.2165e+27])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第68次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第68次反向传播后的梯度为:\n",
      "tensor([-3.5055e+28]) tensor([-5.4161e+27])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第69次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第69次反向传播后的梯度为:\n",
      "tensor([8.5656e+28]) tensor([1.3234e+28])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第70次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第70次反向传播后的梯度为:\n",
      "tensor([-2.0930e+29]) tensor([-3.2337e+28])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第71次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第71次反向传播后的梯度为:\n",
      "tensor([5.1141e+29]) tensor([7.9013e+28])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第72次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第72次反向传播后的梯度为:\n",
      "tensor([-1.2496e+30]) tensor([-1.9307e+29])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第73次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第73次反向传播后的梯度为:\n",
      "tensor([3.0534e+30]) tensor([4.7175e+29])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第74次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第74次反向传播后的梯度为:\n",
      "tensor([-7.4608e+30]) tensor([-1.1527e+30])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第75次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第75次反向传播后的梯度为:\n",
      "tensor([1.8230e+31]) tensor([2.8166e+30])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第76次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第76次反向传播后的梯度为:\n",
      "tensor([-4.4545e+31]) tensor([-6.8822e+30])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第77次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第77次反向传播后的梯度为:\n",
      "tensor([1.0884e+32]) tensor([1.6816e+31])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第78次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第78次反向传播后的梯度为:\n",
      "tensor([-2.6595e+32]) tensor([-4.1090e+31])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第79次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第79次反向传播后的梯度为:\n",
      "tensor([6.4985e+32]) tensor([1.0040e+32])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第80次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第80次反向传播后的梯度为:\n",
      "tensor([-1.5879e+33]) tensor([-2.4533e+32])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第81次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第81次反向传播后的梯度为:\n",
      "tensor([3.8799e+33]) tensor([5.9945e+32])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第82次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第82次反向传播后的梯度为:\n",
      "tensor([-9.4804e+33]) tensor([-1.4647e+33])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第83次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第83次反向传播后的梯度为:\n",
      "tensor([2.3165e+34]) tensor([3.5790e+33])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第84次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第84次反向传播后的梯度为:\n",
      "tensor([-5.6603e+34]) tensor([-8.7452e+33])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第85次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第85次反向传播后的梯度为:\n",
      "tensor([1.3831e+35]) tensor([2.1369e+34])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第86次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第86次反向传播后的梯度为:\n",
      "tensor([-3.3795e+35]) tensor([-5.2214e+34])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第87次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第87次反向传播后的梯度为:\n",
      "tensor([8.2576e+35]) tensor([1.2758e+35])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第88次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第88次反向传播后的梯度为:\n",
      "tensor([-2.0177e+36]) tensor([-3.1174e+35])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第89次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第89次反向传播后的梯度为:\n",
      "tensor([4.9302e+36]) tensor([7.6173e+35])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第90次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第90次反向传播后的梯度为:\n",
      "tensor([-1.2047e+37]) tensor([-1.8613e+36])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第91次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第91次反向传播后的梯度为:\n",
      "tensor([2.9436e+37]) tensor([4.5479e+36])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第92次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第92次反向传播后的梯度为:\n",
      "tensor([-7.1926e+37]) tensor([-1.1113e+37])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第93次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第93次反向传播后的梯度为:\n",
      "tensor([1.7575e+38]) tensor([2.7153e+37])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第94次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第94次反向传播后的梯度为:\n",
      "tensor([-inf]) tensor([-6.6348e+37])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第95次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第95次反向传播后的梯度为:\n",
      "tensor([inf]) tensor([inf])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第96次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第96次反向传播后的梯度为:\n",
      "tensor([nan]) tensor([nan])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第97次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第97次反向传播后的梯度为:\n",
      "tensor([nan]) tensor([nan])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第98次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第98次反向传播后的梯度为:\n",
      "tensor([nan]) tensor([nan])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第99次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n",
      "第99次反向传播后的梯度为:\n",
      "tensor([nan]) tensor([nan])\n",
      "************************************************************\n",
      "tensor([nan]) tensor([nan])\n"
     ]
    }
   ],
   "source": [
    "# 首先我们得有训练样本X，Y， 这里我们随机生成\n",
    "x = torch.rand(20, 1) * 10\n",
    "y = 2 * x + (5 + torch.randn(20, 1))\n",
    "\n",
    "# 构建线性回归函数的参数\n",
    "w = torch.randn((1), requires_grad=True)\n",
    "b = torch.zeros((1), requires_grad=True)   # 这俩都需要求梯度\n",
    "\n",
    "# 设置学习率lr为0.1\n",
    "lr = 0.1\n",
    "\n",
    "for iteration in range(100):\n",
    "    # 前向传播\n",
    "    wx = torch.mul(w, x) #将两张量中元素\n",
    "    y_pred = torch.add(wx, b)\n",
    "\n",
    "    \n",
    "    # 计算loss\n",
    "    loss = (0.5 * (y-y_pred)**2).mean()\n",
    "    print(\"*\"*60)\n",
    "    print(f\"第{iteration}次反向传播前的梯度为:\")\n",
    "    try:\n",
    "        print(w.grad.data,b.grad.data)\n",
    "    except :\n",
    "        print(\"梯度不存在\")\n",
    "    # 反向传播\n",
    "    loss.backward()\n",
    "    print(f\"第{iteration}次反向传播后的梯度为:\")\n",
    "    print(w.grad.data,b.grad.data)\n",
    "    print(\"*\"*60)\n",
    "    # 更新参数\n",
    "    b.data.sub_(lr * b.grad)    # 这种_的加法操作时从自身减，相当于-=\n",
    "    w.data.sub_(lr * w.grad)\n",
    "\n",
    "    # 梯度清零\n",
    "    w.grad.data.zero_()\n",
    "    b.grad.data.zero_()\n",
    "\n",
    "print(w.data, b.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，参数在经过反向传播后获得了梯度。\n",
    "但是有个问题，torch是怎么知道该计算谁的梯度呢\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过查询资料可以得知，torch.backward()默认情况下只累积叶子节点张量的梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x is leaf: True\n",
      "y is leaf: True\n",
      "w is leaf: True\n",
      "b is leaf: True\n",
      "wx is leaf: False\n",
      "y_pred is leaf: False\n"
     ]
    }
   ],
   "source": [
    "# 首先我们得有训练样本X，Y， 这里我们随机生成\n",
    "x = torch.rand(20, 1) * 10\n",
    "y = 2 * x + (5 + torch.randn(20, 1))\n",
    "\n",
    "# 构建线性回归函数的参数\n",
    "w = torch.randn((1), requires_grad=True)\n",
    "b = torch.zeros((1), requires_grad=True)   # 这俩都需要求梯度\n",
    "wx = torch.mul(w, x) #将两张量中元素\n",
    "y_pred = torch.add(wx, b)\n",
    "\n",
    "print(\"x is leaf:\",x.is_leaf)\n",
    "print(\"y is leaf:\",y.is_leaf)\n",
    "print(\"w is leaf:\",w.is_leaf)\n",
    "print(\"b is leaf:\",b.is_leaf)\n",
    "print(\"wx is leaf:\",wx.is_leaf)\n",
    "print(\"y_pred is leaf:\",y_pred.is_leaf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那是不是意味着x,y同样也获得了梯度呢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "第0次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第0次反向传播后的梯度为:\n",
      "tensor([-193.3717]) tensor([-28.7433])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\envs\\d2l\\lib\\site-packages\\torch\\_tensor.py:1104: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\build\\aten\\src\\ATen/core/TensorBody.h:475.)\n",
      "  return self._grad\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\WINDOWS\\TEMP/ipykernel_20472/2321206500.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"第{iteration}次反向传播后的梯度为:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"*\"\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;31m# 更新参数\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "# 首先我们得有训练样本X，Y， 这里我们随机生成\n",
    "x = torch.rand(20, 1) * 10\n",
    "y = 2 * x + (5 + torch.randn(20, 1))\n",
    "\n",
    "# 构建线性回归函数的参数\n",
    "w = torch.randn((1), requires_grad=True)\n",
    "b = torch.zeros((1), requires_grad=True)   # 这俩都需要求梯度\n",
    "\n",
    "# 设置学习率lr为0.1\n",
    "lr = 0.1\n",
    "\n",
    "for iteration in range(100):\n",
    "    # 前向传播\n",
    "    wx = torch.mul(w, x) #将两张量中元素\n",
    "    y_pred = torch.add(wx, b)\n",
    "\n",
    "    \n",
    "    # 计算loss\n",
    "    loss = (0.5 * (y-y_pred)**2).mean()\n",
    "    print(\"*\"*60)\n",
    "    print(f\"第{iteration}次反向传播前的梯度为:\")\n",
    "    try:\n",
    "        print(w.grad.data,b.grad.data,x.grad.data,y.grad.data)\n",
    "    except :\n",
    "        print(\"梯度不存在\")\n",
    "    # 反向传播\n",
    "    loss.backward()\n",
    "    print(f\"第{iteration}次反向传播后的梯度为:\")\n",
    "    print(w.grad.data,b.grad.data)\n",
    "    print(x.grad.data,y.grad.data)\n",
    "    print(\"*\"*60)\n",
    "    # 更新参数\n",
    "    b.data.sub_(lr * b.grad)    # 这种_的加法操作时从自身减，相当于-=\n",
    "    w.data.sub_(lr * w.grad)\n",
    "\n",
    "    # 梯度清零\n",
    "    w.grad.data.zero_()\n",
    "    b.grad.data.zero_()\n",
    "\n",
    "print(w.data, b.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "显然不太行，发现w,b后面有requires_grad，那如果去掉是不是连w,b也没法求梯度了呢？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "第0次反向传播前的梯度为:\n",
      "梯度不存在\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mC:\\WINDOWS\\TEMP/ipykernel_20472/3540320366.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"梯度不存在\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m# 反向传播\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"第{iteration}次反向传播后的梯度为:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\conda\\envs\\d2l\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\conda\\envs\\d2l\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "# 首先我们得有训练样本X，Y， 这里我们随机生成\n",
    "x = torch.rand(20, 1) * 10\n",
    "y = 2 * x + (5 + torch.randn(20, 1))\n",
    "\n",
    "# 构建线性回归函数的参数\n",
    "w = torch.randn((1), requires_grad=False)\n",
    "b = torch.zeros((1), requires_grad=False)   # 这俩都需要求梯度\n",
    "\n",
    "# 设置学习率lr为0.1\n",
    "lr = 0.1\n",
    "\n",
    "for iteration in range(100):\n",
    "    # 前向传播\n",
    "    wx = torch.mul(w, x) #将两张量中元素\n",
    "    y_pred = torch.add(wx, b)\n",
    "\n",
    "    \n",
    "    # 计算loss\n",
    "    loss = (0.5 * (y-y_pred)**2).mean()\n",
    "    print(\"*\"*60)\n",
    "    print(f\"第{iteration}次反向传播前的梯度为:\")\n",
    "    try:\n",
    "        print(w.grad.data,b.grad.data,x.grad.data,y.grad.data)\n",
    "    except :\n",
    "        print(\"梯度不存在\")\n",
    "    # 反向传播\n",
    "    loss.backward()\n",
    "    print(f\"第{iteration}次反向传播后的梯度为:\")\n",
    "    print(w.grad.data,b.grad.data)\n",
    "    print(x.grad.data,y.grad.data)\n",
    "    print(\"*\"*60)\n",
    "    # 更新参数\n",
    "    b.data.sub_(lr * b.grad)    # 这种_的加法操作时从自身减，相当于-=\n",
    "    w.data.sub_(lr * w.grad)\n",
    "\n",
    "    # 梯度清零\n",
    "    w.grad.data.zero_()\n",
    "    b.grad.data.zero_()\n",
    "\n",
    "print(w.data, b.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "确实，那么如果我们为x,y也加入requires_grad=True ，那是不是意味着x,y同样也能获取梯度呢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "第0次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第0次反向传播后的梯度为:\n",
      "tensor([-3.5335]) tensor([-6.6732])\n",
      "************************************************************\n",
      "************************************************************\n",
      "第1次反向传播前的梯度为:\n",
      "tensor([0.]) tensor([0.])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mC:\\WINDOWS\\TEMP/ipykernel_20472/639501818.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"梯度不存在\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m# 反向传播\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"第{iteration}次反向传播后的梯度为:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\conda\\envs\\d2l\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\conda\\envs\\d2l\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "# 首先我们得有训练样本X，Y， 这里我们随机生成\n",
    "x = torch.rand(20, 1, requires_grad=True)\n",
    "y = 2 * x + (5 + torch.randn(20, 1, requires_grad=True))\n",
    "\n",
    "# 构建线性回归函数的参数\n",
    "w = torch.randn((1), requires_grad=True)\n",
    "b = torch.zeros((1), requires_grad=True)   # 这俩都需要求梯度\n",
    "\n",
    "# 设置学习率lr为0.1\n",
    "lr = 0.1\n",
    "\n",
    "for iteration in range(100):\n",
    "    # 前向传播\n",
    "    wx = torch.mul(w, x) #将两张量中元素\n",
    "    y_pred = torch.add(wx, b)\n",
    "\n",
    "    \n",
    "    # 计算loss\n",
    "    loss = (0.5 * (y-y_pred)**2).mean()\n",
    "    print(\"*\"*60)\n",
    "    print(f\"第{iteration}次反向传播前的梯度为:\")\n",
    "    try:\n",
    "        print(w.grad.data,b.grad.data)\n",
    "    except :\n",
    "        print(\"梯度不存在\")\n",
    "    # 反向传播\n",
    "    loss.backward()\n",
    "    print(f\"第{iteration}次反向传播后的梯度为:\")\n",
    "    print(w.grad.data,b.grad.data)\n",
    "    print(\"*\"*60)\n",
    "    # 更新参数\n",
    "    b.data.sub_(lr * b.grad)    # 这种_的加法操作时从自身减，相当于-=\n",
    "    w.data.sub_(lr * w.grad)\n",
    "\n",
    "    # 梯度清零\n",
    "    w.grad.data.zero_()\n",
    "    b.grad.data.zero_()\n",
    "\n",
    "print(w.data, b.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "出现了些奇怪的错误，报错的意思就是，因为某个带有梯度信息的变量在被执行了一次后，这些梯度信息就被计算图释放掉了，而我们的代码却尝试第二次反向传播的时候来访问这些变量(梯度信息)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在查询资料后发现在backward后添加retain_graph=True就可以在每次反向传播后暂时保留中间节点的梯度值，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "第0次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第0次反向传播后的梯度为:\n",
      "tensor([-2.2859]) tensor([-5.9602]) tensor([[0.3021],\n",
      "        [0.3650],\n",
      "        [0.3853],\n",
      "        [0.3502],\n",
      "        [0.4887],\n",
      "        [0.4344],\n",
      "        [0.4268],\n",
      "        [0.4804],\n",
      "        [0.4478],\n",
      "        [0.4632],\n",
      "        [0.3373],\n",
      "        [0.3467],\n",
      "        [0.4078],\n",
      "        [0.4276],\n",
      "        [0.3957],\n",
      "        [0.2453],\n",
      "        [0.3994],\n",
      "        [0.4038],\n",
      "        [0.4239],\n",
      "        [0.2832]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第1次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第1次反向传播后的梯度为:\n",
      "tensor([-2.0005]) tensor([-5.2769]) tensor([[0.5181],\n",
      "        [0.6329],\n",
      "        [0.6611],\n",
      "        [0.6051],\n",
      "        [0.8593],\n",
      "        [0.7505],\n",
      "        [0.7449],\n",
      "        [0.8326],\n",
      "        [0.7834],\n",
      "        [0.8032],\n",
      "        [0.5752],\n",
      "        [0.5979],\n",
      "        [0.7056],\n",
      "        [0.7420],\n",
      "        [0.6898],\n",
      "        [0.4048],\n",
      "        [0.6960],\n",
      "        [0.7019],\n",
      "        [0.7414],\n",
      "        [0.4813]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第2次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第2次反向传播后的梯度为:\n",
      "tensor([-1.7484]) tensor([-4.6728]) tensor([[0.6700],\n",
      "        [0.8270],\n",
      "        [0.8553],\n",
      "        [0.7883],\n",
      "        [1.1377],\n",
      "        [0.9776],\n",
      "        [0.9795],\n",
      "        [1.0877],\n",
      "        [1.0323],\n",
      "        [1.0497],\n",
      "        [0.7398],\n",
      "        [0.7774],\n",
      "        [0.9203],\n",
      "        [0.9705],\n",
      "        [0.9059],\n",
      "        [0.5039],\n",
      "        [0.9139],\n",
      "        [0.9194],\n",
      "        [0.9768],\n",
      "        [0.6172]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第3次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第3次反向传播后的梯度为:\n",
      "tensor([-1.5257]) tensor([-4.1388]) tensor([[0.7746],\n",
      "        [0.9655],\n",
      "        [0.9895],\n",
      "        [0.9178],\n",
      "        [1.3442],\n",
      "        [1.1380],\n",
      "        [1.1501],\n",
      "        [1.2695],\n",
      "        [1.2144],\n",
      "        [1.2258],\n",
      "        [0.8511],\n",
      "        [0.9035],\n",
      "        [1.0727],\n",
      "        [1.1341],\n",
      "        [1.0626],\n",
      "        [0.5615],\n",
      "        [1.0716],\n",
      "        [1.0758],\n",
      "        [1.1489],\n",
      "        [0.7080]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第4次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第4次反向传播后的梯度为:\n",
      "tensor([-1.3290]) tensor([-3.6666]) tensor([[0.8448],\n",
      "        [1.0623],\n",
      "        [1.0798],\n",
      "        [1.0071],\n",
      "        [1.4944],\n",
      "        [1.2489],\n",
      "        [1.2718],\n",
      "        [1.3965],\n",
      "        [1.3451],\n",
      "        [1.3489],\n",
      "        [0.9241],\n",
      "        [0.9899],\n",
      "        [1.1785],\n",
      "        [1.2487],\n",
      "        [1.1738],\n",
      "        [0.5916],\n",
      "        [1.1836],\n",
      "        [1.1860],\n",
      "        [1.2723],\n",
      "        [0.7666]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第5次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第5次反向传播后的梯度为:\n",
      "tensor([-1.1554]) tensor([-3.2492]) tensor([[0.8902],\n",
      "        [1.1278],\n",
      "        [1.1384],\n",
      "        [1.0669],\n",
      "        [1.6008],\n",
      "        [1.3231],\n",
      "        [1.3561],\n",
      "        [1.4826],\n",
      "        [1.4364],\n",
      "        [1.4324],\n",
      "        [0.9699],\n",
      "        [1.0472],\n",
      "        [1.2497],\n",
      "        [1.3267],\n",
      "        [1.2506],\n",
      "        [0.6042],\n",
      "        [1.2607],\n",
      "        [1.2614],\n",
      "        [1.3583],\n",
      "        [0.8027]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第6次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第6次反向传播后的梯度为:\n",
      "tensor([-1.0020]) tensor([-2.8802]) tensor([[0.9179],\n",
      "        [1.1702],\n",
      "        [1.1745],\n",
      "        [1.1051],\n",
      "        [1.6730],\n",
      "        [1.3706],\n",
      "        [1.4120],\n",
      "        [1.5384],\n",
      "        [1.4974],\n",
      "        [1.4867],\n",
      "        [0.9970],\n",
      "        [1.0835],\n",
      "        [1.2955],\n",
      "        [1.3775],\n",
      "        [1.3013],\n",
      "        [0.6069],\n",
      "        [1.3117],\n",
      "        [1.3107],\n",
      "        [1.4158],\n",
      "        [0.8234]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第7次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第7次反向传播后的梯度为:\n",
      "tensor([-0.8667]) tensor([-2.5539]) tensor([[0.9336],\n",
      "        [1.1957],\n",
      "        [1.1951],\n",
      "        [1.1277],\n",
      "        [1.7186],\n",
      "        [1.3987],\n",
      "        [1.4466],\n",
      "        [1.5719],\n",
      "        [1.5354],\n",
      "        [1.5194],\n",
      "        [1.0116],\n",
      "        [1.1047],\n",
      "        [1.3229],\n",
      "        [1.4081],\n",
      "        [1.3325],\n",
      "        [0.6049],\n",
      "        [1.3430],\n",
      "        [1.3407],\n",
      "        [1.4515],\n",
      "        [0.8341]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第8次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第8次反向传播后的梯度为:\n",
      "tensor([-0.7472]) tensor([-2.2654]) tensor([[0.9411],\n",
      "        [1.2089],\n",
      "        [1.2050],\n",
      "        [1.1392],\n",
      "        [1.7435],\n",
      "        [1.4131],\n",
      "        [1.4650],\n",
      "        [1.5893],\n",
      "        [1.5558],\n",
      "        [1.5364],\n",
      "        [1.0182],\n",
      "        [1.1153],\n",
      "        [1.3369],\n",
      "        [1.4241],\n",
      "        [1.3490],\n",
      "        [0.6017],\n",
      "        [1.3595],\n",
      "        [1.3564],\n",
      "        [1.4707],\n",
      "        [0.8386]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第9次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第9次反向传播后的梯度为:\n",
      "tensor([-0.6418]) tensor([-2.0104]) tensor([[0.9433],\n",
      "        [1.2134],\n",
      "        [1.2081],\n",
      "        [1.1430],\n",
      "        [1.7524],\n",
      "        [1.4178],\n",
      "        [1.4714],\n",
      "        [1.5952],\n",
      "        [1.5630],\n",
      "        [1.5421],\n",
      "        [1.0200],\n",
      "        [1.1188],\n",
      "        [1.3416],\n",
      "        [1.4295],\n",
      "        [1.3547],\n",
      "        [0.5999],\n",
      "        [1.3652],\n",
      "        [1.3618],\n",
      "        [1.4774],\n",
      "        [0.8398]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第10次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第10次反向传播后的梯度为:\n",
      "tensor([-0.5488]) tensor([-1.7848]) tensor([[0.9426],\n",
      "        [1.2117],\n",
      "        [1.2070],\n",
      "        [1.1416],\n",
      "        [1.7488],\n",
      "        [1.4161],\n",
      "        [1.4689],\n",
      "        [1.5930],\n",
      "        [1.5601],\n",
      "        [1.5399],\n",
      "        [1.0195],\n",
      "        [1.1175],\n",
      "        [1.3398],\n",
      "        [1.4275],\n",
      "        [1.3525],\n",
      "        [0.6009],\n",
      "        [1.3630],\n",
      "        [1.3597],\n",
      "        [1.4748],\n",
      "        [0.8395]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第11次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第11次反向传播后的梯度为:\n",
      "tensor([-0.4668]) tensor([-1.5854]) tensor([[0.9403],\n",
      "        [1.2058],\n",
      "        [1.2037],\n",
      "        [1.1368],\n",
      "        [1.7357],\n",
      "        [1.4100],\n",
      "        [1.4599],\n",
      "        [1.5851],\n",
      "        [1.5499],\n",
      "        [1.5323],\n",
      "        [1.0181],\n",
      "        [1.1133],\n",
      "        [1.3338],\n",
      "        [1.4202],\n",
      "        [1.3446],\n",
      "        [0.6057],\n",
      "        [1.3551],\n",
      "        [1.3524],\n",
      "        [1.4652],\n",
      "        [0.8391]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第12次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第12次反向传播后的梯度为:\n",
      "tensor([-0.3944]) tensor([-1.4090]) tensor([[0.9375],\n",
      "        [1.1973],\n",
      "        [1.1995],\n",
      "        [1.1301],\n",
      "        [1.7153],\n",
      "        [1.4014],\n",
      "        [1.4461],\n",
      "        [1.5736],\n",
      "        [1.5341],\n",
      "        [1.5209],\n",
      "        [1.0171],\n",
      "        [1.1076],\n",
      "        [1.3250],\n",
      "        [1.4094],\n",
      "        [1.3326],\n",
      "        [0.6148],\n",
      "        [1.3431],\n",
      "        [1.3415],\n",
      "        [1.4505],\n",
      "        [0.8396]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第13次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第13次反向传播后的梯度为:\n",
      "tensor([-0.3306]) tensor([-1.2531]) tensor([[0.9349],\n",
      "        [1.1871],\n",
      "        [1.1953],\n",
      "        [1.1223],\n",
      "        [1.6894],\n",
      "        [1.3913],\n",
      "        [1.4291],\n",
      "        [1.5598],\n",
      "        [1.5144],\n",
      "        [1.5073],\n",
      "        [1.0171],\n",
      "        [1.1011],\n",
      "        [1.3147],\n",
      "        [1.3964],\n",
      "        [1.3178],\n",
      "        [0.6282],\n",
      "        [1.3283],\n",
      "        [1.3283],\n",
      "        [1.4321],\n",
      "        [0.8413]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第14次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第14次反向传播后的梯度为:\n",
      "tensor([-0.2744]) tensor([-1.1151]) tensor([[0.9331],\n",
      "        [1.1761],\n",
      "        [1.1917],\n",
      "        [1.1142],\n",
      "        [1.6593],\n",
      "        [1.3806],\n",
      "        [1.4098],\n",
      "        [1.5447],\n",
      "        [1.4919],\n",
      "        [1.4923],\n",
      "        [1.0185],\n",
      "        [1.0945],\n",
      "        [1.3036],\n",
      "        [1.3821],\n",
      "        [1.3011],\n",
      "        [0.6459],\n",
      "        [1.3118],\n",
      "        [1.3136],\n",
      "        [1.4112],\n",
      "        [0.8448]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第15次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第15次反向传播后的梯度为:\n",
      "tensor([-0.2249]) tensor([-0.9932]) tensor([[0.9323],\n",
      "        [1.1647],\n",
      "        [1.1890],\n",
      "        [1.1062],\n",
      "        [1.6262],\n",
      "        [1.3699],\n",
      "        [1.3891],\n",
      "        [1.5289],\n",
      "        [1.4675],\n",
      "        [1.4767],\n",
      "        [1.0215],\n",
      "        [1.0883],\n",
      "        [1.2923],\n",
      "        [1.3672],\n",
      "        [1.2834],\n",
      "        [0.6676],\n",
      "        [1.2942],\n",
      "        [1.2981],\n",
      "        [1.3886],\n",
      "        [0.8500]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第16次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第16次反向传播后的梯度为:\n",
      "tensor([-0.1813]) tensor([-0.8853]) tensor([[0.9326],\n",
      "        [1.1535],\n",
      "        [1.1876],\n",
      "        [1.0987],\n",
      "        [1.5909],\n",
      "        [1.3595],\n",
      "        [1.3675],\n",
      "        [1.5130],\n",
      "        [1.4418],\n",
      "        [1.4609],\n",
      "        [1.0262],\n",
      "        [1.0828],\n",
      "        [1.2813],\n",
      "        [1.3521],\n",
      "        [1.2651],\n",
      "        [0.6929],\n",
      "        [1.2759],\n",
      "        [1.2823],\n",
      "        [1.3648],\n",
      "        [0.8571]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第17次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第17次反向传播后的梯度为:\n",
      "tensor([-0.1429]) tensor([-0.7898]) tensor([[0.9342],\n",
      "        [1.1425],\n",
      "        [1.1873],\n",
      "        [1.0918],\n",
      "        [1.5542],\n",
      "        [1.3496],\n",
      "        [1.3455],\n",
      "        [1.4973],\n",
      "        [1.4154],\n",
      "        [1.4453],\n",
      "        [1.0326],\n",
      "        [1.0780],\n",
      "        [1.2707],\n",
      "        [1.3371],\n",
      "        [1.2465],\n",
      "        [0.7215],\n",
      "        [1.2575],\n",
      "        [1.2666],\n",
      "        [1.3404],\n",
      "        [0.8659]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第18次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第18次反向传播后的梯度为:\n",
      "tensor([-0.1091]) tensor([-0.7054]) tensor([[0.9369],\n",
      "        [1.1321],\n",
      "        [1.1883],\n",
      "        [1.0856],\n",
      "        [1.5166],\n",
      "        [1.3405],\n",
      "        [1.3234],\n",
      "        [1.4820],\n",
      "        [1.3887],\n",
      "        [1.4301],\n",
      "        [1.0406],\n",
      "        [1.0741],\n",
      "        [1.2607],\n",
      "        [1.3225],\n",
      "        [1.2281],\n",
      "        [0.7530],\n",
      "        [1.2392],\n",
      "        [1.2511],\n",
      "        [1.3158],\n",
      "        [0.8764]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第19次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第19次反向传播后的梯度为:\n",
      "tensor([-0.0794]) tensor([-0.6307]) tensor([[0.9408],\n",
      "        [1.1223],\n",
      "        [1.1905],\n",
      "        [1.0802],\n",
      "        [1.4785],\n",
      "        [1.3322],\n",
      "        [1.3015],\n",
      "        [1.4673],\n",
      "        [1.3619],\n",
      "        [1.4154],\n",
      "        [1.0500],\n",
      "        [1.0712],\n",
      "        [1.2514],\n",
      "        [1.3084],\n",
      "        [1.2099],\n",
      "        [0.7868],\n",
      "        [1.2212],\n",
      "        [1.2361],\n",
      "        [1.2913],\n",
      "        [0.8883]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第20次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第20次反向传播后的梯度为:\n",
      "tensor([-0.0533]) tensor([-0.5646]) tensor([[0.9457],\n",
      "        [1.1132],\n",
      "        [1.1938],\n",
      "        [1.0756],\n",
      "        [1.4403],\n",
      "        [1.3247],\n",
      "        [1.2799],\n",
      "        [1.4532],\n",
      "        [1.3354],\n",
      "        [1.4013],\n",
      "        [1.0606],\n",
      "        [1.0690],\n",
      "        [1.2429],\n",
      "        [1.2949],\n",
      "        [1.1922],\n",
      "        [0.8225],\n",
      "        [1.2037],\n",
      "        [1.2216],\n",
      "        [1.2669],\n",
      "        [0.9014]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第21次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第21次反向传播后的梯度为:\n",
      "tensor([-0.0304]) tensor([-0.5061]) tensor([[0.9516],\n",
      "        [1.1048],\n",
      "        [1.1980],\n",
      "        [1.0718],\n",
      "        [1.4022],\n",
      "        [1.3179],\n",
      "        [1.2588],\n",
      "        [1.4398],\n",
      "        [1.3092],\n",
      "        [1.3879],\n",
      "        [1.0724],\n",
      "        [1.0678],\n",
      "        [1.2351],\n",
      "        [1.2821],\n",
      "        [1.1750],\n",
      "        [0.8599],\n",
      "        [1.1866],\n",
      "        [1.2077],\n",
      "        [1.2430],\n",
      "        [0.9157]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第22次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第22次反向传播后的梯度为:\n",
      "tensor([-0.0103]) tensor([-0.4543]) tensor([[0.9582],\n",
      "        [1.0970],\n",
      "        [1.2031],\n",
      "        [1.0687],\n",
      "        [1.3645],\n",
      "        [1.3119],\n",
      "        [1.2382],\n",
      "        [1.4271],\n",
      "        [1.2836],\n",
      "        [1.3752],\n",
      "        [1.0850],\n",
      "        [1.0672],\n",
      "        [1.2280],\n",
      "        [1.2699],\n",
      "        [1.1583],\n",
      "        [0.8984],\n",
      "        [1.1702],\n",
      "        [1.1944],\n",
      "        [1.2197],\n",
      "        [0.9310]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第23次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第23次反向传播后的梯度为:\n",
      "tensor([0.0073]) tensor([-0.4085]) tensor([[0.9657],\n",
      "        [1.0899],\n",
      "        [1.2089],\n",
      "        [1.0663],\n",
      "        [1.3274],\n",
      "        [1.3066],\n",
      "        [1.2183],\n",
      "        [1.4150],\n",
      "        [1.2585],\n",
      "        [1.3631],\n",
      "        [1.0985],\n",
      "        [1.0674],\n",
      "        [1.2215],\n",
      "        [1.2583],\n",
      "        [1.1423],\n",
      "        [0.9378],\n",
      "        [1.1544],\n",
      "        [1.1818],\n",
      "        [1.1969],\n",
      "        [0.9469]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第24次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第24次反向传播后的梯度为:\n",
      "tensor([0.0227]) tensor([-0.3679]) tensor([[0.9737],\n",
      "        [1.0835],\n",
      "        [1.2153],\n",
      "        [1.0645],\n",
      "        [1.2910],\n",
      "        [1.3019],\n",
      "        [1.1990],\n",
      "        [1.4036],\n",
      "        [1.2342],\n",
      "        [1.3517],\n",
      "        [1.1124],\n",
      "        [1.0682],\n",
      "        [1.2157],\n",
      "        [1.2474],\n",
      "        [1.1270],\n",
      "        [0.9776],\n",
      "        [1.1392],\n",
      "        [1.1699],\n",
      "        [1.1748],\n",
      "        [0.9635]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第25次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第25次反向传播后的梯度为:\n",
      "tensor([0.0362]) tensor([-0.3320]) tensor([[0.9821],\n",
      "        [1.0776],\n",
      "        [1.2221],\n",
      "        [1.0633],\n",
      "        [1.2554],\n",
      "        [1.2977],\n",
      "        [1.1804],\n",
      "        [1.3927],\n",
      "        [1.2105],\n",
      "        [1.3408],\n",
      "        [1.1269],\n",
      "        [1.0695],\n",
      "        [1.2105],\n",
      "        [1.2372],\n",
      "        [1.1123],\n",
      "        [1.0178],\n",
      "        [1.1247],\n",
      "        [1.1585],\n",
      "        [1.1534],\n",
      "        [0.9804]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第26次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第26次反向传播后的梯度为:\n",
      "tensor([0.0479]) tensor([-0.3002]) tensor([[0.9910],\n",
      "        [1.0723],\n",
      "        [1.2294],\n",
      "        [1.0626],\n",
      "        [1.2208],\n",
      "        [1.2941],\n",
      "        [1.1625],\n",
      "        [1.3825],\n",
      "        [1.1876],\n",
      "        [1.3306],\n",
      "        [1.1416],\n",
      "        [1.0713],\n",
      "        [1.2058],\n",
      "        [1.2275],\n",
      "        [1.0983],\n",
      "        [1.0578],\n",
      "        [1.1109],\n",
      "        [1.1478],\n",
      "        [1.1328],\n",
      "        [0.9977]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第27次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第27次反向传播后的梯度为:\n",
      "tensor([0.0582]) tensor([-0.2720]) tensor([[1.0002],\n",
      "        [1.0675],\n",
      "        [1.2369],\n",
      "        [1.0623],\n",
      "        [1.1871],\n",
      "        [1.2909],\n",
      "        [1.1454],\n",
      "        [1.3728],\n",
      "        [1.1656],\n",
      "        [1.3209],\n",
      "        [1.1564],\n",
      "        [1.0735],\n",
      "        [1.2016],\n",
      "        [1.2184],\n",
      "        [1.0850],\n",
      "        [1.0976],\n",
      "        [1.0978],\n",
      "        [1.1377],\n",
      "        [1.1129],\n",
      "        [1.0151]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第28次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第28次反向传播后的梯度为:\n",
      "tensor([0.0671]) tensor([-0.2470]) tensor([[1.0096],\n",
      "        [1.0632],\n",
      "        [1.2446],\n",
      "        [1.0624],\n",
      "        [1.1545],\n",
      "        [1.2880],\n",
      "        [1.1289],\n",
      "        [1.3635],\n",
      "        [1.1443],\n",
      "        [1.3117],\n",
      "        [1.1713],\n",
      "        [1.0760],\n",
      "        [1.1978],\n",
      "        [1.2098],\n",
      "        [1.0723],\n",
      "        [1.1369],\n",
      "        [1.0852],\n",
      "        [1.1282],\n",
      "        [1.0938],\n",
      "        [1.0325]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第29次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第29次反向传播后的梯度为:\n",
      "tensor([0.0748]) tensor([-0.2249]) tensor([[1.0190],\n",
      "        [1.0593],\n",
      "        [1.2523],\n",
      "        [1.0629],\n",
      "        [1.1230],\n",
      "        [1.2855],\n",
      "        [1.1132],\n",
      "        [1.3548],\n",
      "        [1.1239],\n",
      "        [1.3030],\n",
      "        [1.1861],\n",
      "        [1.0788],\n",
      "        [1.1944],\n",
      "        [1.2017],\n",
      "        [1.0603],\n",
      "        [1.1756],\n",
      "        [1.0734],\n",
      "        [1.1192],\n",
      "        [1.0755],\n",
      "        [1.0498]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第30次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第30次反向传播后的梯度为:\n",
      "tensor([0.0815]) tensor([-0.2052]) tensor([[1.0286],\n",
      "        [1.0559],\n",
      "        [1.2601],\n",
      "        [1.0636],\n",
      "        [1.0926],\n",
      "        [1.2833],\n",
      "        [1.0982],\n",
      "        [1.3465],\n",
      "        [1.1043],\n",
      "        [1.2948],\n",
      "        [1.2008],\n",
      "        [1.0818],\n",
      "        [1.1913],\n",
      "        [1.1940],\n",
      "        [1.0489],\n",
      "        [1.2135],\n",
      "        [1.0621],\n",
      "        [1.1107],\n",
      "        [1.0580],\n",
      "        [1.0669]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第31次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第31次反向传播后的梯度为:\n",
      "tensor([0.0873]) tensor([-0.1878]) tensor([[1.0381],\n",
      "        [1.0528],\n",
      "        [1.2678],\n",
      "        [1.0645],\n",
      "        [1.0634],\n",
      "        [1.2814],\n",
      "        [1.0838],\n",
      "        [1.3386],\n",
      "        [1.0855],\n",
      "        [1.2869],\n",
      "        [1.2152],\n",
      "        [1.0849],\n",
      "        [1.1886],\n",
      "        [1.1869],\n",
      "        [1.0381],\n",
      "        [1.2504],\n",
      "        [1.0514],\n",
      "        [1.1027],\n",
      "        [1.0413],\n",
      "        [1.0838]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第32次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第32次反向传播后的梯度为:\n",
      "tensor([0.0922]) tensor([-0.1724]) tensor([[1.0475],\n",
      "        [1.0500],\n",
      "        [1.2755],\n",
      "        [1.0657],\n",
      "        [1.0354],\n",
      "        [1.2796],\n",
      "        [1.0702],\n",
      "        [1.3311],\n",
      "        [1.0676],\n",
      "        [1.2795],\n",
      "        [1.2294],\n",
      "        [1.0882],\n",
      "        [1.1861],\n",
      "        [1.1801],\n",
      "        [1.0278],\n",
      "        [1.2862],\n",
      "        [1.0413],\n",
      "        [1.0952],\n",
      "        [1.0254],\n",
      "        [1.1003]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第33次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第33次反向传播后的梯度为:\n",
      "tensor([0.0965]) tensor([-0.1587]) tensor([[1.0568],\n",
      "        [1.0475],\n",
      "        [1.2829],\n",
      "        [1.0670],\n",
      "        [1.0086],\n",
      "        [1.2781],\n",
      "        [1.0573],\n",
      "        [1.3239],\n",
      "        [1.0505],\n",
      "        [1.2725],\n",
      "        [1.2431],\n",
      "        [1.0915],\n",
      "        [1.1838],\n",
      "        [1.1737],\n",
      "        [1.0182],\n",
      "        [1.3208],\n",
      "        [1.0318],\n",
      "        [1.0882],\n",
      "        [1.0103],\n",
      "        [1.1164]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第34次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第34次反向传播后的梯度为:\n",
      "tensor([0.1001]) tensor([-0.1465]) tensor([[1.0659],\n",
      "        [1.0453],\n",
      "        [1.2902],\n",
      "        [1.0684],\n",
      "        [0.9831],\n",
      "        [1.2766],\n",
      "        [1.0450],\n",
      "        [1.3171],\n",
      "        [1.0343],\n",
      "        [1.2658],\n",
      "        [1.2564],\n",
      "        [1.0948],\n",
      "        [1.1818],\n",
      "        [1.1677],\n",
      "        [1.0091],\n",
      "        [1.3542],\n",
      "        [1.0228],\n",
      "        [1.0816],\n",
      "        [0.9959],\n",
      "        [1.1320]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第35次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第35次反向传播后的梯度为:\n",
      "tensor([0.1031]) tensor([-0.1356]) tensor([[1.0747],\n",
      "        [1.0434],\n",
      "        [1.2972],\n",
      "        [1.0699],\n",
      "        [0.9588],\n",
      "        [1.2754],\n",
      "        [1.0334],\n",
      "        [1.3107],\n",
      "        [1.0189],\n",
      "        [1.2595],\n",
      "        [1.2693],\n",
      "        [1.0982],\n",
      "        [1.1800],\n",
      "        [1.1621],\n",
      "        [1.0006],\n",
      "        [1.3862],\n",
      "        [1.0144],\n",
      "        [1.0754],\n",
      "        [0.9824],\n",
      "        [1.1471]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第36次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第36次反向传播后的梯度为:\n",
      "tensor([0.1057]) tensor([-0.1260]) tensor([[1.0833],\n",
      "        [1.0416],\n",
      "        [1.3040],\n",
      "        [1.0715],\n",
      "        [0.9357],\n",
      "        [1.2742],\n",
      "        [1.0225],\n",
      "        [1.3046],\n",
      "        [1.0044],\n",
      "        [1.2536],\n",
      "        [1.2816],\n",
      "        [1.1015],\n",
      "        [1.1783],\n",
      "        [1.1568],\n",
      "        [0.9926],\n",
      "        [1.4169],\n",
      "        [1.0065],\n",
      "        [1.0696],\n",
      "        [0.9695],\n",
      "        [1.1617]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第37次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第37次反向传播后的梯度为:\n",
      "tensor([0.1078]) tensor([-0.1175]) tensor([[1.0916],\n",
      "        [1.0401],\n",
      "        [1.3105],\n",
      "        [1.0731],\n",
      "        [0.9139],\n",
      "        [1.2731],\n",
      "        [1.0122],\n",
      "        [1.2988],\n",
      "        [0.9906],\n",
      "        [1.2479],\n",
      "        [1.2934],\n",
      "        [1.1048],\n",
      "        [1.1768],\n",
      "        [1.1519],\n",
      "        [0.9851],\n",
      "        [1.4460],\n",
      "        [0.9991],\n",
      "        [1.0642],\n",
      "        [0.9575],\n",
      "        [1.1756]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第38次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第38次反向传播后的梯度为:\n",
      "tensor([0.1096]) tensor([-0.1098]) tensor([[1.0996],\n",
      "        [1.0388],\n",
      "        [1.3167],\n",
      "        [1.0747],\n",
      "        [0.8934],\n",
      "        [1.2721],\n",
      "        [1.0025],\n",
      "        [1.2933],\n",
      "        [0.9777],\n",
      "        [1.2426],\n",
      "        [1.3046],\n",
      "        [1.1080],\n",
      "        [1.1754],\n",
      "        [1.1473],\n",
      "        [0.9782],\n",
      "        [1.4737],\n",
      "        [0.9922],\n",
      "        [1.0592],\n",
      "        [0.9462],\n",
      "        [1.1889]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第39次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第39次反向传播后的梯度为:\n",
      "tensor([0.1110]) tensor([-0.1030]) tensor([[1.1072],\n",
      "        [1.0376],\n",
      "        [1.3225],\n",
      "        [1.0763],\n",
      "        [0.8741],\n",
      "        [1.2712],\n",
      "        [0.9935],\n",
      "        [1.2881],\n",
      "        [0.9656],\n",
      "        [1.2376],\n",
      "        [1.3152],\n",
      "        [1.1110],\n",
      "        [1.1742],\n",
      "        [1.1429],\n",
      "        [0.9717],\n",
      "        [1.4998],\n",
      "        [0.9858],\n",
      "        [1.0545],\n",
      "        [0.9356],\n",
      "        [1.2015]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第40次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第40次反向传播后的梯度为:\n",
      "tensor([0.1121]) tensor([-0.0970]) tensor([[1.1144],\n",
      "        [1.0365],\n",
      "        [1.3280],\n",
      "        [1.0779],\n",
      "        [0.8560],\n",
      "        [1.2704],\n",
      "        [0.9851],\n",
      "        [1.2833],\n",
      "        [0.9543],\n",
      "        [1.2329],\n",
      "        [1.3252],\n",
      "        [1.1140],\n",
      "        [1.1730],\n",
      "        [1.1389],\n",
      "        [0.9657],\n",
      "        [1.5243],\n",
      "        [0.9798],\n",
      "        [1.0502],\n",
      "        [0.9257],\n",
      "        [1.2134]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第41次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第41次反向传播后的梯度为:\n",
      "tensor([0.1130]) tensor([-0.0915]) tensor([[1.1212],\n",
      "        [1.0357],\n",
      "        [1.3331],\n",
      "        [1.0794],\n",
      "        [0.8392],\n",
      "        [1.2696],\n",
      "        [0.9773],\n",
      "        [1.2787],\n",
      "        [0.9438],\n",
      "        [1.2286],\n",
      "        [1.3345],\n",
      "        [1.1168],\n",
      "        [1.1720],\n",
      "        [1.1352],\n",
      "        [0.9601],\n",
      "        [1.5473],\n",
      "        [0.9743],\n",
      "        [1.0462],\n",
      "        [0.9166],\n",
      "        [1.2246]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第42次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第42次反向传播后的梯度为:\n",
      "tensor([0.1136]) tensor([-0.0867]) tensor([[1.1276],\n",
      "        [1.0349],\n",
      "        [1.3379],\n",
      "        [1.0809],\n",
      "        [0.8236],\n",
      "        [1.2688],\n",
      "        [0.9701],\n",
      "        [1.2744],\n",
      "        [0.9341],\n",
      "        [1.2245],\n",
      "        [1.3433],\n",
      "        [1.1195],\n",
      "        [1.1710],\n",
      "        [1.1317],\n",
      "        [0.9550],\n",
      "        [1.5687],\n",
      "        [0.9693],\n",
      "        [1.0425],\n",
      "        [0.9081],\n",
      "        [1.2350]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第43次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第43次反向传播后的梯度为:\n",
      "tensor([0.1141]) tensor([-0.0824]) tensor([[1.1336],\n",
      "        [1.0342],\n",
      "        [1.3423],\n",
      "        [1.0823],\n",
      "        [0.8093],\n",
      "        [1.2682],\n",
      "        [0.9635],\n",
      "        [1.2705],\n",
      "        [0.9251],\n",
      "        [1.2207],\n",
      "        [1.3513],\n",
      "        [1.1220],\n",
      "        [1.1702],\n",
      "        [1.1286],\n",
      "        [0.9504],\n",
      "        [1.5884],\n",
      "        [0.9647],\n",
      "        [1.0392],\n",
      "        [0.9004],\n",
      "        [1.2447]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第44次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第44次反向传播后的梯度为:\n",
      "tensor([0.1143]) tensor([-0.0785]) tensor([[1.1391],\n",
      "        [1.0337],\n",
      "        [1.3464],\n",
      "        [1.0837],\n",
      "        [0.7962],\n",
      "        [1.2675],\n",
      "        [0.9575],\n",
      "        [1.2668],\n",
      "        [0.9170],\n",
      "        [1.2173],\n",
      "        [1.3587],\n",
      "        [1.1244],\n",
      "        [1.1694],\n",
      "        [1.1257],\n",
      "        [0.9462],\n",
      "        [1.6065],\n",
      "        [0.9605],\n",
      "        [1.0362],\n",
      "        [0.8933],\n",
      "        [1.2537]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第45次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第45次反向传播后的梯度为:\n",
      "tensor([0.1144]) tensor([-0.0750]) tensor([[1.1442],\n",
      "        [1.0332],\n",
      "        [1.3501],\n",
      "        [1.0850],\n",
      "        [0.7843],\n",
      "        [1.2669],\n",
      "        [0.9520],\n",
      "        [1.2635],\n",
      "        [0.9096],\n",
      "        [1.2141],\n",
      "        [1.3655],\n",
      "        [1.1266],\n",
      "        [1.1687],\n",
      "        [1.1231],\n",
      "        [0.9424],\n",
      "        [1.6229],\n",
      "        [0.9567],\n",
      "        [1.0334],\n",
      "        [0.8870],\n",
      "        [1.2618]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第46次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第46次反向传播后的梯度为:\n",
      "tensor([0.1144]) tensor([-0.0719]) tensor([[1.1488],\n",
      "        [1.0328],\n",
      "        [1.3534],\n",
      "        [1.0861],\n",
      "        [0.7736],\n",
      "        [1.2664],\n",
      "        [0.9471],\n",
      "        [1.2605],\n",
      "        [0.9029],\n",
      "        [1.2112],\n",
      "        [1.3716],\n",
      "        [1.1286],\n",
      "        [1.1681],\n",
      "        [1.1207],\n",
      "        [0.9390],\n",
      "        [1.6378],\n",
      "        [0.9534],\n",
      "        [1.0310],\n",
      "        [0.8813],\n",
      "        [1.2692]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第47次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第47次反向传播后的梯度为:\n",
      "tensor([0.1142]) tensor([-0.0691]) tensor([[1.1530],\n",
      "        [1.0325],\n",
      "        [1.3563],\n",
      "        [1.0872],\n",
      "        [0.7641],\n",
      "        [1.2659],\n",
      "        [0.9428],\n",
      "        [1.2577],\n",
      "        [0.8970],\n",
      "        [1.2087],\n",
      "        [1.3770],\n",
      "        [1.1303],\n",
      "        [1.1676],\n",
      "        [1.1186],\n",
      "        [0.9360],\n",
      "        [1.6510],\n",
      "        [0.9504],\n",
      "        [1.0288],\n",
      "        [0.8762],\n",
      "        [1.2758]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第48次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第48次反向传播后的梯度为:\n",
      "tensor([0.1140]) tensor([-0.0665]) tensor([[1.1566],\n",
      "        [1.0322],\n",
      "        [1.3589],\n",
      "        [1.0882],\n",
      "        [0.7558],\n",
      "        [1.2654],\n",
      "        [0.9390],\n",
      "        [1.2553],\n",
      "        [0.8919],\n",
      "        [1.2064],\n",
      "        [1.3817],\n",
      "        [1.1319],\n",
      "        [1.1671],\n",
      "        [1.1168],\n",
      "        [0.9334],\n",
      "        [1.6625],\n",
      "        [0.9478],\n",
      "        [1.0270],\n",
      "        [0.8718],\n",
      "        [1.2816]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第49次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第49次反向传播后的梯度为:\n",
      "tensor([0.1136]) tensor([-0.0642]) tensor([[1.1598],\n",
      "        [1.0320],\n",
      "        [1.3611],\n",
      "        [1.0890],\n",
      "        [0.7487],\n",
      "        [1.2651],\n",
      "        [0.9358],\n",
      "        [1.2533],\n",
      "        [0.8875],\n",
      "        [1.2044],\n",
      "        [1.3858],\n",
      "        [1.1333],\n",
      "        [1.1667],\n",
      "        [1.1152],\n",
      "        [0.9312],\n",
      "        [1.6725],\n",
      "        [0.9456],\n",
      "        [1.0254],\n",
      "        [0.8680],\n",
      "        [1.2866]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第50次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第50次反向传播后的梯度为:\n",
      "tensor([0.1132]) tensor([-0.0621]) tensor([[1.1625],\n",
      "        [1.0319],\n",
      "        [1.3629],\n",
      "        [1.0897],\n",
      "        [0.7427],\n",
      "        [1.2647],\n",
      "        [0.9331],\n",
      "        [1.2515],\n",
      "        [0.8838],\n",
      "        [1.2028],\n",
      "        [1.3892],\n",
      "        [1.1345],\n",
      "        [1.1664],\n",
      "        [1.1139],\n",
      "        [0.9294],\n",
      "        [1.6808],\n",
      "        [0.9438],\n",
      "        [1.0240],\n",
      "        [0.8649],\n",
      "        [1.2908]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第51次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第51次反向传播后的梯度为:\n",
      "tensor([0.1127]) tensor([-0.0602]) tensor([[1.1646],\n",
      "        [1.0318],\n",
      "        [1.3644],\n",
      "        [1.0903],\n",
      "        [0.7379],\n",
      "        [1.2644],\n",
      "        [0.9309],\n",
      "        [1.2500],\n",
      "        [0.8808],\n",
      "        [1.2015],\n",
      "        [1.3920],\n",
      "        [1.1354],\n",
      "        [1.1661],\n",
      "        [1.1129],\n",
      "        [0.9279],\n",
      "        [1.6876],\n",
      "        [0.9423],\n",
      "        [1.0230],\n",
      "        [0.8623],\n",
      "        [1.2943]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第52次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第52次反向传播后的梯度为:\n",
      "tensor([0.1121]) tensor([-0.0585]) tensor([[1.1663],\n",
      "        [1.0317],\n",
      "        [1.3655],\n",
      "        [1.0908],\n",
      "        [0.7343],\n",
      "        [1.2642],\n",
      "        [0.9293],\n",
      "        [1.2489],\n",
      "        [0.8786],\n",
      "        [1.2004],\n",
      "        [1.3941],\n",
      "        [1.1362],\n",
      "        [1.1659],\n",
      "        [1.1121],\n",
      "        [0.9268],\n",
      "        [1.6927],\n",
      "        [0.9412],\n",
      "        [1.0221],\n",
      "        [0.8604],\n",
      "        [1.2969]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第53次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第53次反向传播后的梯度为:\n",
      "tensor([0.1115]) tensor([-0.0569]) tensor([[1.1675],\n",
      "        [1.0316],\n",
      "        [1.3663],\n",
      "        [1.0911],\n",
      "        [0.7317],\n",
      "        [1.2641],\n",
      "        [0.9281],\n",
      "        [1.2482],\n",
      "        [0.8770],\n",
      "        [1.1997],\n",
      "        [1.3956],\n",
      "        [1.1367],\n",
      "        [1.1658],\n",
      "        [1.1115],\n",
      "        [0.9260],\n",
      "        [1.6963],\n",
      "        [0.9405],\n",
      "        [1.0216],\n",
      "        [0.8591],\n",
      "        [1.2987]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第54次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第54次反向传播后的梯度为:\n",
      "tensor([0.1109]) tensor([-0.0555]) tensor([[1.1681],\n",
      "        [1.0316],\n",
      "        [1.3667],\n",
      "        [1.0913],\n",
      "        [0.7303],\n",
      "        [1.2640],\n",
      "        [0.9275],\n",
      "        [1.2477],\n",
      "        [0.8761],\n",
      "        [1.1993],\n",
      "        [1.3964],\n",
      "        [1.1370],\n",
      "        [1.1657],\n",
      "        [1.1112],\n",
      "        [0.9256],\n",
      "        [1.6982],\n",
      "        [0.9400],\n",
      "        [1.0213],\n",
      "        [0.8583],\n",
      "        [1.2997]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第55次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第55次反向传播后的梯度为:\n",
      "tensor([0.1102]) tensor([-0.0542]) tensor([[1.1683],\n",
      "        [1.0316],\n",
      "        [1.3668],\n",
      "        [1.0913],\n",
      "        [0.7300],\n",
      "        [1.2639],\n",
      "        [0.9274],\n",
      "        [1.2476],\n",
      "        [0.8759],\n",
      "        [1.1992],\n",
      "        [1.3966],\n",
      "        [1.1370],\n",
      "        [1.1657],\n",
      "        [1.1111],\n",
      "        [0.9255],\n",
      "        [1.6987],\n",
      "        [0.9399],\n",
      "        [1.0212],\n",
      "        [0.8582],\n",
      "        [1.2999]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第56次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第56次反向传播后的梯度为:\n",
      "tensor([0.1095]) tensor([-0.0530]) tensor([[1.1679],\n",
      "        [1.0316],\n",
      "        [1.3666],\n",
      "        [1.0912],\n",
      "        [0.7308],\n",
      "        [1.2640],\n",
      "        [0.9277],\n",
      "        [1.2479],\n",
      "        [0.8764],\n",
      "        [1.1994],\n",
      "        [1.3961],\n",
      "        [1.1369],\n",
      "        [1.1657],\n",
      "        [1.1113],\n",
      "        [0.9257],\n",
      "        [1.6976],\n",
      "        [0.9402],\n",
      "        [1.0214],\n",
      "        [0.8586],\n",
      "        [1.2994]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第57次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第57次反向传播后的梯度为:\n",
      "tensor([0.1087]) tensor([-0.0519]) tensor([[1.1670],\n",
      "        [1.0316],\n",
      "        [1.3660],\n",
      "        [1.0910],\n",
      "        [0.7327],\n",
      "        [1.2641],\n",
      "        [0.9286],\n",
      "        [1.2485],\n",
      "        [0.8776],\n",
      "        [1.2000],\n",
      "        [1.3950],\n",
      "        [1.1365],\n",
      "        [1.1658],\n",
      "        [1.1117],\n",
      "        [0.9263],\n",
      "        [1.6949],\n",
      "        [0.9407],\n",
      "        [1.0218],\n",
      "        [0.8596],\n",
      "        [1.2980]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第58次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第58次反向传播后的梯度为:\n",
      "tensor([0.1080]) tensor([-0.0508]) tensor([[1.1656],\n",
      "        [1.0317],\n",
      "        [1.3651],\n",
      "        [1.0906],\n",
      "        [0.7356],\n",
      "        [1.2643],\n",
      "        [0.9299],\n",
      "        [1.2494],\n",
      "        [0.8794],\n",
      "        [1.2009],\n",
      "        [1.3933],\n",
      "        [1.1359],\n",
      "        [1.1660],\n",
      "        [1.1124],\n",
      "        [0.9272],\n",
      "        [1.6908],\n",
      "        [0.9416],\n",
      "        [1.0224],\n",
      "        [0.8611],\n",
      "        [1.2958]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第59次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第59次反向传播后的梯度为:\n",
      "tensor([0.1072]) tensor([-0.0499]) tensor([[1.1637],\n",
      "        [1.0317],\n",
      "        [1.3639],\n",
      "        [1.0900],\n",
      "        [0.7396],\n",
      "        [1.2646],\n",
      "        [0.9316],\n",
      "        [1.2507],\n",
      "        [0.8818],\n",
      "        [1.2021],\n",
      "        [1.3910],\n",
      "        [1.1350],\n",
      "        [1.1662],\n",
      "        [1.1133],\n",
      "        [0.9283],\n",
      "        [1.6851],\n",
      "        [0.9428],\n",
      "        [1.0233],\n",
      "        [0.8631],\n",
      "        [1.2929]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第60次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第60次反向传播后的梯度为:\n",
      "tensor([0.1064]) tensor([-0.0490]) tensor([[1.1613],\n",
      "        [1.0317],\n",
      "        [1.3624],\n",
      "        [1.0893],\n",
      "        [0.7446],\n",
      "        [1.2650],\n",
      "        [0.9339],\n",
      "        [1.2524],\n",
      "        [0.8849],\n",
      "        [1.2036],\n",
      "        [1.3881],\n",
      "        [1.1339],\n",
      "        [1.1665],\n",
      "        [1.1144],\n",
      "        [0.9298],\n",
      "        [1.6780],\n",
      "        [0.9442],\n",
      "        [1.0244],\n",
      "        [0.8657],\n",
      "        [1.2892]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第61次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第61次反向传播后的梯度为:\n",
      "tensor([0.1055]) tensor([-0.0481]) tensor([[1.1583],\n",
      "        [1.0317],\n",
      "        [1.3606],\n",
      "        [1.0884],\n",
      "        [0.7507],\n",
      "        [1.2655],\n",
      "        [0.9366],\n",
      "        [1.2544],\n",
      "        [0.8887],\n",
      "        [1.2054],\n",
      "        [1.3846],\n",
      "        [1.1326],\n",
      "        [1.1669],\n",
      "        [1.1158],\n",
      "        [0.9315],\n",
      "        [1.6694],\n",
      "        [0.9460],\n",
      "        [1.0257],\n",
      "        [0.8689],\n",
      "        [1.2847]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第62次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第62次反向传播后的梯度为:\n",
      "tensor([0.1047]) tensor([-0.0473]) tensor([[1.1549],\n",
      "        [1.0317],\n",
      "        [1.3585],\n",
      "        [1.0873],\n",
      "        [0.7578],\n",
      "        [1.2661],\n",
      "        [0.9397],\n",
      "        [1.2568],\n",
      "        [0.8930],\n",
      "        [1.2076],\n",
      "        [1.3805],\n",
      "        [1.1310],\n",
      "        [1.1673],\n",
      "        [1.1174],\n",
      "        [0.9335],\n",
      "        [1.6594],\n",
      "        [0.9480],\n",
      "        [1.0272],\n",
      "        [0.8725],\n",
      "        [1.2794]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第63次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第63次反向传播后的梯度为:\n",
      "tensor([0.1038]) tensor([-0.0466]) tensor([[1.1509],\n",
      "        [1.0317],\n",
      "        [1.3562],\n",
      "        [1.0861],\n",
      "        [0.7659],\n",
      "        [1.2668],\n",
      "        [0.9433],\n",
      "        [1.2596],\n",
      "        [0.8980],\n",
      "        [1.2101],\n",
      "        [1.3758],\n",
      "        [1.1292],\n",
      "        [1.1678],\n",
      "        [1.1193],\n",
      "        [0.9358],\n",
      "        [1.6479],\n",
      "        [0.9503],\n",
      "        [1.0289],\n",
      "        [0.8766],\n",
      "        [1.2734]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第64次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第64次反向传播后的梯度为:\n",
      "tensor([0.1030]) tensor([-0.0459]) tensor([[1.1464],\n",
      "        [1.0317],\n",
      "        [1.3535],\n",
      "        [1.0848],\n",
      "        [0.7750],\n",
      "        [1.2675],\n",
      "        [0.9474],\n",
      "        [1.2627],\n",
      "        [0.9036],\n",
      "        [1.2130],\n",
      "        [1.3705],\n",
      "        [1.1272],\n",
      "        [1.1684],\n",
      "        [1.1214],\n",
      "        [0.9384],\n",
      "        [1.6350],\n",
      "        [0.9529],\n",
      "        [1.0308],\n",
      "        [0.8812],\n",
      "        [1.2666]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第65次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第65次反向传播后的梯度为:\n",
      "tensor([0.1021]) tensor([-0.0453]) tensor([[1.1414],\n",
      "        [1.0316],\n",
      "        [1.3506],\n",
      "        [1.0832],\n",
      "        [0.7850],\n",
      "        [1.2684],\n",
      "        [0.9518],\n",
      "        [1.2663],\n",
      "        [0.9097],\n",
      "        [1.2161],\n",
      "        [1.3647],\n",
      "        [1.1249],\n",
      "        [1.1690],\n",
      "        [1.1237],\n",
      "        [0.9412],\n",
      "        [1.6208],\n",
      "        [0.9558],\n",
      "        [1.0329],\n",
      "        [0.8864],\n",
      "        [1.2590]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第66次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第66次反向传播后的梯度为:\n",
      "tensor([0.1013]) tensor([-0.0446]) tensor([[1.1359],\n",
      "        [1.0315],\n",
      "        [1.3474],\n",
      "        [1.0815],\n",
      "        [0.7961],\n",
      "        [1.2694],\n",
      "        [0.9567],\n",
      "        [1.2702],\n",
      "        [0.9165],\n",
      "        [1.2196],\n",
      "        [1.3583],\n",
      "        [1.1224],\n",
      "        [1.1697],\n",
      "        [1.1263],\n",
      "        [0.9443],\n",
      "        [1.6051],\n",
      "        [0.9589],\n",
      "        [1.0353],\n",
      "        [0.8920],\n",
      "        [1.2507]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第67次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第67次反向传播后的梯度为:\n",
      "tensor([0.1004]) tensor([-0.0440]) tensor([[1.1299],\n",
      "        [1.0314],\n",
      "        [1.3439],\n",
      "        [1.0796],\n",
      "        [0.8081],\n",
      "        [1.2705],\n",
      "        [0.9620],\n",
      "        [1.2744],\n",
      "        [0.9239],\n",
      "        [1.2235],\n",
      "        [1.3513],\n",
      "        [1.1197],\n",
      "        [1.1705],\n",
      "        [1.1291],\n",
      "        [0.9476],\n",
      "        [1.5881],\n",
      "        [0.9623],\n",
      "        [1.0378],\n",
      "        [0.8980],\n",
      "        [1.2416]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第68次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第68次反向传播后的梯度为:\n",
      "tensor([0.0996]) tensor([-0.0435]) tensor([[1.1233],\n",
      "        [1.0313],\n",
      "        [1.3402],\n",
      "        [1.0776],\n",
      "        [0.8210],\n",
      "        [1.2717],\n",
      "        [0.9677],\n",
      "        [1.2791],\n",
      "        [0.9318],\n",
      "        [1.2277],\n",
      "        [1.3438],\n",
      "        [1.1167],\n",
      "        [1.1713],\n",
      "        [1.1321],\n",
      "        [0.9512],\n",
      "        [1.5697],\n",
      "        [0.9659],\n",
      "        [1.0405],\n",
      "        [0.9046],\n",
      "        [1.2318]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第69次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第69次反向传播后的梯度为:\n",
      "tensor([0.0987]) tensor([-0.0429]) tensor([[1.1163],\n",
      "        [1.0311],\n",
      "        [1.3362],\n",
      "        [1.0753],\n",
      "        [0.8349],\n",
      "        [1.2731],\n",
      "        [0.9738],\n",
      "        [1.2842],\n",
      "        [0.9403],\n",
      "        [1.2322],\n",
      "        [1.3358],\n",
      "        [1.1135],\n",
      "        [1.1722],\n",
      "        [1.1353],\n",
      "        [0.9550],\n",
      "        [1.5499],\n",
      "        [0.9697],\n",
      "        [1.0434],\n",
      "        [0.9116],\n",
      "        [1.2213]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第70次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第70次反向传播后的梯度为:\n",
      "tensor([0.0978]) tensor([-0.0424]) tensor([[1.1087],\n",
      "        [1.0309],\n",
      "        [1.3320],\n",
      "        [1.0729],\n",
      "        [0.8497],\n",
      "        [1.2745],\n",
      "        [0.9803],\n",
      "        [1.2896],\n",
      "        [0.9494],\n",
      "        [1.2371],\n",
      "        [1.3272],\n",
      "        [1.1100],\n",
      "        [1.1732],\n",
      "        [1.1388],\n",
      "        [0.9591],\n",
      "        [1.5289],\n",
      "        [0.9738],\n",
      "        [1.0465],\n",
      "        [0.9190],\n",
      "        [1.2100]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第71次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第71次反向传播后的梯度为:\n",
      "tensor([0.0970]) tensor([-0.0419]) tensor([[1.1007],\n",
      "        [1.0307],\n",
      "        [1.3276],\n",
      "        [1.0703],\n",
      "        [0.8654],\n",
      "        [1.2761],\n",
      "        [0.9872],\n",
      "        [1.2954],\n",
      "        [0.9590],\n",
      "        [1.2423],\n",
      "        [1.3182],\n",
      "        [1.1064],\n",
      "        [1.1742],\n",
      "        [1.1425],\n",
      "        [0.9633],\n",
      "        [1.5066],\n",
      "        [0.9782],\n",
      "        [1.0497],\n",
      "        [0.9269],\n",
      "        [1.1979]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第72次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第72次反向传播后的梯度为:\n",
      "tensor([0.0961]) tensor([-0.0414]) tensor([[1.0921],\n",
      "        [1.0304],\n",
      "        [1.3229],\n",
      "        [1.0676],\n",
      "        [0.8820],\n",
      "        [1.2778],\n",
      "        [0.9945],\n",
      "        [1.3016],\n",
      "        [0.9691],\n",
      "        [1.2478],\n",
      "        [1.3085],\n",
      "        [1.1024],\n",
      "        [1.1754],\n",
      "        [1.1465],\n",
      "        [0.9678],\n",
      "        [1.4829],\n",
      "        [0.9827],\n",
      "        [1.0532],\n",
      "        [0.9352],\n",
      "        [1.1852]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第73次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第73次反向传播后的梯度为:\n",
      "tensor([0.0953]) tensor([-0.0409]) tensor([[1.0830],\n",
      "        [1.0301],\n",
      "        [1.3180],\n",
      "        [1.0647],\n",
      "        [0.8995],\n",
      "        [1.2797],\n",
      "        [1.0022],\n",
      "        [1.3082],\n",
      "        [0.9798],\n",
      "        [1.2537],\n",
      "        [1.2984],\n",
      "        [1.0983],\n",
      "        [1.1765],\n",
      "        [1.1506],\n",
      "        [0.9725],\n",
      "        [1.4580],\n",
      "        [0.9875],\n",
      "        [1.0568],\n",
      "        [0.9439],\n",
      "        [1.1717]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第74次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第74次反向传播后的梯度为:\n",
      "tensor([0.0944]) tensor([-0.0405]) tensor([[1.0734],\n",
      "        [1.0297],\n",
      "        [1.3129],\n",
      "        [1.0615],\n",
      "        [0.9179],\n",
      "        [1.2817],\n",
      "        [1.0102],\n",
      "        [1.3153],\n",
      "        [0.9911],\n",
      "        [1.2600],\n",
      "        [1.2878],\n",
      "        [1.0939],\n",
      "        [1.1778],\n",
      "        [1.1550],\n",
      "        [0.9774],\n",
      "        [1.4319],\n",
      "        [0.9925],\n",
      "        [1.0606],\n",
      "        [0.9531],\n",
      "        [1.1575]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第75次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第75次反向传播后的梯度为:\n",
      "tensor([0.0936]) tensor([-0.0400]) tensor([[1.0634],\n",
      "        [1.0292],\n",
      "        [1.3075],\n",
      "        [1.0583],\n",
      "        [0.9371],\n",
      "        [1.2838],\n",
      "        [1.0186],\n",
      "        [1.3227],\n",
      "        [1.0028],\n",
      "        [1.2665],\n",
      "        [1.2767],\n",
      "        [1.0893],\n",
      "        [1.1791],\n",
      "        [1.1596],\n",
      "        [0.9825],\n",
      "        [1.4044],\n",
      "        [0.9977],\n",
      "        [1.0645],\n",
      "        [0.9627],\n",
      "        [1.1426]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第76次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第76次反向传播后的梯度为:\n",
      "tensor([0.0927]) tensor([-0.0396]) tensor([[1.0528],\n",
      "        [1.0288],\n",
      "        [1.3020],\n",
      "        [1.0548],\n",
      "        [0.9572],\n",
      "        [1.2860],\n",
      "        [1.0274],\n",
      "        [1.3305],\n",
      "        [1.0151],\n",
      "        [1.2735],\n",
      "        [1.2650],\n",
      "        [1.0844],\n",
      "        [1.1805],\n",
      "        [1.1645],\n",
      "        [0.9878],\n",
      "        [1.3758],\n",
      "        [1.0031],\n",
      "        [1.0686],\n",
      "        [0.9726],\n",
      "        [1.1270]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第77次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第77次反向传播后的梯度为:\n",
      "tensor([0.0919]) tensor([-0.0392]) tensor([[1.0417],\n",
      "        [1.0282],\n",
      "        [1.2962],\n",
      "        [1.0511],\n",
      "        [0.9781],\n",
      "        [1.2884],\n",
      "        [1.0366],\n",
      "        [1.3387],\n",
      "        [1.0279],\n",
      "        [1.2807],\n",
      "        [1.2529],\n",
      "        [1.0793],\n",
      "        [1.1820],\n",
      "        [1.1695],\n",
      "        [0.9933],\n",
      "        [1.3460],\n",
      "        [1.0087],\n",
      "        [1.0729],\n",
      "        [0.9830],\n",
      "        [1.1107]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第78次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第78次反向传播后的梯度为:\n",
      "tensor([0.0911]) tensor([-0.0388]) tensor([[1.0301],\n",
      "        [1.0276],\n",
      "        [1.2903],\n",
      "        [1.0473],\n",
      "        [0.9999],\n",
      "        [1.2909],\n",
      "        [1.0460],\n",
      "        [1.3473],\n",
      "        [1.0412],\n",
      "        [1.2883],\n",
      "        [1.2404],\n",
      "        [1.0740],\n",
      "        [1.1835],\n",
      "        [1.1748],\n",
      "        [0.9990],\n",
      "        [1.3149],\n",
      "        [1.0145],\n",
      "        [1.0774],\n",
      "        [0.9938],\n",
      "        [1.0937]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第79次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第79次反向传播后的梯度为:\n",
      "tensor([0.0902]) tensor([-0.0384]) tensor([[1.0181],\n",
      "        [1.0270],\n",
      "        [1.2842],\n",
      "        [1.0433],\n",
      "        [1.0225],\n",
      "        [1.2936],\n",
      "        [1.0559],\n",
      "        [1.3563],\n",
      "        [1.0550],\n",
      "        [1.2963],\n",
      "        [1.2273],\n",
      "        [1.0684],\n",
      "        [1.1852],\n",
      "        [1.1803],\n",
      "        [1.0049],\n",
      "        [1.2827],\n",
      "        [1.0205],\n",
      "        [1.0820],\n",
      "        [1.0049],\n",
      "        [1.0760]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第80次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第80次反向传播后的梯度为:\n",
      "tensor([0.0894]) tensor([-0.0380]) tensor([[1.0055],\n",
      "        [1.0263],\n",
      "        [1.2778],\n",
      "        [1.0391],\n",
      "        [1.0459],\n",
      "        [1.2964],\n",
      "        [1.0661],\n",
      "        [1.3657],\n",
      "        [1.0692],\n",
      "        [1.3046],\n",
      "        [1.2138],\n",
      "        [1.0626],\n",
      "        [1.1868],\n",
      "        [1.1860],\n",
      "        [1.0109],\n",
      "        [1.2493],\n",
      "        [1.0267],\n",
      "        [1.0867],\n",
      "        [1.0164],\n",
      "        [1.0576]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第81次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第81次反向传播后的梯度为:\n",
      "tensor([0.0886]) tensor([-0.0376]) tensor([[0.9925],\n",
      "        [1.0255],\n",
      "        [1.2713],\n",
      "        [1.0347],\n",
      "        [1.0701],\n",
      "        [1.2994],\n",
      "        [1.0766],\n",
      "        [1.3755],\n",
      "        [1.0840],\n",
      "        [1.3132],\n",
      "        [1.1998],\n",
      "        [1.0566],\n",
      "        [1.1886],\n",
      "        [1.1919],\n",
      "        [1.0172],\n",
      "        [1.2148],\n",
      "        [1.0331],\n",
      "        [1.0916],\n",
      "        [1.0283],\n",
      "        [1.0385]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第82次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第82次反向传播后的梯度为:\n",
      "tensor([0.0878]) tensor([-0.0372]) tensor([[0.9789],\n",
      "        [1.0246],\n",
      "        [1.2646],\n",
      "        [1.0302],\n",
      "        [1.0950],\n",
      "        [1.3025],\n",
      "        [1.0874],\n",
      "        [1.3857],\n",
      "        [1.0992],\n",
      "        [1.3222],\n",
      "        [1.1854],\n",
      "        [1.0503],\n",
      "        [1.1905],\n",
      "        [1.1981],\n",
      "        [1.0236],\n",
      "        [1.1791],\n",
      "        [1.0396],\n",
      "        [1.0967],\n",
      "        [1.0405],\n",
      "        [1.0188]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第83次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第83次反向传播后的梯度为:\n",
      "tensor([0.0870]) tensor([-0.0368]) tensor([[0.9649],\n",
      "        [1.0237],\n",
      "        [1.2578],\n",
      "        [1.0254],\n",
      "        [1.1208],\n",
      "        [1.3058],\n",
      "        [1.0986],\n",
      "        [1.3964],\n",
      "        [1.1149],\n",
      "        [1.3316],\n",
      "        [1.1705],\n",
      "        [1.0438],\n",
      "        [1.1924],\n",
      "        [1.2044],\n",
      "        [1.0301],\n",
      "        [1.1423],\n",
      "        [1.0463],\n",
      "        [1.1019],\n",
      "        [1.0531],\n",
      "        [0.9984]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第84次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第84次反向传播后的梯度为:\n",
      "tensor([0.0862]) tensor([-0.0365]) tensor([[0.9504],\n",
      "        [1.0228],\n",
      "        [1.2507],\n",
      "        [1.0205],\n",
      "        [1.1474],\n",
      "        [1.3092],\n",
      "        [1.1101],\n",
      "        [1.4074],\n",
      "        [1.1311],\n",
      "        [1.3413],\n",
      "        [1.1552],\n",
      "        [1.0371],\n",
      "        [1.1944],\n",
      "        [1.2110],\n",
      "        [1.0368],\n",
      "        [1.1043],\n",
      "        [1.0532],\n",
      "        [1.1072],\n",
      "        [1.0661],\n",
      "        [0.9773]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第85次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第85次反向传播后的梯度为:\n",
      "tensor([0.0854]) tensor([-0.0361]) tensor([[0.9354],\n",
      "        [1.0217],\n",
      "        [1.2436],\n",
      "        [1.0154],\n",
      "        [1.1747],\n",
      "        [1.3128],\n",
      "        [1.1219],\n",
      "        [1.4189],\n",
      "        [1.1477],\n",
      "        [1.3513],\n",
      "        [1.1395],\n",
      "        [1.0302],\n",
      "        [1.1964],\n",
      "        [1.2178],\n",
      "        [1.0437],\n",
      "        [1.0653],\n",
      "        [1.0603],\n",
      "        [1.1127],\n",
      "        [1.0794],\n",
      "        [0.9556]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第86次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第86次反向传播后的梯度为:\n",
      "tensor([0.0846]) tensor([-0.0358]) tensor([[0.9199],\n",
      "        [1.0206],\n",
      "        [1.2362],\n",
      "        [1.0101],\n",
      "        [1.2027],\n",
      "        [1.3165],\n",
      "        [1.1340],\n",
      "        [1.4307],\n",
      "        [1.1648],\n",
      "        [1.3617],\n",
      "        [1.1233],\n",
      "        [1.0230],\n",
      "        [1.1985],\n",
      "        [1.2248],\n",
      "        [1.0507],\n",
      "        [1.0252],\n",
      "        [1.0675],\n",
      "        [1.1183],\n",
      "        [1.0930],\n",
      "        [0.9332]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第87次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第87次反向传播后的梯度为:\n",
      "tensor([0.0838]) tensor([-0.0354]) tensor([[0.9040],\n",
      "        [1.0194],\n",
      "        [1.2287],\n",
      "        [1.0046],\n",
      "        [1.2315],\n",
      "        [1.3204],\n",
      "        [1.1465],\n",
      "        [1.4430],\n",
      "        [1.1824],\n",
      "        [1.3724],\n",
      "        [1.1067],\n",
      "        [1.0156],\n",
      "        [1.2008],\n",
      "        [1.2320],\n",
      "        [1.0579],\n",
      "        [0.9840],\n",
      "        [1.0749],\n",
      "        [1.1240],\n",
      "        [1.1070],\n",
      "        [0.9101]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第88次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第88次反向传播后的梯度为:\n",
      "tensor([0.0831]) tensor([-0.0351]) tensor([[0.8876],\n",
      "        [1.0181],\n",
      "        [1.2210],\n",
      "        [0.9990],\n",
      "        [1.2610],\n",
      "        [1.3245],\n",
      "        [1.1592],\n",
      "        [1.4556],\n",
      "        [1.2003],\n",
      "        [1.3835],\n",
      "        [1.0897],\n",
      "        [1.0080],\n",
      "        [1.2030],\n",
      "        [1.2394],\n",
      "        [1.0652],\n",
      "        [0.9418],\n",
      "        [1.0824],\n",
      "        [1.1299],\n",
      "        [1.1212],\n",
      "        [0.8864]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第89次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第89次反向传播后的梯度为:\n",
      "tensor([0.0823]) tensor([-0.0347]) tensor([[0.8707],\n",
      "        [1.0168],\n",
      "        [1.2132],\n",
      "        [0.9931],\n",
      "        [1.2913],\n",
      "        [1.3287],\n",
      "        [1.1722],\n",
      "        [1.4687],\n",
      "        [1.2187],\n",
      "        [1.3949],\n",
      "        [1.0722],\n",
      "        [1.0001],\n",
      "        [1.2054],\n",
      "        [1.2470],\n",
      "        [1.0726],\n",
      "        [0.8985],\n",
      "        [1.0901],\n",
      "        [1.1359],\n",
      "        [1.1359],\n",
      "        [0.8621]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第90次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第90次反向传播后的梯度为:\n",
      "tensor([0.0815]) tensor([-0.0344]) tensor([[0.8533],\n",
      "        [1.0154],\n",
      "        [1.2053],\n",
      "        [0.9871],\n",
      "        [1.3222],\n",
      "        [1.3331],\n",
      "        [1.1856],\n",
      "        [1.4822],\n",
      "        [1.2376],\n",
      "        [1.4066],\n",
      "        [1.0544],\n",
      "        [0.9920],\n",
      "        [1.2078],\n",
      "        [1.2548],\n",
      "        [1.0802],\n",
      "        [0.8542],\n",
      "        [1.0979],\n",
      "        [1.1420],\n",
      "        [1.1508],\n",
      "        [0.8371]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第91次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第91次反向传播后的梯度为:\n",
      "tensor([0.0808]) tensor([-0.0341]) tensor([[0.8354],\n",
      "        [1.0139],\n",
      "        [1.1972],\n",
      "        [0.9809],\n",
      "        [1.3539],\n",
      "        [1.3376],\n",
      "        [1.1992],\n",
      "        [1.4961],\n",
      "        [1.2568],\n",
      "        [1.4187],\n",
      "        [1.0362],\n",
      "        [0.9837],\n",
      "        [1.2103],\n",
      "        [1.2628],\n",
      "        [1.0879],\n",
      "        [0.8088],\n",
      "        [1.1059],\n",
      "        [1.1483],\n",
      "        [1.1660],\n",
      "        [0.8115]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第92次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第92次反向传播后的梯度为:\n",
      "tensor([0.0800]) tensor([-0.0338]) tensor([[0.8171],\n",
      "        [1.0123],\n",
      "        [1.1890],\n",
      "        [0.9745],\n",
      "        [1.3862],\n",
      "        [1.3423],\n",
      "        [1.2131],\n",
      "        [1.5104],\n",
      "        [1.2765],\n",
      "        [1.4312],\n",
      "        [1.0176],\n",
      "        [0.9752],\n",
      "        [1.2129],\n",
      "        [1.2711],\n",
      "        [1.0957],\n",
      "        [0.7624],\n",
      "        [1.1140],\n",
      "        [1.1547],\n",
      "        [1.1815],\n",
      "        [0.7853]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第93次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第93次反向传播后的梯度为:\n",
      "tensor([0.0793]) tensor([-0.0334]) tensor([[0.7984],\n",
      "        [1.0106],\n",
      "        [1.1806],\n",
      "        [0.9679],\n",
      "        [1.4193],\n",
      "        [1.3472],\n",
      "        [1.2273],\n",
      "        [1.5251],\n",
      "        [1.2966],\n",
      "        [1.4440],\n",
      "        [0.9985],\n",
      "        [0.9664],\n",
      "        [1.2156],\n",
      "        [1.2795],\n",
      "        [1.1037],\n",
      "        [0.7151],\n",
      "        [1.1223],\n",
      "        [1.1612],\n",
      "        [1.1974],\n",
      "        [0.7585]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第94次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第94次反向传播后的梯度为:\n",
      "tensor([0.0786]) tensor([-0.0331]) tensor([[0.7791],\n",
      "        [1.0089],\n",
      "        [1.1721],\n",
      "        [0.9611],\n",
      "        [1.4530],\n",
      "        [1.3523],\n",
      "        [1.2417],\n",
      "        [1.5402],\n",
      "        [1.3171],\n",
      "        [1.4571],\n",
      "        [0.9791],\n",
      "        [0.9575],\n",
      "        [1.2183],\n",
      "        [1.2881],\n",
      "        [1.1117],\n",
      "        [0.6668],\n",
      "        [1.1306],\n",
      "        [1.1678],\n",
      "        [1.2135],\n",
      "        [0.7310]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第95次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第95次反向传播后的梯度为:\n",
      "tensor([0.0779]) tensor([-0.0328]) tensor([[0.7594],\n",
      "        [1.0071],\n",
      "        [1.1635],\n",
      "        [0.9542],\n",
      "        [1.4874],\n",
      "        [1.3575],\n",
      "        [1.2565],\n",
      "        [1.5557],\n",
      "        [1.3380],\n",
      "        [1.4706],\n",
      "        [0.9594],\n",
      "        [0.9483],\n",
      "        [1.2211],\n",
      "        [1.2969],\n",
      "        [1.1199],\n",
      "        [0.6174],\n",
      "        [1.1391],\n",
      "        [1.1746],\n",
      "        [1.2299],\n",
      "        [0.7029]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第96次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第96次反向传播后的梯度为:\n",
      "tensor([0.0771]) tensor([-0.0325]) tensor([[0.7393],\n",
      "        [1.0052],\n",
      "        [1.1548],\n",
      "        [0.9471],\n",
      "        [1.5224],\n",
      "        [1.3629],\n",
      "        [1.2715],\n",
      "        [1.5717],\n",
      "        [1.3592],\n",
      "        [1.4844],\n",
      "        [0.9392],\n",
      "        [0.9388],\n",
      "        [1.2240],\n",
      "        [1.3060],\n",
      "        [1.1282],\n",
      "        [0.5672],\n",
      "        [1.1478],\n",
      "        [1.1814],\n",
      "        [1.2466],\n",
      "        [0.6742]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第97次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第97次反向传播后的梯度为:\n",
      "tensor([0.0764]) tensor([-0.0322]) tensor([[0.7187],\n",
      "        [1.0032],\n",
      "        [1.1460],\n",
      "        [0.9397],\n",
      "        [1.5582],\n",
      "        [1.3684],\n",
      "        [1.2867],\n",
      "        [1.5880],\n",
      "        [1.3809],\n",
      "        [1.4985],\n",
      "        [0.9187],\n",
      "        [0.9292],\n",
      "        [1.2270],\n",
      "        [1.3152],\n",
      "        [1.1367],\n",
      "        [0.5160],\n",
      "        [1.1565],\n",
      "        [1.1884],\n",
      "        [1.2636],\n",
      "        [0.6450]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第98次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第98次反向传播后的梯度为:\n",
      "tensor([0.0757]) tensor([-0.0319]) tensor([[0.6976],\n",
      "        [1.0011],\n",
      "        [1.1370],\n",
      "        [0.9322],\n",
      "        [1.5945],\n",
      "        [1.3741],\n",
      "        [1.3023],\n",
      "        [1.6048],\n",
      "        [1.4030],\n",
      "        [1.5130],\n",
      "        [0.8978],\n",
      "        [0.9194],\n",
      "        [1.2300],\n",
      "        [1.3246],\n",
      "        [1.1452],\n",
      "        [0.4638],\n",
      "        [1.1654],\n",
      "        [1.1955],\n",
      "        [1.2808],\n",
      "        [0.6151]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第99次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第99次反向传播后的梯度为:\n",
      "tensor([0.0750]) tensor([-0.0316]) tensor([[0.6761],\n",
      "        [0.9989],\n",
      "        [1.1280],\n",
      "        [0.9245],\n",
      "        [1.6315],\n",
      "        [1.3800],\n",
      "        [1.3181],\n",
      "        [1.6219],\n",
      "        [1.4254],\n",
      "        [1.5278],\n",
      "        [0.8765],\n",
      "        [0.9093],\n",
      "        [1.2331],\n",
      "        [1.3342],\n",
      "        [1.1538],\n",
      "        [0.4107],\n",
      "        [1.1744],\n",
      "        [1.2027],\n",
      "        [1.2983],\n",
      "        [0.5846]]) None\n",
      "************************************************************\n",
      "tensor([1.5881]) tensor([5.5855])\n"
     ]
    }
   ],
   "source": [
    "# 首先我们得有训练样本X，Y， 这里我们随机生成\n",
    "x = torch.rand(20, 1, requires_grad=True)\n",
    "\n",
    "y = 2 * x + (5 + torch.randn(20, 1, requires_grad=True))\n",
    "\n",
    "# 构建线性回归函数的参数\n",
    "w = torch.randn((1), requires_grad=True)\n",
    "b = torch.zeros((1), requires_grad=True)   # 这俩都需要求梯度\n",
    "\n",
    "# 设置学习率lr为0.1\n",
    "lr = 0.1\n",
    "\n",
    "for iteration in range(100):\n",
    "    # 前向传播\n",
    "    wx = torch.mul(w, x) #将两张量中元素\n",
    "    y_pred = torch.add(wx, b)\n",
    "\n",
    "    \n",
    "    # 计算loss\n",
    "    loss = (0.5 * (y-y_pred)**2).mean()\n",
    "\n",
    "    print(\"*\"*60)\n",
    "    print(f\"第{iteration}次反向传播前的梯度为:\")\n",
    "    try:\n",
    "        print(w.grad.data,b.grad.data,x.grad.data,y.grad.data)\n",
    "    except :\n",
    "        print(\"梯度不存在\")\n",
    "    # 反向传播\n",
    "    loss.backward(retain_graph=True)\n",
    "    print(f\"第{iteration}次反向传播后的梯度为:\")\n",
    "    t = x.grad.data if x.grad != None  else None\n",
    "    t1 = y.grad.data if y.grad != None else None\n",
    "    print(w.grad.data,b.grad.data,t,t1)\n",
    "    print(\"*\"*60)\n",
    "    # 更新参数\n",
    "    b.data.sub_(lr * b.grad)    # 这种_的加法操作时从自身减，相当于-=\n",
    "    w.data.sub_(lr * w.grad)\n",
    "\n",
    "    # 梯度清零\n",
    "    w.grad.data.zero_()\n",
    "    b.grad.data.zero_()\n",
    "\n",
    "print(w.data, b.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "未经过任何计算的x有了梯度，而经过计算的y没有，那么会是这个原因吗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "第0次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第0次反向传播后的梯度为:\n",
      "tensor([-2.8534]) tensor([-5.7790]) tensor([[-0.1618],\n",
      "        [-0.1793],\n",
      "        [-0.1260],\n",
      "        [-0.1605],\n",
      "        [-0.1202],\n",
      "        [-0.1990],\n",
      "        [-0.1493],\n",
      "        [-0.1229],\n",
      "        [-0.2035],\n",
      "        [-0.1558],\n",
      "        [-0.1348],\n",
      "        [-0.1343],\n",
      "        [-0.1691],\n",
      "        [-0.2098],\n",
      "        [-0.1676],\n",
      "        [-0.1083],\n",
      "        [-0.1101],\n",
      "        [-0.1402],\n",
      "        [-0.1767],\n",
      "        [-0.1312]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第1次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第1次反向传播后的梯度为:\n",
      "tensor([-2.4753]) tensor([-5.0599]) tensor([[-0.3801],\n",
      "        [-0.4272],\n",
      "        [-0.2868],\n",
      "        [-0.3795],\n",
      "        [-0.2745],\n",
      "        [-0.4802],\n",
      "        [-0.3480],\n",
      "        [-0.2794],\n",
      "        [-0.4870],\n",
      "        [-0.3659],\n",
      "        [-0.3177],\n",
      "        [-0.3078],\n",
      "        [-0.3957],\n",
      "        [-0.4994],\n",
      "        [-0.4012],\n",
      "        [-0.2503],\n",
      "        [-0.2520],\n",
      "        [-0.3308],\n",
      "        [-0.4208],\n",
      "        [-0.2996]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第2次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第2次反向传播后的梯度为:\n",
      "tensor([-2.1451]) tensor([-4.4314]) tensor([[-0.6298],\n",
      "        [-0.7184],\n",
      "        [-0.4588],\n",
      "        [-0.6332],\n",
      "        [-0.4408],\n",
      "        [-0.8182],\n",
      "        [-0.5715],\n",
      "        [-0.4461],\n",
      "        [-0.8230],\n",
      "        [-0.6059],\n",
      "        [-0.5280],\n",
      "        [-0.4960],\n",
      "        [-0.6529],\n",
      "        [-0.8393],\n",
      "        [-0.6781],\n",
      "        [-0.4072],\n",
      "        [-0.4054],\n",
      "        [-0.5503],\n",
      "        [-0.7077],\n",
      "        [-0.4814]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第3次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第3次反向传播后的梯度为:\n",
      "tensor([-1.8565]) tensor([-3.8821]) tensor([[-0.8934],\n",
      "        [-1.0350],\n",
      "        [-0.6261],\n",
      "        [-0.9047],\n",
      "        [-0.6038],\n",
      "        [-1.1945],\n",
      "        [-0.8028],\n",
      "        [-0.6074],\n",
      "        [-1.1913],\n",
      "        [-0.8587],\n",
      "        [-0.7511],\n",
      "        [-0.6825],\n",
      "        [-0.9221],\n",
      "        [-1.2081],\n",
      "        [-0.9818],\n",
      "        [-0.5662],\n",
      "        [-0.5568],\n",
      "        [-0.7840],\n",
      "        [-1.0192],\n",
      "        [-0.6600]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第4次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第4次反向传播后的梯度为:\n",
      "tensor([-1.6045]) tensor([-3.4020]) tensor([[-1.1586],\n",
      "        [-1.3639],\n",
      "        [-0.7781],\n",
      "        [-1.1821],\n",
      "        [-0.7539],\n",
      "        [-1.5953],\n",
      "        [-1.0305],\n",
      "        [-0.7530],\n",
      "        [-1.5778],\n",
      "        [-1.1127],\n",
      "        [-0.9771],\n",
      "        [-0.8563],\n",
      "        [-1.1902],\n",
      "        [-1.5909],\n",
      "        [-1.3003],\n",
      "        [-0.7184],\n",
      "        [-0.6971],\n",
      "        [-1.0212],\n",
      "        [-1.3429],\n",
      "        [-0.8248]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第5次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第5次反向传播后的梯度为:\n",
      "tensor([-1.3844]) tensor([-2.9824]) tensor([[-1.4173],\n",
      "        [-1.6964],\n",
      "        [-0.9085],\n",
      "        [-1.4574],\n",
      "        [-0.8848],\n",
      "        [-2.0108],\n",
      "        [-1.2471],\n",
      "        [-0.8768],\n",
      "        [-1.9723],\n",
      "        [-1.3601],\n",
      "        [-1.1990],\n",
      "        [-1.0108],\n",
      "        [-1.4490],\n",
      "        [-1.9774],\n",
      "        [-1.6254],\n",
      "        [-0.8585],\n",
      "        [-0.8206],\n",
      "        [-1.2549],\n",
      "        [-1.6698],\n",
      "        [-0.9690]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第6次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第6次反向传播后的梯度为:\n",
      "tensor([-1.1921]) tensor([-2.6157]) tensor([[-1.6645],\n",
      "        [-2.0262],\n",
      "        [-1.0139],\n",
      "        [-1.7254],\n",
      "        [-0.9931],\n",
      "        [-2.4339],\n",
      "        [-1.4479],\n",
      "        [-0.9752],\n",
      "        [-2.3678],\n",
      "        [-1.5958],\n",
      "        [-1.4125],\n",
      "        [-1.1419],\n",
      "        [-1.6931],\n",
      "        [-2.3604],\n",
      "        [-1.9511],\n",
      "        [-0.9830],\n",
      "        [-0.9241],\n",
      "        [-1.4804],\n",
      "        [-1.9941],\n",
      "        [-1.0891]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第7次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第7次反向传播后的梯度为:\n",
      "tensor([-1.0242]) tensor([-2.2951]) tensor([[-1.8969],\n",
      "        [-2.3495],\n",
      "        [-1.0925],\n",
      "        [-1.9826],\n",
      "        [-1.0772],\n",
      "        [-2.8596],\n",
      "        [-1.6303],\n",
      "        [-1.0469],\n",
      "        [-2.7597],\n",
      "        [-1.8169],\n",
      "        [-1.6148],\n",
      "        [-1.2479],\n",
      "        [-1.9195],\n",
      "        [-2.7354],\n",
      "        [-2.2736],\n",
      "        [-1.0901],\n",
      "        [-1.0062],\n",
      "        [-1.6950],\n",
      "        [-2.3117],\n",
      "        [-1.1832]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第8次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第8次反向传播后的梯度为:\n",
      "tensor([-0.8776]) tensor([-2.0149]) tensor([[-2.1131],\n",
      "        [-2.6638],\n",
      "        [-1.1444],\n",
      "        [-2.2273],\n",
      "        [-1.1369],\n",
      "        [-3.2845],\n",
      "        [-1.7933],\n",
      "        [-1.0917],\n",
      "        [-3.1448],\n",
      "        [-2.0219],\n",
      "        [-1.8043],\n",
      "        [-1.3284],\n",
      "        [-2.1268],\n",
      "        [-3.0997],\n",
      "        [-2.5903],\n",
      "        [-1.1794],\n",
      "        [-1.0664],\n",
      "        [-1.8971],\n",
      "        [-2.6202],\n",
      "        [-1.2512]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第9次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第9次反向传播后的梯度为:\n",
      "tensor([-0.7496]) tensor([-1.7700]) tensor([[-2.3124],\n",
      "        [-2.9676],\n",
      "        [-1.1703],\n",
      "        [-2.4585],\n",
      "        [-1.1728],\n",
      "        [-3.7061],\n",
      "        [-1.9367],\n",
      "        [-1.1105],\n",
      "        [-3.5215],\n",
      "        [-2.2102],\n",
      "        [-1.9806],\n",
      "        [-1.3841],\n",
      "        [-2.3145],\n",
      "        [-3.4518],\n",
      "        [-2.8995],\n",
      "        [-1.2508],\n",
      "        [-1.1052],\n",
      "        [-2.0859],\n",
      "        [-2.9183],\n",
      "        [-1.2937]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第10次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第10次反向传播后的梯度为:\n",
      "tensor([-0.6378]) tensor([-1.5559]) tensor([[-2.4951],\n",
      "        [-3.2604],\n",
      "        [-1.1716],\n",
      "        [-2.6760],\n",
      "        [-1.1861],\n",
      "        [-4.1230],\n",
      "        [-2.0610],\n",
      "        [-1.1046],\n",
      "        [-3.8885],\n",
      "        [-2.3821],\n",
      "        [-2.1435],\n",
      "        [-1.4160],\n",
      "        [-2.4831],\n",
      "        [-3.7909],\n",
      "        [-3.2004],\n",
      "        [-1.3050],\n",
      "        [-1.1237],\n",
      "        [-2.2613],\n",
      "        [-3.2054],\n",
      "        [-1.3119]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第11次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第11次反向传播后的梯度为:\n",
      "tensor([-0.5402]) tensor([-1.3687]) tensor([[-2.6617],\n",
      "        [-3.5419],\n",
      "        [-1.1499],\n",
      "        [-2.8802],\n",
      "        [-1.1783],\n",
      "        [-4.5342],\n",
      "        [-2.1672],\n",
      "        [-1.0758],\n",
      "        [-4.2457],\n",
      "        [-2.5382],\n",
      "        [-2.2934],\n",
      "        [-1.4258],\n",
      "        [-2.6335],\n",
      "        [-4.1171],\n",
      "        [-3.4927],\n",
      "        [-1.3429],\n",
      "        [-1.1231],\n",
      "        [-2.4238],\n",
      "        [-3.4813],\n",
      "        [-1.3076]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第12次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第12次反向传播后的梯度为:\n",
      "tensor([-0.4550]) tensor([-1.2051]) tensor([[-2.8131],\n",
      "        [-3.8126],\n",
      "        [-1.1072],\n",
      "        [-3.0715],\n",
      "        [-1.1510],\n",
      "        [-4.9391],\n",
      "        [-2.2565],\n",
      "        [-1.0260],\n",
      "        [-4.5929],\n",
      "        [-2.6794],\n",
      "        [-2.4309],\n",
      "        [-1.4152],\n",
      "        [-2.7668],\n",
      "        [-4.4307],\n",
      "        [-3.7762],\n",
      "        [-1.3656],\n",
      "        [-1.1048],\n",
      "        [-2.5738],\n",
      "        [-3.7462],\n",
      "        [-1.2826]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第13次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第13次反向传播后的梯度为:\n",
      "tensor([-0.3807]) tensor([-1.0621]) tensor([[-2.9505],\n",
      "        [-4.0727],\n",
      "        [-1.0454],\n",
      "        [-3.2508],\n",
      "        [-1.1060],\n",
      "        [-5.3376],\n",
      "        [-2.3302],\n",
      "        [-0.9572],\n",
      "        [-4.9304],\n",
      "        [-2.8067],\n",
      "        [-2.5568],\n",
      "        [-1.3861],\n",
      "        [-2.8843],\n",
      "        [-4.7323],\n",
      "        [-4.0511],\n",
      "        [-1.3744],\n",
      "        [-1.0704],\n",
      "        [-2.7121],\n",
      "        [-4.0008],\n",
      "        [-1.2387]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第14次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第14次反向传播后的梯度为:\n",
      "tensor([-0.3159]) tensor([-0.9370]) tensor([[-3.0750],\n",
      "        [-4.3229],\n",
      "        [-0.9664],\n",
      "        [-3.4189],\n",
      "        [-1.0451],\n",
      "        [-5.7296],\n",
      "        [-2.3898],\n",
      "        [-0.8712],\n",
      "        [-5.2587],\n",
      "        [-2.9212],\n",
      "        [-2.6718],\n",
      "        [-1.3404],\n",
      "        [-2.9875],\n",
      "        [-5.0227],\n",
      "        [-4.3179],\n",
      "        [-1.3703],\n",
      "        [-1.0214],\n",
      "        [-2.8396],\n",
      "        [-4.2455],\n",
      "        [-1.1778]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第15次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第15次反向传播后的梯度为:\n",
      "tensor([-0.2593]) tensor([-0.8277]) tensor([[-3.1878],\n",
      "        [-4.5640],\n",
      "        [-0.8722],\n",
      "        [-3.5767],\n",
      "        [-0.9699],\n",
      "        [-6.1153],\n",
      "        [-2.4366],\n",
      "        [-0.7699],\n",
      "        [-5.5783],\n",
      "        [-3.0242],\n",
      "        [-2.7770],\n",
      "        [-1.2797],\n",
      "        [-3.0777],\n",
      "        [-5.3028],\n",
      "        [-4.5768],\n",
      "        [-1.3547],\n",
      "        [-0.9593],\n",
      "        [-2.9572],\n",
      "        [-4.4810],\n",
      "        [-1.1018]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第16次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第16次反向传播后的梯度为:\n",
      "tensor([-0.2100]) tensor([-0.7321]) tensor([[-3.2899],\n",
      "        [-4.7965],\n",
      "        [-0.7645],\n",
      "        [-3.7251],\n",
      "        [-0.8820],\n",
      "        [-6.4949],\n",
      "        [-2.4719],\n",
      "        [-0.6552],\n",
      "        [-5.8899],\n",
      "        [-3.1167],\n",
      "        [-2.8730],\n",
      "        [-1.2058],\n",
      "        [-3.1562],\n",
      "        [-5.5734],\n",
      "        [-4.8285],\n",
      "        [-1.3287],\n",
      "        [-0.8855],\n",
      "        [-3.0656],\n",
      "        [-4.7080],\n",
      "        [-1.0125]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第17次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第17次反向传播后的梯度为:\n",
      "tensor([-0.1670]) tensor([-0.6485]) tensor([[-3.3824],\n",
      "        [-5.0211],\n",
      "        [-0.6448],\n",
      "        [-3.8650],\n",
      "        [-0.7829],\n",
      "        [-6.8685],\n",
      "        [-2.4969],\n",
      "        [-0.5285],\n",
      "        [-6.1939],\n",
      "        [-3.1997],\n",
      "        [-2.9607],\n",
      "        [-1.1202],\n",
      "        [-3.2243],\n",
      "        [-5.8354],\n",
      "        [-5.0733],\n",
      "        [-1.2933],\n",
      "        [-0.8013],\n",
      "        [-3.1657],\n",
      "        [-4.9272],\n",
      "        [-0.9113]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第18次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第18次反向传播后的梯度为:\n",
      "tensor([-0.1295]) tensor([-0.5754]) tensor([[-3.4665],\n",
      "        [-5.2387],\n",
      "        [-0.5148],\n",
      "        [-3.9971],\n",
      "        [-0.6739],\n",
      "        [-7.2365],\n",
      "        [-2.5129],\n",
      "        [-0.3915],\n",
      "        [-6.4911],\n",
      "        [-3.2743],\n",
      "        [-3.0410],\n",
      "        [-1.0244],\n",
      "        [-3.2833],\n",
      "        [-6.0896],\n",
      "        [-5.3117],\n",
      "        [-1.2495],\n",
      "        [-0.7079],\n",
      "        [-3.2582],\n",
      "        [-5.1392],\n",
      "        [-0.7998]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第19次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第19次反向传播后的梯度为:\n",
      "tensor([-0.0968]) tensor([-0.5114]) tensor([[-3.5429],\n",
      "        [-5.4497],\n",
      "        [-0.3757],\n",
      "        [-4.1223],\n",
      "        [-0.5563],\n",
      "        [-7.5993],\n",
      "        [-2.5208],\n",
      "        [-0.2454],\n",
      "        [-6.7819],\n",
      "        [-3.3414],\n",
      "        [-3.1144],\n",
      "        [-0.9198],\n",
      "        [-3.3341],\n",
      "        [-6.3367],\n",
      "        [-5.5442],\n",
      "        [-1.1982],\n",
      "        [-0.6063],\n",
      "        [-3.3440],\n",
      "        [-5.3448],\n",
      "        [-0.6793]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第20次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第20次反向传播后的梯度为:\n",
      "tensor([-0.0684]) tensor([-0.4555]) tensor([[-3.6127],\n",
      "        [-5.6547],\n",
      "        [-0.2287],\n",
      "        [-4.2412],\n",
      "        [-0.4312],\n",
      "        [-7.9570],\n",
      "        [-2.5217],\n",
      "        [-0.0915],\n",
      "        [-7.0670],\n",
      "        [-3.4018],\n",
      "        [-3.1817],\n",
      "        [-0.8074],\n",
      "        [-3.3778],\n",
      "        [-6.5775],\n",
      "        [-5.7713],\n",
      "        [-1.1404],\n",
      "        [-0.4977],\n",
      "        [-3.4236],\n",
      "        [-5.5445],\n",
      "        [-0.5510]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第21次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第21次反向传播后的梯度为:\n",
      "tensor([-0.0436]) tensor([-0.4066]) tensor([[-3.6764],\n",
      "        [-5.8544],\n",
      "        [-0.0750],\n",
      "        [-4.3545],\n",
      "        [-0.2996],\n",
      "        [-8.3099],\n",
      "        [-2.5164],\n",
      "        [ 0.0691],\n",
      "        [-7.3468],\n",
      "        [-3.4563],\n",
      "        [-3.2435],\n",
      "        [-0.6883],\n",
      "        [-3.4153],\n",
      "        [-6.8127],\n",
      "        [-5.9933],\n",
      "        [-1.0766],\n",
      "        [-0.3828],\n",
      "        [-3.4977],\n",
      "        [-5.7387],\n",
      "        [-0.4160]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第22次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第22次反向传播后的梯度为:\n",
      "tensor([-0.0221]) tensor([-0.3638]) tensor([[-3.7350],\n",
      "        [-6.0492],\n",
      "        [ 0.0844],\n",
      "        [-4.4627],\n",
      "        [-0.1625],\n",
      "        [-8.6584],\n",
      "        [-2.5058],\n",
      "        [ 0.2355],\n",
      "        [-7.6218],\n",
      "        [-3.5056],\n",
      "        [-3.3003],\n",
      "        [-0.5636],\n",
      "        [-3.4473],\n",
      "        [-7.0428],\n",
      "        [-6.2106],\n",
      "        [-1.0077],\n",
      "        [-0.2625],\n",
      "        [-3.5668],\n",
      "        [-5.9281],\n",
      "        [-0.2753]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第23次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第23次反向传播后的梯度为:\n",
      "tensor([-0.0034]) tensor([-0.3263]) tensor([[-3.7889],\n",
      "        [-6.2396],\n",
      "        [ 0.2487],\n",
      "        [-4.5665],\n",
      "        [-0.0205],\n",
      "        [-9.0026],\n",
      "        [-2.4904],\n",
      "        [ 0.4067],\n",
      "        [-7.8923],\n",
      "        [-3.5503],\n",
      "        [-3.3527],\n",
      "        [-0.4340],\n",
      "        [-3.4746],\n",
      "        [-7.2684],\n",
      "        [-6.4236],\n",
      "        [-0.9342],\n",
      "        [-0.1375],\n",
      "        [-3.6314],\n",
      "        [-6.1131],\n",
      "        [-0.1298]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第24次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第24次反向传播后的梯度为:\n",
      "tensor([0.0129]) tensor([-0.2935]) tensor([[-3.8387e+00],\n",
      "        [-6.4259e+00],\n",
      "        [ 4.1707e-01],\n",
      "        [-4.6661e+00],\n",
      "        [ 1.2558e-01],\n",
      "        [-9.3428e+00],\n",
      "        [-2.4709e+00],\n",
      "        [ 5.8207e-01],\n",
      "        [-8.1589e+00],\n",
      "        [-3.5909e+00],\n",
      "        [-3.4010e+00],\n",
      "        [-3.0034e-01],\n",
      "        [-3.4979e+00],\n",
      "        [-7.4899e+00],\n",
      "        [-6.6326e+00],\n",
      "        [-8.5657e-01],\n",
      "        [-8.3698e-03],\n",
      "        [-3.6919e+00],\n",
      "        [-6.2940e+00],\n",
      "        [ 1.9906e-02]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第25次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第25次反向传播后的梯度为:\n",
      "tensor([0.0270]) tensor([-0.2648]) tensor([[-3.8850],\n",
      "        [-6.6086],\n",
      "        [ 0.5889],\n",
      "        [-4.7622],\n",
      "        [ 0.2751],\n",
      "        [-9.6793],\n",
      "        [-2.4480],\n",
      "        [ 0.7608],\n",
      "        [-8.4217],\n",
      "        [-3.6279],\n",
      "        [-3.4457],\n",
      "        [-0.1632],\n",
      "        [-3.5176],\n",
      "        [-7.7078],\n",
      "        [-6.8379],\n",
      "        [-0.7754],\n",
      "        [ 0.1242],\n",
      "        [-3.7489],\n",
      "        [-6.4712],\n",
      "        [ 0.1730]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第26次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第26次反向传播后的梯度为:\n",
      "tensor([0.0392]) tensor([-0.2396]) tensor([[ -3.9282],\n",
      "        [ -6.7879],\n",
      "        [  0.7635],\n",
      "        [ -4.8550],\n",
      "        [  0.4275],\n",
      "        [-10.0121],\n",
      "        [ -2.4219],\n",
      "        [  0.9424],\n",
      "        [ -8.6812],\n",
      "        [ -3.6618],\n",
      "        [ -3.4870],\n",
      "        [ -0.0233],\n",
      "        [ -3.5343],\n",
      "        [ -7.9224],\n",
      "        [ -7.0396],\n",
      "        [ -0.6911],\n",
      "        [  0.2599],\n",
      "        [ -3.8025],\n",
      "        [ -6.6451],\n",
      "        [  0.3289]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第27次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第27次反向传播后的梯度为:\n",
      "tensor([0.0498]) tensor([-0.2176]) tensor([[ -3.9686],\n",
      "        [ -6.9642],\n",
      "        [  0.9404],\n",
      "        [ -4.9449],\n",
      "        [  0.5824],\n",
      "        [-10.3415],\n",
      "        [ -2.3933],\n",
      "        [  1.1263],\n",
      "        [ -8.9375],\n",
      "        [ -3.6930],\n",
      "        [ -3.5254],\n",
      "        [  0.1190],\n",
      "        [ -3.5485],\n",
      "        [ -8.1342],\n",
      "        [ -7.2382],\n",
      "        [ -0.6040],\n",
      "        [  0.3981],\n",
      "        [ -3.8532],\n",
      "        [ -6.8160],\n",
      "        [  0.4871]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第28次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第28次反向传播后的梯度为:\n",
      "tensor([0.0590]) tensor([-0.1983]) tensor([[ -4.0066],\n",
      "        [ -7.1376],\n",
      "        [  1.1192],\n",
      "        [ -5.0321],\n",
      "        [  0.7393],\n",
      "        [-10.6677],\n",
      "        [ -2.3625],\n",
      "        [  1.3120],\n",
      "        [ -9.1910],\n",
      "        [ -3.7217],\n",
      "        [ -3.5611],\n",
      "        [  0.2632],\n",
      "        [ -3.5604],\n",
      "        [ -8.3434],\n",
      "        [ -7.4336],\n",
      "        [ -0.5144],\n",
      "        [  0.5385],\n",
      "        [ -3.9012],\n",
      "        [ -6.9840],\n",
      "        [  0.6472]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第29次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第29次反向传播后的梯度为:\n",
      "tensor([0.0669]) tensor([-0.1814]) tensor([[ -4.0426],\n",
      "        [ -7.3085],\n",
      "        [  1.2993],\n",
      "        [ -5.1170],\n",
      "        [  0.8977],\n",
      "        [-10.9907],\n",
      "        [ -2.3298],\n",
      "        [  1.4991],\n",
      "        [ -9.4418],\n",
      "        [ -3.7483],\n",
      "        [ -3.5943],\n",
      "        [  0.4089],\n",
      "        [ -3.5705],\n",
      "        [ -8.5502],\n",
      "        [ -7.6263],\n",
      "        [ -0.4227],\n",
      "        [  0.6807],\n",
      "        [ -3.9467],\n",
      "        [ -7.1494],\n",
      "        [  0.8087]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第30次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第30次反向传播后的梯度为:\n",
      "tensor([0.0737]) tensor([-0.1666]) tensor([[ -4.0767],\n",
      "        [ -7.4770],\n",
      "        [  1.4806],\n",
      "        [ -5.1997],\n",
      "        [  1.0575],\n",
      "        [-11.3107],\n",
      "        [ -2.2955],\n",
      "        [  1.6873],\n",
      "        [ -9.6901],\n",
      "        [ -3.7731],\n",
      "        [ -3.6253],\n",
      "        [  0.5557],\n",
      "        [ -3.5791],\n",
      "        [ -8.7549],\n",
      "        [ -7.8162],\n",
      "        [ -0.3291],\n",
      "        [  0.8245],\n",
      "        [ -3.9900],\n",
      "        [ -7.3125],\n",
      "        [  0.9714]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第31次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第31次反向传播后的梯度为:\n",
      "tensor([0.0796]) tensor([-0.1536]) tensor([[ -4.1092],\n",
      "        [ -7.6433],\n",
      "        [  1.6625],\n",
      "        [ -5.2805],\n",
      "        [  1.2182],\n",
      "        [-11.6279],\n",
      "        [ -2.2598],\n",
      "        [  1.8763],\n",
      "        [ -9.9361],\n",
      "        [ -3.7962],\n",
      "        [ -3.6542],\n",
      "        [  0.7033],\n",
      "        [ -3.5864],\n",
      "        [ -8.9577],\n",
      "        [ -8.0036],\n",
      "        [ -0.2338],\n",
      "        [  0.9696],\n",
      "        [ -4.0312],\n",
      "        [ -7.4734],\n",
      "        [  1.1348]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第32次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第32次反向传播后的梯度为:\n",
      "tensor([0.0846]) tensor([-0.1421]) tensor([[ -4.1403],\n",
      "        [ -7.8076],\n",
      "        [  1.8450],\n",
      "        [ -5.3595],\n",
      "        [  1.3798],\n",
      "        [-11.9422],\n",
      "        [ -2.2230],\n",
      "        [  2.0657],\n",
      "        [-10.1799],\n",
      "        [ -3.8179],\n",
      "        [ -3.6813],\n",
      "        [  0.8516],\n",
      "        [ -3.5926],\n",
      "        [ -9.1588],\n",
      "        [ -8.1885],\n",
      "        [ -0.1371],\n",
      "        [  1.1157],\n",
      "        [ -4.0706],\n",
      "        [ -7.6322],\n",
      "        [  1.2987]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第33次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第33次反向传播后的梯度为:\n",
      "tensor([0.0889]) tensor([-0.1321]) tensor([[ -4.1703],\n",
      "        [ -7.9699],\n",
      "        [  2.0277],\n",
      "        [ -5.4369],\n",
      "        [  1.5418],\n",
      "        [-12.2539],\n",
      "        [ -2.1853],\n",
      "        [  2.2554],\n",
      "        [-10.4217],\n",
      "        [ -3.8383],\n",
      "        [ -3.7066],\n",
      "        [  1.0001],\n",
      "        [ -3.5980],\n",
      "        [ -9.3583],\n",
      "        [ -8.3712],\n",
      "        [ -0.0391],\n",
      "        [  1.2627],\n",
      "        [ -4.1083],\n",
      "        [ -7.7890],\n",
      "        [  1.4629]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第34次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第34次反向传播后的梯度为:\n",
      "tensor([0.0926]) tensor([-0.1233]) tensor([[ -4.1992],\n",
      "        [ -8.1305],\n",
      "        [  2.2105],\n",
      "        [ -5.5129],\n",
      "        [  1.7042],\n",
      "        [-12.5630],\n",
      "        [ -2.1468],\n",
      "        [  2.4452],\n",
      "        [-10.6616],\n",
      "        [ -3.8576],\n",
      "        [ -3.7304],\n",
      "        [  1.1489],\n",
      "        [ -3.6026],\n",
      "        [ -9.5564],\n",
      "        [ -8.5516],\n",
      "        [  0.0600],\n",
      "        [  1.4104],\n",
      "        [ -4.1444],\n",
      "        [ -7.9441],\n",
      "        [  1.6272]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第35次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第35次反向传播后的梯度为:\n",
      "tensor([0.0957]) tensor([-0.1156]) tensor([[ -4.2271],\n",
      "        [ -8.2894],\n",
      "        [  2.3931],\n",
      "        [ -5.5874],\n",
      "        [  1.8668],\n",
      "        [-12.8695],\n",
      "        [ -2.1078],\n",
      "        [  2.6348],\n",
      "        [-10.8996],\n",
      "        [ -3.8760],\n",
      "        [ -3.7526],\n",
      "        [  1.2976],\n",
      "        [ -3.6068],\n",
      "        [ -9.7531],\n",
      "        [ -8.7299],\n",
      "        [  0.1602],\n",
      "        [  1.5587],\n",
      "        [ -4.1791],\n",
      "        [ -8.0975],\n",
      "        [  1.7915]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第36次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第36次反向传播后的梯度为:\n",
      "tensor([0.0983]) tensor([-0.1087]) tensor([[ -4.2543],\n",
      "        [ -8.4467],\n",
      "        [  2.5755],\n",
      "        [ -5.6607],\n",
      "        [  2.0294],\n",
      "        [-13.1736],\n",
      "        [ -2.0682],\n",
      "        [  2.8242],\n",
      "        [-11.1359],\n",
      "        [ -3.8935],\n",
      "        [ -3.7735],\n",
      "        [  1.4461],\n",
      "        [ -3.6105],\n",
      "        [ -9.9487],\n",
      "        [ -8.9063],\n",
      "        [  0.2612],\n",
      "        [  1.7073],\n",
      "        [ -4.2123],\n",
      "        [ -8.2494],\n",
      "        [  1.9555]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第37次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第37次反向传播后的梯度为:\n",
      "tensor([0.1005]) tensor([-0.1027]) tensor([[ -4.2807],\n",
      "        [ -8.6025],\n",
      "        [  2.7574],\n",
      "        [ -5.7329],\n",
      "        [  2.1919],\n",
      "        [-13.4753],\n",
      "        [ -2.0283],\n",
      "        [  3.0132],\n",
      "        [-11.3706],\n",
      "        [ -3.9102],\n",
      "        [ -3.7932],\n",
      "        [  1.5944],\n",
      "        [ -3.6139],\n",
      "        [-10.1431],\n",
      "        [ -9.0806],\n",
      "        [  0.3630],\n",
      "        [  1.8562],\n",
      "        [ -4.2444],\n",
      "        [ -8.3997],\n",
      "        [  2.1191]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第38次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第38次反向传播后的梯度为:\n",
      "tensor([0.1024]) tensor([-0.0974]) tensor([[ -4.3066],\n",
      "        [ -8.7570],\n",
      "        [  2.9389],\n",
      "        [ -5.8040],\n",
      "        [  2.3542],\n",
      "        [-13.7747],\n",
      "        [ -1.9881],\n",
      "        [  3.2016],\n",
      "        [-11.6036],\n",
      "        [ -3.9263],\n",
      "        [ -3.8116],\n",
      "        [  1.7423],\n",
      "        [ -3.6171],\n",
      "        [-10.3364],\n",
      "        [ -9.2531],\n",
      "        [  0.4654],\n",
      "        [  2.0053],\n",
      "        [ -4.2752],\n",
      "        [ -8.5486],\n",
      "        [  2.2823]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第39次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第39次反向传播后的梯度为:\n",
      "tensor([0.1039]) tensor([-0.0928]) tensor([[ -4.3319],\n",
      "        [ -8.9100],\n",
      "        [  3.1197],\n",
      "        [ -5.8741],\n",
      "        [  2.5163],\n",
      "        [-14.0718],\n",
      "        [ -1.9477],\n",
      "        [  3.3895],\n",
      "        [-11.8352],\n",
      "        [ -3.9418],\n",
      "        [ -3.8289],\n",
      "        [  1.8896],\n",
      "        [ -3.6201],\n",
      "        [-10.5288],\n",
      "        [ -9.4238],\n",
      "        [  0.5685],\n",
      "        [  2.1545],\n",
      "        [ -4.3049],\n",
      "        [ -8.6961],\n",
      "        [  2.4449]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第40次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第40次反向传播后的梯度为:\n",
      "tensor([0.1051]) tensor([-0.0886]) tensor([[ -4.3568],\n",
      "        [ -9.0618],\n",
      "        [  3.2998],\n",
      "        [ -5.9432],\n",
      "        [  2.6779],\n",
      "        [-14.3666],\n",
      "        [ -1.9072],\n",
      "        [  3.5766],\n",
      "        [-12.0652],\n",
      "        [ -3.9569],\n",
      "        [ -3.8451],\n",
      "        [  2.0364],\n",
      "        [ -3.6231],\n",
      "        [-10.7203],\n",
      "        [ -9.5927],\n",
      "        [  0.6721],\n",
      "        [  2.3037],\n",
      "        [ -4.3336],\n",
      "        [ -8.8423],\n",
      "        [  2.6069]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第41次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第41次反向传播后的梯度为:\n",
      "tensor([0.1061]) tensor([-0.0850]) tensor([[ -4.3813],\n",
      "        [ -9.2123],\n",
      "        [  3.4791],\n",
      "        [ -6.0115],\n",
      "        [  2.8392],\n",
      "        [-14.6592],\n",
      "        [ -1.8666],\n",
      "        [  3.7630],\n",
      "        [-12.2939],\n",
      "        [ -3.9714],\n",
      "        [ -3.8604],\n",
      "        [  2.1826],\n",
      "        [ -3.6262],\n",
      "        [-10.9109],\n",
      "        [ -9.7599],\n",
      "        [  0.7761],\n",
      "        [  2.4528],\n",
      "        [ -4.3613],\n",
      "        [ -8.9873],\n",
      "        [  2.7681]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第42次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第42次反向传播后的梯度为:\n",
      "tensor([0.1069]) tensor([-0.0817]) tensor([[ -4.4054],\n",
      "        [ -9.3616],\n",
      "        [  3.6576],\n",
      "        [ -6.0789],\n",
      "        [  2.9999],\n",
      "        [-14.9497],\n",
      "        [ -1.8261],\n",
      "        [  3.9486],\n",
      "        [-12.5211],\n",
      "        [ -3.9856],\n",
      "        [ -3.8747],\n",
      "        [  2.3280],\n",
      "        [ -3.6293],\n",
      "        [-11.1006],\n",
      "        [ -9.9254],\n",
      "        [  0.8805],\n",
      "        [  2.6019],\n",
      "        [ -4.3881],\n",
      "        [ -9.1310],\n",
      "        [  2.9286]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第43次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第43次反向传播后的梯度为:\n",
      "tensor([0.1075]) tensor([-0.0788]) tensor([[ -4.4292],\n",
      "        [ -9.5098],\n",
      "        [  3.8353],\n",
      "        [ -6.1455],\n",
      "        [  3.1601],\n",
      "        [-15.2381],\n",
      "        [ -1.7856],\n",
      "        [  4.1333],\n",
      "        [-12.7471],\n",
      "        [ -3.9994],\n",
      "        [ -3.8881],\n",
      "        [  2.4727],\n",
      "        [ -3.6324],\n",
      "        [-11.2896],\n",
      "        [-10.0893],\n",
      "        [  0.9853],\n",
      "        [  2.7507],\n",
      "        [ -4.4139],\n",
      "        [ -9.2736],\n",
      "        [  3.0882]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第44次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第44次反向传播后的梯度为:\n",
      "tensor([0.1079]) tensor([-0.0763]) tensor([[ -4.4528],\n",
      "        [ -9.6568],\n",
      "        [  4.0120],\n",
      "        [ -6.2114],\n",
      "        [  3.3197],\n",
      "        [-15.5243],\n",
      "        [ -1.7451],\n",
      "        [  4.3170],\n",
      "        [-12.9717],\n",
      "        [ -4.0129],\n",
      "        [ -3.9007],\n",
      "        [  2.6166],\n",
      "        [ -3.6358],\n",
      "        [-11.4778],\n",
      "        [-10.2516],\n",
      "        [  1.0904],\n",
      "        [  2.8994],\n",
      "        [ -4.4390],\n",
      "        [ -9.4151],\n",
      "        [  3.2469]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第45次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第45次反向传播后的梯度为:\n",
      "tensor([0.1082]) tensor([-0.0740]) tensor([[ -4.4761],\n",
      "        [ -9.8028],\n",
      "        [  4.1877],\n",
      "        [ -6.2766],\n",
      "        [  3.4787],\n",
      "        [-15.8086],\n",
      "        [ -1.7049],\n",
      "        [  4.4999],\n",
      "        [-13.1950],\n",
      "        [ -4.0261],\n",
      "        [ -3.9124],\n",
      "        [  2.7597],\n",
      "        [ -3.6393],\n",
      "        [-11.6653],\n",
      "        [-10.4123],\n",
      "        [  1.1957],\n",
      "        [  3.0478],\n",
      "        [ -4.4632],\n",
      "        [ -9.5554],\n",
      "        [  3.4048]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第46次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第46次反向传播后的梯度为:\n",
      "tensor([0.1084]) tensor([-0.0719]) tensor([[ -4.4992],\n",
      "        [ -9.9477],\n",
      "        [  4.3624],\n",
      "        [ -6.3411],\n",
      "        [  3.6370],\n",
      "        [-16.0908],\n",
      "        [ -1.6647],\n",
      "        [  4.6817],\n",
      "        [-13.4171],\n",
      "        [ -4.0390],\n",
      "        [ -3.9233],\n",
      "        [  2.9019],\n",
      "        [ -3.6430],\n",
      "        [-11.8521],\n",
      "        [-10.5715],\n",
      "        [  1.3013],\n",
      "        [  3.1959],\n",
      "        [ -4.4866],\n",
      "        [ -9.6947],\n",
      "        [  3.5617]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第47次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第47次反向传播后的梯度为:\n",
      "tensor([0.1085]) tensor([-0.0701]) tensor([[ -4.5222],\n",
      "        [-10.0915],\n",
      "        [  4.5362],\n",
      "        [ -6.4049],\n",
      "        [  3.7946],\n",
      "        [-16.3710],\n",
      "        [ -1.6247],\n",
      "        [  4.8625],\n",
      "        [-13.6379],\n",
      "        [ -4.0518],\n",
      "        [ -3.9335],\n",
      "        [  3.0432],\n",
      "        [ -3.6469],\n",
      "        [-12.0382],\n",
      "        [-10.7293],\n",
      "        [  1.4071],\n",
      "        [  3.3438],\n",
      "        [ -4.5093],\n",
      "        [ -9.8330],\n",
      "        [  3.7177]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第48次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第48次反向传播后的梯度为:\n",
      "tensor([0.1084]) tensor([-0.0685]) tensor([[ -4.5449],\n",
      "        [-10.2344],\n",
      "        [  4.7089],\n",
      "        [ -6.4681],\n",
      "        [  3.9515],\n",
      "        [-16.6492],\n",
      "        [ -1.5850],\n",
      "        [  5.0423],\n",
      "        [-13.8576],\n",
      "        [ -4.0643],\n",
      "        [ -3.9429],\n",
      "        [  3.1836],\n",
      "        [ -3.6511],\n",
      "        [-12.2237],\n",
      "        [-10.8855],\n",
      "        [  1.5130],\n",
      "        [  3.4913],\n",
      "        [ -4.5312],\n",
      "        [ -9.9702],\n",
      "        [  3.8726]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第49次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第49次反向传播后的梯度为:\n",
      "tensor([0.1083]) tensor([-0.0670]) tensor([[ -4.5676],\n",
      "        [-10.3763],\n",
      "        [  4.8805],\n",
      "        [ -6.5307],\n",
      "        [  4.1077],\n",
      "        [-16.9255],\n",
      "        [ -1.5454],\n",
      "        [  5.2210],\n",
      "        [-14.0761],\n",
      "        [ -4.0766],\n",
      "        [ -3.9517],\n",
      "        [  3.3231],\n",
      "        [ -3.6555],\n",
      "        [-12.4085],\n",
      "        [-11.0403],\n",
      "        [  1.6191],\n",
      "        [  3.6384],\n",
      "        [ -4.5525],\n",
      "        [-10.1064],\n",
      "        [  4.0266]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第50次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第50次反向传播后的梯度为:\n",
      "tensor([0.1081]) tensor([-0.0657]) tensor([[ -4.5901],\n",
      "        [-10.5172],\n",
      "        [  5.0511],\n",
      "        [ -6.5927],\n",
      "        [  4.2631],\n",
      "        [-17.1998],\n",
      "        [ -1.5061],\n",
      "        [  5.3987],\n",
      "        [-14.2934],\n",
      "        [ -4.0888],\n",
      "        [ -3.9597],\n",
      "        [  3.4616],\n",
      "        [ -3.6603],\n",
      "        [-12.5927],\n",
      "        [-11.1937],\n",
      "        [  1.7253],\n",
      "        [  3.7852],\n",
      "        [ -4.5730],\n",
      "        [-10.2417],\n",
      "        [  4.1796]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第51次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第51次反向传播后的梯度为:\n",
      "tensor([0.1079]) tensor([-0.0644]) tensor([[ -4.6126],\n",
      "        [-10.6571],\n",
      "        [  5.2206],\n",
      "        [ -6.6541],\n",
      "        [  4.4178],\n",
      "        [-17.4723],\n",
      "        [ -1.4671],\n",
      "        [  5.5753],\n",
      "        [-14.5095],\n",
      "        [ -4.1009],\n",
      "        [ -3.9671],\n",
      "        [  3.5992],\n",
      "        [ -3.6653],\n",
      "        [-12.7763],\n",
      "        [-11.3457],\n",
      "        [  1.8317],\n",
      "        [  3.9315],\n",
      "        [ -4.5930],\n",
      "        [-10.3760],\n",
      "        [  4.3316]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第52次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第52次反向传播后的梯度为:\n",
      "tensor([0.1076]) tensor([-0.0633]) tensor([[ -4.6349],\n",
      "        [-10.7961],\n",
      "        [  5.3890],\n",
      "        [ -6.7149],\n",
      "        [  4.5717],\n",
      "        [-17.7429],\n",
      "        [ -1.4282],\n",
      "        [  5.7508],\n",
      "        [-14.7246],\n",
      "        [ -4.1127],\n",
      "        [ -3.9739],\n",
      "        [  3.7359],\n",
      "        [ -3.6706],\n",
      "        [-12.9593],\n",
      "        [-11.4963],\n",
      "        [  1.9381],\n",
      "        [  4.0775],\n",
      "        [ -4.6122],\n",
      "        [-10.5094],\n",
      "        [  4.4825]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第53次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第53次反向传播后的梯度为:\n",
      "tensor([0.1073]) tensor([-0.0623]) tensor([[ -4.6571],\n",
      "        [-10.9343],\n",
      "        [  5.5563],\n",
      "        [ -6.7752],\n",
      "        [  4.7249],\n",
      "        [-18.0117],\n",
      "        [ -1.3897],\n",
      "        [  5.9252],\n",
      "        [-14.9385],\n",
      "        [ -4.1245],\n",
      "        [ -3.9800],\n",
      "        [  3.8716],\n",
      "        [ -3.6761],\n",
      "        [-13.1416],\n",
      "        [-11.6456],\n",
      "        [  2.0445],\n",
      "        [  4.2231],\n",
      "        [ -4.6309],\n",
      "        [-10.6418],\n",
      "        [  4.6324]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第54次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第54次反向传播后的梯度为:\n",
      "tensor([0.1069]) tensor([-0.0614]) tensor([[ -4.6793],\n",
      "        [-11.0715],\n",
      "        [  5.7225],\n",
      "        [ -6.8350],\n",
      "        [  4.8773],\n",
      "        [-18.2786],\n",
      "        [ -1.3514],\n",
      "        [  6.0985],\n",
      "        [-15.1513],\n",
      "        [ -4.1362],\n",
      "        [ -3.9855],\n",
      "        [  4.0063],\n",
      "        [ -3.6820],\n",
      "        [-13.3234],\n",
      "        [-11.7935],\n",
      "        [  2.1511],\n",
      "        [  4.3682],\n",
      "        [ -4.6489],\n",
      "        [-10.7734],\n",
      "        [  4.7812]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第55次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第55次反向传播后的梯度为:\n",
      "tensor([0.1065]) tensor([-0.0606]) tensor([[ -4.7014],\n",
      "        [-11.2078],\n",
      "        [  5.8877],\n",
      "        [ -6.8942],\n",
      "        [  5.0288],\n",
      "        [-18.5437],\n",
      "        [ -1.3134],\n",
      "        [  6.2708],\n",
      "        [-15.3630],\n",
      "        [ -4.1477],\n",
      "        [ -3.9904],\n",
      "        [  4.1401],\n",
      "        [ -3.6882],\n",
      "        [-13.5046],\n",
      "        [-11.9401],\n",
      "        [  2.2576],\n",
      "        [  4.5129],\n",
      "        [ -4.6664],\n",
      "        [-10.9040],\n",
      "        [  4.9291]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第56次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第56次反向传播后的梯度为:\n",
      "tensor([0.1060]) tensor([-0.0598]) tensor([[ -4.7235],\n",
      "        [-11.3432],\n",
      "        [  6.0517],\n",
      "        [ -6.9530],\n",
      "        [  5.1796],\n",
      "        [-18.8069],\n",
      "        [ -1.2757],\n",
      "        [  6.4420],\n",
      "        [-15.5736],\n",
      "        [ -4.1592],\n",
      "        [ -3.9948],\n",
      "        [  4.2729],\n",
      "        [ -3.6948],\n",
      "        [-13.6853],\n",
      "        [-12.0854],\n",
      "        [  2.3643],\n",
      "        [  4.6571],\n",
      "        [ -4.6833],\n",
      "        [-11.0338],\n",
      "        [  5.0759]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第57次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第57次反向传播后的梯度为:\n",
      "tensor([0.1056]) tensor([-0.0590]) tensor([[ -4.7455],\n",
      "        [-11.4778],\n",
      "        [  6.2147],\n",
      "        [ -7.0112],\n",
      "        [  5.3297],\n",
      "        [-19.0685],\n",
      "        [ -1.2383],\n",
      "        [  6.6120],\n",
      "        [-15.7832],\n",
      "        [ -4.1705],\n",
      "        [ -3.9985],\n",
      "        [  4.4048],\n",
      "        [ -3.7016],\n",
      "        [-13.8653],\n",
      "        [-12.2294],\n",
      "        [  2.4709],\n",
      "        [  4.8009],\n",
      "        [ -4.6996],\n",
      "        [-11.1627],\n",
      "        [  5.2216]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第58次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第58次反向传播后的梯度为:\n",
      "tensor([0.1051]) tensor([-0.0584]) tensor([[ -4.7674],\n",
      "        [-11.6115],\n",
      "        [  6.3766],\n",
      "        [ -7.0690],\n",
      "        [  5.4789],\n",
      "        [-19.3282],\n",
      "        [ -1.2012],\n",
      "        [  6.7810],\n",
      "        [-15.9917],\n",
      "        [ -4.1818],\n",
      "        [ -4.0018],\n",
      "        [  4.5357],\n",
      "        [ -3.7087],\n",
      "        [-14.0448],\n",
      "        [-12.3722],\n",
      "        [  2.5775],\n",
      "        [  4.9443],\n",
      "        [ -4.7154],\n",
      "        [-11.2907],\n",
      "        [  5.3664]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第59次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第59次反向传播后的梯度为:\n",
      "tensor([0.1046]) tensor([-0.0577]) tensor([[ -4.7893],\n",
      "        [-11.7444],\n",
      "        [  6.5374],\n",
      "        [ -7.1262],\n",
      "        [  5.6273],\n",
      "        [-19.5862],\n",
      "        [ -1.1643],\n",
      "        [  6.9489],\n",
      "        [-16.1991],\n",
      "        [ -4.1930],\n",
      "        [ -4.0045],\n",
      "        [  4.6657],\n",
      "        [ -3.7162],\n",
      "        [-14.2238],\n",
      "        [-12.5137],\n",
      "        [  2.6841],\n",
      "        [  5.0871],\n",
      "        [ -4.7306],\n",
      "        [-11.4179],\n",
      "        [  5.5101]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第60次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第60次反向传播后的梯度为:\n",
      "tensor([0.1041]) tensor([-0.0571]) tensor([[ -4.8111],\n",
      "        [-11.8765],\n",
      "        [  6.6971],\n",
      "        [ -7.1830],\n",
      "        [  5.7749],\n",
      "        [-19.8425],\n",
      "        [ -1.1278],\n",
      "        [  7.1158],\n",
      "        [-16.4055],\n",
      "        [ -4.2041],\n",
      "        [ -4.0066],\n",
      "        [  4.7947],\n",
      "        [ -3.7239],\n",
      "        [-14.4022],\n",
      "        [-12.6540],\n",
      "        [  2.7907],\n",
      "        [  5.2295],\n",
      "        [ -4.7453],\n",
      "        [-11.5443],\n",
      "        [  5.6528]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第61次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第61次反向传播后的梯度为:\n",
      "tensor([0.1035]) tensor([-0.0566]) tensor([[ -4.8330],\n",
      "        [-12.0077],\n",
      "        [  6.8557],\n",
      "        [ -7.2393],\n",
      "        [  5.9218],\n",
      "        [-20.0971],\n",
      "        [ -1.0916],\n",
      "        [  7.2815],\n",
      "        [-16.6109],\n",
      "        [ -4.2151],\n",
      "        [ -4.0083],\n",
      "        [  4.9227],\n",
      "        [ -3.7320],\n",
      "        [-14.5800],\n",
      "        [-12.7931],\n",
      "        [  2.8973],\n",
      "        [  5.3715],\n",
      "        [ -4.7595],\n",
      "        [-11.6698],\n",
      "        [  5.7945]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第62次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第62次反向传播后的梯度为:\n",
      "tensor([0.1030]) tensor([-0.0560]) tensor([[ -4.8547],\n",
      "        [-12.1381],\n",
      "        [  7.0133],\n",
      "        [ -7.2952],\n",
      "        [  6.0679],\n",
      "        [-20.3500],\n",
      "        [ -1.0556],\n",
      "        [  7.4462],\n",
      "        [-16.8152],\n",
      "        [ -4.2261],\n",
      "        [ -4.0094],\n",
      "        [  5.0499],\n",
      "        [ -3.7403],\n",
      "        [-14.7573],\n",
      "        [-12.9309],\n",
      "        [  3.0039],\n",
      "        [  5.5130],\n",
      "        [ -4.7732],\n",
      "        [-11.7945],\n",
      "        [  5.9351]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第63次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第63次反向传播后的梯度为:\n",
      "tensor([0.1025]) tensor([-0.0555]) tensor([[ -4.8765],\n",
      "        [-12.2677],\n",
      "        [  7.1698],\n",
      "        [ -7.3506],\n",
      "        [  6.2131],\n",
      "        [-20.6012],\n",
      "        [ -1.0199],\n",
      "        [  7.6098],\n",
      "        [-17.0185],\n",
      "        [ -4.2370],\n",
      "        [ -4.0100],\n",
      "        [  5.1760],\n",
      "        [ -3.7490],\n",
      "        [-14.9340],\n",
      "        [-13.0676],\n",
      "        [  3.1105],\n",
      "        [  5.6540],\n",
      "        [ -4.7863],\n",
      "        [-11.9184],\n",
      "        [  6.0748]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第64次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第64次反向传播后的梯度为:\n",
      "tensor([0.1019]) tensor([-0.0550]) tensor([[ -4.8982],\n",
      "        [-12.3965],\n",
      "        [  7.3253],\n",
      "        [ -7.4056],\n",
      "        [  6.3576],\n",
      "        [-20.8507],\n",
      "        [ -0.9846],\n",
      "        [  7.7724],\n",
      "        [-17.2209],\n",
      "        [ -4.2478],\n",
      "        [ -4.0102],\n",
      "        [  5.3013],\n",
      "        [ -3.7580],\n",
      "        [-15.1102],\n",
      "        [-13.2031],\n",
      "        [  3.2170],\n",
      "        [  5.7945],\n",
      "        [ -4.7990],\n",
      "        [-12.0415],\n",
      "        [  6.2134]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第65次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第65次反向传播后的梯度为:\n",
      "tensor([0.1013]) tensor([-0.0546]) tensor([[ -4.9199],\n",
      "        [-12.5245],\n",
      "        [  7.4797],\n",
      "        [ -7.4601],\n",
      "        [  6.5013],\n",
      "        [-21.0986],\n",
      "        [ -0.9495],\n",
      "        [  7.9339],\n",
      "        [-17.4222],\n",
      "        [ -4.2586],\n",
      "        [ -4.0099],\n",
      "        [  5.4256],\n",
      "        [ -3.7673],\n",
      "        [-15.2858],\n",
      "        [-13.3374],\n",
      "        [  3.3234],\n",
      "        [  5.9346],\n",
      "        [ -4.8112],\n",
      "        [-12.1638],\n",
      "        [  6.3511]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第66次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第66次反向传播后的梯度为:\n",
      "tensor([0.1008]) tensor([-0.0541]) tensor([[ -4.9415],\n",
      "        [-12.6517],\n",
      "        [  7.6330],\n",
      "        [ -7.5142],\n",
      "        [  6.6443],\n",
      "        [-21.3449],\n",
      "        [ -0.9147],\n",
      "        [  8.0944],\n",
      "        [-17.6225],\n",
      "        [ -4.2693],\n",
      "        [ -4.0091],\n",
      "        [  5.5491],\n",
      "        [ -3.7768],\n",
      "        [-15.4609],\n",
      "        [-13.4705],\n",
      "        [  3.4298],\n",
      "        [  6.0741],\n",
      "        [ -4.8230],\n",
      "        [-12.2853],\n",
      "        [  6.4878]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第67次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第67次反向传播后的梯度为:\n",
      "tensor([0.1002]) tensor([-0.0537]) tensor([[ -4.9631],\n",
      "        [-12.7782],\n",
      "        [  7.7853],\n",
      "        [ -7.5679],\n",
      "        [  6.7865],\n",
      "        [-21.5895],\n",
      "        [ -0.8802],\n",
      "        [  8.2538],\n",
      "        [-17.8219],\n",
      "        [ -4.2800],\n",
      "        [ -4.0078],\n",
      "        [  5.6716],\n",
      "        [ -3.7867],\n",
      "        [-15.6355],\n",
      "        [-13.6026],\n",
      "        [  3.5362],\n",
      "        [  6.2132],\n",
      "        [ -4.8342],\n",
      "        [-12.4060],\n",
      "        [  6.6235]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第68次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第68次反向传播后的梯度为:\n",
      "tensor([0.0996]) tensor([-0.0533]) tensor([[ -4.9847],\n",
      "        [-12.9039],\n",
      "        [  7.9366],\n",
      "        [ -7.6211],\n",
      "        [  6.9279],\n",
      "        [-21.8325],\n",
      "        [ -0.8460],\n",
      "        [  8.4122],\n",
      "        [-18.0202],\n",
      "        [ -4.2906],\n",
      "        [ -4.0061],\n",
      "        [  5.7932],\n",
      "        [ -3.7968],\n",
      "        [-15.8095],\n",
      "        [-13.7335],\n",
      "        [  3.6424],\n",
      "        [  6.3519],\n",
      "        [ -4.8450],\n",
      "        [-12.5260],\n",
      "        [  6.7582]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第69次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第69次反向传播后的梯度为:\n",
      "tensor([0.0990]) tensor([-0.0529]) tensor([[ -5.0063],\n",
      "        [-13.0288],\n",
      "        [  8.0869],\n",
      "        [ -7.6740],\n",
      "        [  7.0685],\n",
      "        [-22.0740],\n",
      "        [ -0.8121],\n",
      "        [  8.5696],\n",
      "        [-18.2176],\n",
      "        [ -4.3011],\n",
      "        [ -4.0039],\n",
      "        [  5.9139],\n",
      "        [ -3.8073],\n",
      "        [-15.9830],\n",
      "        [-13.8632],\n",
      "        [  3.7487],\n",
      "        [  6.4900],\n",
      "        [ -4.8554],\n",
      "        [-12.6452],\n",
      "        [  6.8920]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第70次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第70次反向传播后的梯度为:\n",
      "tensor([0.0985]) tensor([-0.0525]) tensor([[ -5.0278],\n",
      "        [-13.1530],\n",
      "        [  8.2362],\n",
      "        [ -7.7264],\n",
      "        [  7.2084],\n",
      "        [-22.3138],\n",
      "        [ -0.7785],\n",
      "        [  8.7259],\n",
      "        [-18.4140],\n",
      "        [ -4.3116],\n",
      "        [ -4.0014],\n",
      "        [  6.0337],\n",
      "        [ -3.8180],\n",
      "        [-16.1559],\n",
      "        [-13.9919],\n",
      "        [  3.8548],\n",
      "        [  6.6277],\n",
      "        [ -4.8653],\n",
      "        [-12.7637],\n",
      "        [  7.0248]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第71次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第71次反向传播后的梯度为:\n",
      "tensor([0.0979]) tensor([-0.0521]) tensor([[ -5.0493],\n",
      "        [-13.2764],\n",
      "        [  8.3844],\n",
      "        [ -7.7784],\n",
      "        [  7.3475],\n",
      "        [-22.5522],\n",
      "        [ -0.7452],\n",
      "        [  8.8813],\n",
      "        [-18.6095],\n",
      "        [ -4.3221],\n",
      "        [ -3.9983],\n",
      "        [  6.1527],\n",
      "        [ -3.8290],\n",
      "        [-16.3283],\n",
      "        [-14.1195],\n",
      "        [  3.9609],\n",
      "        [  6.7649],\n",
      "        [ -4.8748],\n",
      "        [-12.8814],\n",
      "        [  7.1567]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第72次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第72次反向传播后的梯度为:\n",
      "tensor([0.0973]) tensor([-0.0518]) tensor([[ -5.0708],\n",
      "        [-13.3990],\n",
      "        [  8.5317],\n",
      "        [ -7.8300],\n",
      "        [  7.4859],\n",
      "        [-22.7889],\n",
      "        [ -0.7121],\n",
      "        [  9.0356],\n",
      "        [-18.8040],\n",
      "        [ -4.3325],\n",
      "        [ -3.9949],\n",
      "        [  6.2707],\n",
      "        [ -3.8402],\n",
      "        [-16.5002],\n",
      "        [-14.2460],\n",
      "        [  4.0668],\n",
      "        [  6.9016],\n",
      "        [ -4.8839],\n",
      "        [-12.9983],\n",
      "        [  7.2876]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第73次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第73次反向传播后的梯度为:\n",
      "tensor([0.0967]) tensor([-0.0514]) tensor([[ -5.0922],\n",
      "        [-13.5210],\n",
      "        [  8.6780],\n",
      "        [ -7.8812],\n",
      "        [  7.6235],\n",
      "        [-23.0242],\n",
      "        [ -0.6793],\n",
      "        [  9.1890],\n",
      "        [-18.9976],\n",
      "        [ -4.3428],\n",
      "        [ -3.9910],\n",
      "        [  6.3879],\n",
      "        [ -3.8518],\n",
      "        [-16.6715],\n",
      "        [-14.3715],\n",
      "        [  4.1727],\n",
      "        [  7.0378],\n",
      "        [ -4.8925],\n",
      "        [-13.1145],\n",
      "        [  7.4176]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第74次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第74次反向传播后的梯度为:\n",
      "tensor([0.0962]) tensor([-0.0511]) tensor([[ -5.1136],\n",
      "        [-13.6422],\n",
      "        [  8.8233],\n",
      "        [ -7.9320],\n",
      "        [  7.7604],\n",
      "        [-23.2579],\n",
      "        [ -0.6468],\n",
      "        [  9.3414],\n",
      "        [-19.1902],\n",
      "        [ -4.3531],\n",
      "        [ -3.9868],\n",
      "        [  6.5043],\n",
      "        [ -3.8636],\n",
      "        [-16.8423],\n",
      "        [-14.4958],\n",
      "        [  4.2785],\n",
      "        [  7.1736],\n",
      "        [ -4.9007],\n",
      "        [-13.2300],\n",
      "        [  7.5466]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第75次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第75次反向传播后的梯度为:\n",
      "tensor([0.0956]) tensor([-0.0507]) tensor([[ -5.1350],\n",
      "        [-13.7627],\n",
      "        [  8.9676],\n",
      "        [ -7.9824],\n",
      "        [  7.8965],\n",
      "        [-23.4901],\n",
      "        [ -0.6146],\n",
      "        [  9.4928],\n",
      "        [-19.3819],\n",
      "        [ -4.3633],\n",
      "        [ -3.9821],\n",
      "        [  6.6198],\n",
      "        [ -3.8756],\n",
      "        [-17.0125],\n",
      "        [-14.6192],\n",
      "        [  4.3842],\n",
      "        [  7.3089],\n",
      "        [ -4.9085],\n",
      "        [-13.3448],\n",
      "        [  7.6748]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第76次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第76次反向传播后的梯度为:\n",
      "tensor([0.0950]) tensor([-0.0504]) tensor([[ -5.1564],\n",
      "        [-13.8825],\n",
      "        [  9.1109],\n",
      "        [ -8.0324],\n",
      "        [  8.0320],\n",
      "        [-23.7208],\n",
      "        [ -0.5826],\n",
      "        [  9.6432],\n",
      "        [-19.5727],\n",
      "        [ -4.3735],\n",
      "        [ -3.9771],\n",
      "        [  6.7344],\n",
      "        [ -3.8879],\n",
      "        [-17.1823],\n",
      "        [-14.7415],\n",
      "        [  4.4899],\n",
      "        [  7.4437],\n",
      "        [ -4.9159],\n",
      "        [-13.4588],\n",
      "        [  7.8020]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第77次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第77次反向传播后的梯度为:\n",
      "tensor([0.0944]) tensor([-0.0500]) tensor([[ -5.1777],\n",
      "        [-14.0015],\n",
      "        [  9.2533],\n",
      "        [ -8.0821],\n",
      "        [  8.1667],\n",
      "        [-23.9500],\n",
      "        [ -0.5509],\n",
      "        [  9.7927],\n",
      "        [-19.7625],\n",
      "        [ -4.3837],\n",
      "        [ -3.9716],\n",
      "        [  6.8482],\n",
      "        [ -3.9005],\n",
      "        [-17.3515],\n",
      "        [-14.8628],\n",
      "        [  4.5954],\n",
      "        [  7.5780],\n",
      "        [ -4.9229],\n",
      "        [-13.5722],\n",
      "        [  7.9284]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第78次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第78次反向传播后的梯度为:\n",
      "tensor([0.0939]) tensor([-0.0497]) tensor([[ -5.1990],\n",
      "        [-14.1199],\n",
      "        [  9.3948],\n",
      "        [ -8.1313],\n",
      "        [  8.3006],\n",
      "        [-24.1778],\n",
      "        [ -0.5195],\n",
      "        [  9.9412],\n",
      "        [-19.9515],\n",
      "        [ -4.3938],\n",
      "        [ -3.9658],\n",
      "        [  6.9612],\n",
      "        [ -3.9133],\n",
      "        [-17.5201],\n",
      "        [-14.9830],\n",
      "        [  4.7008],\n",
      "        [  7.7119],\n",
      "        [ -4.9296],\n",
      "        [-13.6848],\n",
      "        [  8.0538]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第79次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第79次反向传播后的梯度为:\n",
      "tensor([0.0933]) tensor([-0.0494]) tensor([[ -5.2203],\n",
      "        [-14.2375],\n",
      "        [  9.5353],\n",
      "        [ -8.1802],\n",
      "        [  8.4339],\n",
      "        [-24.4041],\n",
      "        [ -0.4883],\n",
      "        [ 10.0887],\n",
      "        [-20.1395],\n",
      "        [ -4.4038],\n",
      "        [ -3.9596],\n",
      "        [  7.0734],\n",
      "        [ -3.9263],\n",
      "        [-17.6883],\n",
      "        [-15.1023],\n",
      "        [  4.8061],\n",
      "        [  7.8453],\n",
      "        [ -4.9358],\n",
      "        [-13.7967],\n",
      "        [  8.1784]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第80次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第80次反向传播后的梯度为:\n",
      "tensor([0.0927]) tensor([-0.0491]) tensor([[ -5.2416],\n",
      "        [-14.3545],\n",
      "        [  9.6749],\n",
      "        [ -8.2288],\n",
      "        [  8.5664],\n",
      "        [-24.6289],\n",
      "        [ -0.4574],\n",
      "        [ 10.2354],\n",
      "        [-20.3266],\n",
      "        [ -4.4138],\n",
      "        [ -3.9530],\n",
      "        [  7.1847],\n",
      "        [ -3.9396],\n",
      "        [-17.8559],\n",
      "        [-15.2206],\n",
      "        [  4.9113],\n",
      "        [  7.9782],\n",
      "        [ -4.9417],\n",
      "        [-13.9080],\n",
      "        [  8.3021]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第81次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第81次反向传播后的梯度为:\n",
      "tensor([0.0922]) tensor([-0.0487]) tensor([[ -5.2628],\n",
      "        [-14.4708],\n",
      "        [  9.8135],\n",
      "        [ -8.2769],\n",
      "        [  8.6983],\n",
      "        [-24.8524],\n",
      "        [ -0.4268],\n",
      "        [ 10.3811],\n",
      "        [-20.5128],\n",
      "        [ -4.4238],\n",
      "        [ -3.9461],\n",
      "        [  7.2953],\n",
      "        [ -3.9531],\n",
      "        [-18.0230],\n",
      "        [-15.3379],\n",
      "        [  5.0163],\n",
      "        [  8.1107],\n",
      "        [ -4.9472],\n",
      "        [-14.0185],\n",
      "        [  8.4249]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第82次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第82次反向传播后的梯度为:\n",
      "tensor([0.0916]) tensor([-0.0484]) tensor([[ -5.2840],\n",
      "        [-14.5864],\n",
      "        [  9.9512],\n",
      "        [ -8.3247],\n",
      "        [  8.8294],\n",
      "        [-25.0744],\n",
      "        [ -0.3964],\n",
      "        [ 10.5258],\n",
      "        [-20.6982],\n",
      "        [ -4.4337],\n",
      "        [ -3.9388],\n",
      "        [  7.4050],\n",
      "        [ -3.9669],\n",
      "        [-18.1895],\n",
      "        [-15.4542],\n",
      "        [  5.1213],\n",
      "        [  8.2427],\n",
      "        [ -4.9523],\n",
      "        [-14.1284],\n",
      "        [  8.5468]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第83次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第83次反向传播后的梯度为:\n",
      "tensor([0.0911]) tensor([-0.0481]) tensor([[ -5.3051],\n",
      "        [-14.7013],\n",
      "        [ 10.0881],\n",
      "        [ -8.3721],\n",
      "        [  8.9598],\n",
      "        [-25.2950],\n",
      "        [ -0.3663],\n",
      "        [ 10.6697],\n",
      "        [-20.8826],\n",
      "        [ -4.4436],\n",
      "        [ -3.9312],\n",
      "        [  7.5140],\n",
      "        [ -3.9809],\n",
      "        [-18.3556],\n",
      "        [-15.5696],\n",
      "        [  5.2261],\n",
      "        [  8.3742],\n",
      "        [ -4.9570],\n",
      "        [-14.2376],\n",
      "        [  8.6679]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第84次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第84次反向传播后的梯度为:\n",
      "tensor([0.0905]) tensor([-0.0478]) tensor([[ -5.3262],\n",
      "        [-14.8155],\n",
      "        [ 10.2240],\n",
      "        [ -8.4192],\n",
      "        [  9.0896],\n",
      "        [-25.5142],\n",
      "        [ -0.3364],\n",
      "        [ 10.8127],\n",
      "        [-21.0662],\n",
      "        [ -4.4534],\n",
      "        [ -3.9232],\n",
      "        [  7.6221],\n",
      "        [ -3.9951],\n",
      "        [-18.5211],\n",
      "        [-15.6840],\n",
      "        [  5.3308],\n",
      "        [  8.5052],\n",
      "        [ -4.9615],\n",
      "        [-14.3462],\n",
      "        [  8.7882]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第85次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第85次反向传播后的梯度为:\n",
      "tensor([0.0899]) tensor([-0.0475]) tensor([[ -5.3473],\n",
      "        [-14.9291],\n",
      "        [ 10.3590],\n",
      "        [ -8.4659],\n",
      "        [  9.2186],\n",
      "        [-25.7320],\n",
      "        [ -0.3068],\n",
      "        [ 10.9547],\n",
      "        [-21.2488],\n",
      "        [ -4.4632],\n",
      "        [ -3.9149],\n",
      "        [  7.7295],\n",
      "        [ -4.0095],\n",
      "        [-18.6861],\n",
      "        [-15.7974],\n",
      "        [  5.4354],\n",
      "        [  8.6358],\n",
      "        [ -4.9655],\n",
      "        [-14.4540],\n",
      "        [  8.9076]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第86次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第86次反向传播后的梯度为:\n",
      "tensor([0.0894]) tensor([-0.0472]) tensor([[ -5.3684],\n",
      "        [-15.0420],\n",
      "        [ 10.4932],\n",
      "        [ -8.5123],\n",
      "        [  9.3470],\n",
      "        [-25.9485],\n",
      "        [ -0.2774],\n",
      "        [ 11.0959],\n",
      "        [-21.4307],\n",
      "        [ -4.4729],\n",
      "        [ -3.9063],\n",
      "        [  7.8361],\n",
      "        [ -4.0241],\n",
      "        [-18.8505],\n",
      "        [-15.9100],\n",
      "        [  5.5398],\n",
      "        [  8.7659],\n",
      "        [ -4.9692],\n",
      "        [-14.5613],\n",
      "        [  9.0262]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第87次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第87次反向传播后的梯度为:\n",
      "tensor([0.0888]) tensor([-0.0469]) tensor([[ -5.3894],\n",
      "        [-15.1543],\n",
      "        [ 10.6264],\n",
      "        [ -8.5583],\n",
      "        [  9.4747],\n",
      "        [-26.1636],\n",
      "        [ -0.2483],\n",
      "        [ 11.2361],\n",
      "        [-21.6116],\n",
      "        [ -4.4826],\n",
      "        [ -3.8973],\n",
      "        [  7.9420],\n",
      "        [ -4.0390],\n",
      "        [-19.0145],\n",
      "        [-16.0216],\n",
      "        [  5.6442],\n",
      "        [  8.8956],\n",
      "        [ -4.9726],\n",
      "        [-14.6678],\n",
      "        [  9.1439]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第88次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第88次反向传播后的梯度为:\n",
      "tensor([0.0883]) tensor([-0.0466]) tensor([[ -5.4105],\n",
      "        [-15.2659],\n",
      "        [ 10.7588],\n",
      "        [ -8.6040],\n",
      "        [  9.6017],\n",
      "        [-26.3774],\n",
      "        [ -0.2194],\n",
      "        [ 11.3755],\n",
      "        [-21.7917],\n",
      "        [ -4.4923],\n",
      "        [ -3.8880],\n",
      "        [  8.0471],\n",
      "        [ -4.0540],\n",
      "        [-19.1779],\n",
      "        [-16.1323],\n",
      "        [  5.7483],\n",
      "        [  9.0248],\n",
      "        [ -4.9756],\n",
      "        [-14.7737],\n",
      "        [  9.2609]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第89次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第89次反向传播后的梯度为:\n",
      "tensor([0.0878]) tensor([-0.0463]) tensor([[ -5.4314],\n",
      "        [-15.3769],\n",
      "        [ 10.8904],\n",
      "        [ -8.6494],\n",
      "        [  9.7280],\n",
      "        [-26.5898],\n",
      "        [ -0.1908],\n",
      "        [ 11.5141],\n",
      "        [-21.9709],\n",
      "        [ -4.5019],\n",
      "        [ -3.8784],\n",
      "        [  8.1514],\n",
      "        [ -4.0693],\n",
      "        [-19.3408],\n",
      "        [-16.2420],\n",
      "        [  5.8524],\n",
      "        [  9.1535],\n",
      "        [ -4.9784],\n",
      "        [-14.8790],\n",
      "        [  9.3770]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第90次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第90次反向传播后的梯度为:\n",
      "tensor([0.0872]) tensor([-0.0460]) tensor([[ -5.4524],\n",
      "        [-15.4872],\n",
      "        [ 11.0211],\n",
      "        [ -8.6944],\n",
      "        [  9.8537],\n",
      "        [-26.8009],\n",
      "        [ -0.1624],\n",
      "        [ 11.6517],\n",
      "        [-22.1493],\n",
      "        [ -4.5115],\n",
      "        [ -3.8685],\n",
      "        [  8.2551],\n",
      "        [ -4.0847],\n",
      "        [-19.5031],\n",
      "        [-16.3509],\n",
      "        [  5.9563],\n",
      "        [  9.2818],\n",
      "        [ -4.9808],\n",
      "        [-14.9836],\n",
      "        [  9.4924]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第91次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第91次反向传播后的梯度为:\n",
      "tensor([0.0867]) tensor([-0.0458]) tensor([[ -5.4733],\n",
      "        [-15.5969],\n",
      "        [ 11.1509],\n",
      "        [ -8.7390],\n",
      "        [  9.9787],\n",
      "        [-27.0107],\n",
      "        [ -0.1342],\n",
      "        [ 11.7885],\n",
      "        [-22.3269],\n",
      "        [ -4.5210],\n",
      "        [ -3.8583],\n",
      "        [  8.3579],\n",
      "        [ -4.1004],\n",
      "        [-19.6650],\n",
      "        [-16.4590],\n",
      "        [  6.0600],\n",
      "        [  9.4096],\n",
      "        [ -4.9828],\n",
      "        [-15.0877],\n",
      "        [  9.6069]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第92次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第92次反向传播后的梯度为:\n",
      "tensor([0.0862]) tensor([-0.0455]) tensor([[ -5.4941],\n",
      "        [-15.7060],\n",
      "        [ 11.2799],\n",
      "        [ -8.7834],\n",
      "        [ 10.1031],\n",
      "        [-27.2191],\n",
      "        [ -0.1062],\n",
      "        [ 11.9245],\n",
      "        [-22.5036],\n",
      "        [ -4.5305],\n",
      "        [ -3.8478],\n",
      "        [  8.4601],\n",
      "        [ -4.1162],\n",
      "        [-19.8263],\n",
      "        [-16.5661],\n",
      "        [  6.1637],\n",
      "        [  9.5370],\n",
      "        [ -4.9846],\n",
      "        [-15.1910],\n",
      "        [  9.7207]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第93次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第93次反向传播后的梯度为:\n",
      "tensor([0.0856]) tensor([-0.0452]) tensor([[ -5.5150],\n",
      "        [-15.8144],\n",
      "        [ 11.4080],\n",
      "        [ -8.8274],\n",
      "        [ 10.2268],\n",
      "        [-27.4263],\n",
      "        [ -0.0785],\n",
      "        [ 12.0596],\n",
      "        [-22.6794],\n",
      "        [ -4.5400],\n",
      "        [ -3.8370],\n",
      "        [  8.5615],\n",
      "        [ -4.1322],\n",
      "        [-19.9871],\n",
      "        [-16.6723],\n",
      "        [  6.2671],\n",
      "        [  9.6639],\n",
      "        [ -4.9860],\n",
      "        [-15.2938],\n",
      "        [  9.8336]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第94次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第94次反向传播后的梯度为:\n",
      "tensor([0.0851]) tensor([-0.0449]) tensor([[ -5.5358],\n",
      "        [-15.9222],\n",
      "        [ 11.5354],\n",
      "        [ -8.8711],\n",
      "        [ 10.3499],\n",
      "        [-27.6322],\n",
      "        [ -0.0511],\n",
      "        [ 12.1939],\n",
      "        [-22.8545],\n",
      "        [ -4.5494],\n",
      "        [ -3.8259],\n",
      "        [  8.6622],\n",
      "        [ -4.1485],\n",
      "        [-20.1474],\n",
      "        [-16.7778],\n",
      "        [  6.3704],\n",
      "        [  9.7904],\n",
      "        [ -4.9872],\n",
      "        [-15.3960],\n",
      "        [  9.9458]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第95次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第95次反向传播后的梯度为:\n",
      "tensor([0.0846]) tensor([-0.0446]) tensor([[-5.5566e+00],\n",
      "        [-1.6029e+01],\n",
      "        [ 1.1662e+01],\n",
      "        [-8.9145e+00],\n",
      "        [ 1.0472e+01],\n",
      "        [-2.7837e+01],\n",
      "        [-2.3796e-02],\n",
      "        [ 1.2327e+01],\n",
      "        [-2.3029e+01],\n",
      "        [-4.5587e+00],\n",
      "        [-3.8145e+00],\n",
      "        [ 8.7622e+00],\n",
      "        [-4.1649e+00],\n",
      "        [-2.0307e+01],\n",
      "        [-1.6882e+01],\n",
      "        [ 6.4736e+00],\n",
      "        [ 9.9164e+00],\n",
      "        [-4.9880e+00],\n",
      "        [-1.5497e+01],\n",
      "        [ 1.0057e+01]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第96次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第96次反向传播后的梯度为:\n",
      "tensor([0.0841]) tensor([-0.0443]) tensor([[-5.5773e+00],\n",
      "        [-1.6136e+01],\n",
      "        [ 1.1788e+01],\n",
      "        [-8.9575e+00],\n",
      "        [ 1.0594e+01],\n",
      "        [-2.8040e+01],\n",
      "        [ 3.2344e-03],\n",
      "        [ 1.2460e+01],\n",
      "        [-2.3202e+01],\n",
      "        [-4.5680e+00],\n",
      "        [-3.8029e+00],\n",
      "        [ 8.8615e+00],\n",
      "        [-4.1814e+00],\n",
      "        [-2.0466e+01],\n",
      "        [-1.6986e+01],\n",
      "        [ 6.5766e+00],\n",
      "        [ 1.0042e+01],\n",
      "        [-4.9886e+00],\n",
      "        [-1.5598e+01],\n",
      "        [ 1.0168e+01]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第97次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第97次反向传播后的梯度为:\n",
      "tensor([0.0835]) tensor([-0.0441]) tensor([[ -5.5980],\n",
      "        [-16.2420],\n",
      "        [ 11.9125],\n",
      "        [ -9.0003],\n",
      "        [ 10.7153],\n",
      "        [-28.2424],\n",
      "        [  0.0300],\n",
      "        [ 12.5918],\n",
      "        [-23.3747],\n",
      "        [ -4.5773],\n",
      "        [ -3.7909],\n",
      "        [  8.9601],\n",
      "        [ -4.1982],\n",
      "        [-20.6253],\n",
      "        [-17.0889],\n",
      "        [  6.6795],\n",
      "        [ 10.1671],\n",
      "        [ -4.9888],\n",
      "        [-15.6988],\n",
      "        [ 10.2779]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第98次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第98次反向传播后的梯度为:\n",
      "tensor([0.0830]) tensor([-0.0438]) tensor([[ -5.6187],\n",
      "        [-16.3474],\n",
      "        [ 12.0366],\n",
      "        [ -9.0427],\n",
      "        [ 10.8358],\n",
      "        [-28.4433],\n",
      "        [  0.0566],\n",
      "        [ 12.7228],\n",
      "        [-23.5465],\n",
      "        [ -4.5866],\n",
      "        [ -3.7787],\n",
      "        [  9.0580],\n",
      "        [ -4.2151],\n",
      "        [-20.7835],\n",
      "        [-17.1910],\n",
      "        [  6.7822],\n",
      "        [ 10.2917],\n",
      "        [ -4.9888],\n",
      "        [-15.7985],\n",
      "        [ 10.3871]]) None\n",
      "************************************************************\n",
      "************************************************************\n",
      "第99次反向传播前的梯度为:\n",
      "梯度不存在\n",
      "第99次反向传播后的梯度为:\n",
      "tensor([0.0825]) tensor([-0.0435]) tensor([[ -5.6393],\n",
      "        [-16.4522],\n",
      "        [ 12.1599],\n",
      "        [ -9.0849],\n",
      "        [ 10.9557],\n",
      "        [-28.6430],\n",
      "        [  0.0830],\n",
      "        [ 12.8531],\n",
      "        [-23.7175],\n",
      "        [ -4.5958],\n",
      "        [ -3.7663],\n",
      "        [  9.1553],\n",
      "        [ -4.2322],\n",
      "        [-20.9412],\n",
      "        [-17.2922],\n",
      "        [  6.8847],\n",
      "        [ 10.4160],\n",
      "        [ -4.9885],\n",
      "        [-15.8976],\n",
      "        [ 10.4955]]) None\n",
      "************************************************************\n",
      "tensor([1.7747]) tensor([5.1196])\n"
     ]
    }
   ],
   "source": [
    "# 首先我们得有训练样本X，Y， 这里我们随机生成\n",
    "x = torch.rand(20, 1, requires_grad=True) +6\n",
    "\n",
    "y = 2 * x + (5 + torch.randn(20, 1, requires_grad=True))\n",
    "\n",
    "# 构建线性回归函数的参数\n",
    "w = torch.randn((1), requires_grad=True)\n",
    "b = torch.zeros((1), requires_grad=True)   # 这俩都需要求梯度\n",
    "\n",
    "# 设置学习率lr为0.1\n",
    "lr = 0.1\n",
    "\n",
    "for iteration in range(100):\n",
    "    # 前向传播\n",
    "    wx = torch.mul(w, x) #将两张量中元素\n",
    "    y_pred = torch.add(wx, b)\n",
    "\n",
    "    \n",
    "    # 计算loss\n",
    "    loss = (0.5 * (y-y_pred)**2).mean()\n",
    "\n",
    "    print(\"*\"*60)\n",
    "    print(f\"第{iteration}次反向传播前的梯度为:\")\n",
    "    try:\n",
    "        print(w.grad.data,b.grad.data,x.grad.data,y.grad.data)\n",
    "    except :\n",
    "        print(\"梯度不存在\")\n",
    "    # 反向传播\n",
    "    loss.backward(retain_graph=True)\n",
    "    print(f\"第{iteration}次反向传播后的梯度为:\")\n",
    "    t = x.grad.data if x.grad != None  else None\n",
    "    t1 = y.grad.data if y.grad != None else None\n",
    "    print(w.grad.data,b.grad.data,t,t1)\n",
    "    print(\"*\"*60)\n",
    "    # 更新参数\n",
    "    b.data.sub_(lr * b.grad)    # 这种_的加法操作时从自身减，相当于-=\n",
    "    w.data.sub_(lr * w.grad)\n",
    "\n",
    "    # 梯度清零\n",
    "    w.grad.data.zero_()\n",
    "    b.grad.data.zero_()\n",
    "\n",
    "print(w.data, b.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "给x加点东西，发现真的没法计算梯度了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那么如何计算参数梯度的前提要求就已经确定了\n",
    "1. 使用torch定义一个未经过运算的张量\n",
    "2. 为张量设定requires_grad=True\n",
    "3. 确保张量为叶节点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实操部分结束，那么该回到枯燥的理论部分了\n",
    "<p id = \"end\"><p>\n",
    "\n",
    "[返回深度学习笔记](../../深度学习.md)\n",
    "\n",
    "[直接前往反向传播部分](./backward.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
